{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hu_validations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIkTMVj0WpVBKTxi41r+Xm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emerenan/xlsx_validation/blob/main/hu_validations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sPiDTWZxtiO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "import re\n",
        "from openpyxl import Workbook, styles\n",
        "from openpyxl.styles import PatternFill, Font\n",
        "from openpyxl.styles.differential import DifferentialStyle\n",
        "from openpyxl.formatting.rule import Rule\n",
        "\n",
        "def lower_str(columns):\n",
        "    newlist = list(map(lambda x: x.lower(), columns))\n",
        "    return newlist\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjIt6YFKQ2HV"
      },
      "source": [
        "Doing all checks in Towerdb File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRY_-bVE0AZ0"
      },
      "source": [
        "\"\"\"Defining variables which is gonna be reusable in checks\"\"\"\n",
        "tw_index = 'code'\n",
        "tw_doer = 'date of equipment removal'\n",
        "tw_status = 'active / not active'\n",
        "tw_bts = 'bts_site'\n",
        "tw_bill = 'ready for active installation (\"rfai\") date'\n",
        "tw_wip = 'wip_site'\n",
        "#tw_decom = 'Decommissioned sites'\n",
        "tw_critical = 'critical site'\n",
        "\n",
        "\n",
        "msa_index ='code'\n",
        "msa_doer = 'date of equipment removal'\n",
        "msa_status = 'active / not active'\n",
        "msa_bts = 'bts_site'\n",
        "msa_bill = 'ready for active installation (\"rfai\") date'\n",
        "msa_wip = 'wip_site'\n",
        "#msa_decom = 'Decommissioned sites'\n",
        "msa_critical = 'critical site'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "BhzjYXhrerla",
        "outputId": "9e6656ba-e09c-456d-fe6b-f9de932f6ddb"
      },
      "source": [
        "path_msa = '/content/TowerDB_Hungary_20210731 (1).csv'\n",
        "msa = pd.read_csv(path_msa, encoding='latin')\n",
        "\n",
        "msa_cols = lower_str(list(msa.columns))\n",
        "msa.columns = msa_cols\n",
        "msa = msa.rename(columns={\n",
        "    'additional information \\x96 room configuration (including container information)': 'additional information - room configuration (including container information)'\n",
        "})\n",
        "\n",
        "path_tw = '/content/TowerDB_Hungary_20210831.csv'\n",
        "towerdb = pd.read_csv(path_tw, encoding='latin').fillna('')\n",
        "towerdb.columns = lower_str(list(towerdb.columns))\n",
        "towerdb = towerdb.rename(columns={\n",
        "    'additional information \\x96 room configuration (including container information)': 'additional information - room configuration (including container information)'\n",
        "})\n",
        "\n",
        "towerdb = towerdb.fillna('')\n",
        "\n",
        "#Check and fit date values\n",
        "date_cols = ['first_active_sharing_start_date','first_active_sharing_end_date','ready for active installation (\"rfai\") date', 'date of equipment removal']\n",
        "\n",
        "for i in date_cols:\n",
        "    towerdb[i] = [dt if re.match(r\"[0-9]{1,2}[\\_|\\-|\\/][0-9]{1,2}[\\_|\\-|\\/][0-9]{1,4}\", dt) or dt in (None, '') or dt.isspace() else f\"{dt:%d/%m/%Y}\" for dt in towerdb[i]]\n",
        "\n",
        "#Replace Invalid values\n",
        "replace_cols = [\n",
        "    'confirmed skylon scope',\n",
        "    'code',\n",
        "    'categorization by transmission sys',\n",
        "    'categorization by transmission sys (subcluster)',\n",
        "    'categorization by site type',\n",
        "    'additional information - room configuration (including container information)',\n",
        "    'type of air cooling',\n",
        "    'core site type ',\n",
        "    'macro site - transmission hub site',\n",
        "    'macro site - transmission hub site with/without shelters',\n",
        "    'active sharing arrangements involving the operator',\n",
        "    'critical site',\n",
        "    'strategic site',\n",
        "    'telenor tenant',\n",
        "    'telekom tenant',\n",
        "    'power supply for tenants',\n",
        "    'energy category',\n",
        "    'wip_site',\n",
        "    'bts_site',\n",
        "    'strategic_site_bucket',\n",
        "    'critical_site_beyond_10',\n",
        "    'subsequent_sharing_arrangement',\n",
        "    'sites_as_metered_estimated']\n",
        "for i in replace_cols:\n",
        "    towerdb[i] = towerdb[i].replace([ 'N/A', 'n/a', '0', ' '], '')\n",
        "\n",
        "towerdb.to_csv('/content/TowerDB_Hungary_20210831_test.csv', index=False, encoding='latin')\n",
        "towerdb.head(3)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>celltracker skylon scope</th>\n",
              "      <th>confirmed skylon scope start</th>\n",
              "      <th>confirmed skylon scope end</th>\n",
              "      <th>active / not active</th>\n",
              "      <th>confirmed skylon scope</th>\n",
              "      <th>code</th>\n",
              "      <th>code1</th>\n",
              "      <th>third site id</th>\n",
              "      <th>site name</th>\n",
              "      <th>macro region</th>\n",
              "      <th>province</th>\n",
              "      <th>municipality</th>\n",
              "      <th>inhabitants</th>\n",
              "      <th>address</th>\n",
              "      <th>ground register</th>\n",
              "      <th>altitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>categorization by transmission sys</th>\n",
              "      <th>categorization by transmission sys (subcluster)</th>\n",
              "      <th>das system</th>\n",
              "      <th>active/passive das</th>\n",
              "      <th>das ownership (fully / partially)</th>\n",
              "      <th>vertical passive structure owner</th>\n",
              "      <th>vertical passive structure owner classification</th>\n",
              "      <th>das owner</th>\n",
              "      <th>other categorization for internal use</th>\n",
              "      <th>categorization by site type</th>\n",
              "      <th>categorization by inhabitants</th>\n",
              "      <th>type of structure</th>\n",
              "      <th>other internal categorization 1</th>\n",
              "      <th>other internal categorization 2 (sitetypemain)</th>\n",
              "      <th>other internal categorization 3 (sitetypemain_v1)</th>\n",
              "      <th>other internal categorization 4 (sitetypemain_v2)</th>\n",
              "      <th>other internal categorization 5 (sitetypemain_archive)</th>\n",
              "      <th>other internal categorization 6 (sitetypeminor)</th>\n",
              "      <th>other internal categorization 7 (sitetypeminor_archive)</th>\n",
              "      <th>other internal categorization 8</th>\n",
              "      <th>other internal categorization 9 (for the 1 by 1 reviewed sites only)</th>\n",
              "      <th>technology vod</th>\n",
              "      <th>...</th>\n",
              "      <th>annual hosting digi in huf</th>\n",
              "      <th>annual hosting digi in eur</th>\n",
              "      <th>annual energy digi</th>\n",
              "      <th>annual maintenance fee digi</th>\n",
              "      <th>other services fee digi</th>\n",
              "      <th>total revenues digi in huf</th>\n",
              "      <th>total revenues digi in eur</th>\n",
              "      <th>residual duration digi</th>\n",
              "      <th>maturity clusters digi</th>\n",
              "      <th>otmos</th>\n",
              "      <th>annual hosting otmos in huf</th>\n",
              "      <th>annual hosting otmos in eur</th>\n",
              "      <th>annual energy otmos</th>\n",
              "      <th>annual maintenance fee otmos</th>\n",
              "      <th>other services fee otmos</th>\n",
              "      <th>total revenues otmos in huf</th>\n",
              "      <th>total revenues otmos in eur</th>\n",
              "      <th>residual duration otmos</th>\n",
              "      <th>maturity clusters otmos</th>\n",
              "      <th>total # of 3rd party tenants</th>\n",
              "      <th>annual hosting fee from 3rd party tenants in huf</th>\n",
              "      <th>annual hosting fee from 3rd party tenants in eur</th>\n",
              "      <th>annual energy fee from 3rd party tenants</th>\n",
              "      <th>annual maintenance fee from 3rd party tenants</th>\n",
              "      <th>other services fee from 3rd party tenants</th>\n",
              "      <th>total hosting fee &amp; services from 3rd party tenants in huf</th>\n",
              "      <th>total hosting fee &amp; services from 3rd party tenants in eur</th>\n",
              "      <th>waighted average residual duration</th>\n",
              "      <th>adjusted status</th>\n",
              "      <th>adjustes scope</th>\n",
              "      <th>wip_site</th>\n",
              "      <th>bts_site</th>\n",
              "      <th>strategic_site_bucket</th>\n",
              "      <th>critical_site_beyond_10</th>\n",
              "      <th>subsequent_sharing_arrangement</th>\n",
              "      <th>first_active_sharing_start_date</th>\n",
              "      <th>first_active_sharing_end_date</th>\n",
              "      <th>active sharing deployment types</th>\n",
              "      <th>sites_as_metered_estimated</th>\n",
              "      <th>date of equipment removal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In scope</td>\n",
              "      <td>01/04/2017</td>\n",
              "      <td></td>\n",
              "      <td>In Service</td>\n",
              "      <td>In scope</td>\n",
              "      <td>1001</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>BUDAPESTNYUGATI TER</td>\n",
              "      <td>Pest</td>\n",
              "      <td>Budapest</td>\n",
              "      <td>Budapest</td>\n",
              "      <td>1 735 711</td>\n",
              "      <td>Nyugati tér 5.</td>\n",
              "      <td>25054/3</td>\n",
              "      <td>105</td>\n",
              "      <td>47.51097712</td>\n",
              "      <td>19.05516864</td>\n",
              "      <td>Macro</td>\n",
              "      <td>Standard</td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Vodafone vertical</td>\n",
              "      <td>Vodafone</td>\n",
              "      <td></td>\n",
              "      <td>Macro</td>\n",
              "      <td>RTT</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Rooftop structure</td>\n",
              "      <td>Pitched roof</td>\n",
              "      <td>Pitched roof</td>\n",
              "      <td>Pitched roof</td>\n",
              "      <td>Roof</td>\n",
              "      <td>Lapostetö/Magastetö</td>\n",
              "      <td>Pitched roof</td>\n",
              "      <td>magastetö</td>\n",
              "      <td>Pitched roof</td>\n",
              "      <td></td>\n",
              "      <td>2G3G4G</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>exclude</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>exclude</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Non Strategic</td>\n",
              "      <td>Non Critical</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Estimated Model</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In scope</td>\n",
              "      <td>01/04/2017</td>\n",
              "      <td></td>\n",
              "      <td>In Service</td>\n",
              "      <td>In scope</td>\n",
              "      <td>1002</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>DEAK tér</td>\n",
              "      <td>Pest</td>\n",
              "      <td>Budapest</td>\n",
              "      <td>Budapest</td>\n",
              "      <td>1 735 711</td>\n",
              "      <td>Bajcsy Zsilinszky u. 9.</td>\n",
              "      <td>29264/2</td>\n",
              "      <td>105</td>\n",
              "      <td>47.49906804</td>\n",
              "      <td>19.05508727</td>\n",
              "      <td>Macro</td>\n",
              "      <td>Standard</td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Vodafone vertical</td>\n",
              "      <td>Vodafone</td>\n",
              "      <td></td>\n",
              "      <td>Macro</td>\n",
              "      <td>RTT</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Rooftop structure</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td>Roof</td>\n",
              "      <td>Lapostetö/Magastetö</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td>lapostetö</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td></td>\n",
              "      <td>2G3G4G</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>exclude</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>exclude</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Non Strategic</td>\n",
              "      <td>Non Critical</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Metered Model</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In scope</td>\n",
              "      <td>01/04/2017</td>\n",
              "      <td></td>\n",
              "      <td>In Service</td>\n",
              "      <td>In scope</td>\n",
              "      <td>1004</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>BUDAPEST-BKV</td>\n",
              "      <td>Pest</td>\n",
              "      <td>Budapest</td>\n",
              "      <td>Budapest</td>\n",
              "      <td>1 735 711</td>\n",
              "      <td>Szabó Ervin tér 2.</td>\n",
              "      <td>36750/3</td>\n",
              "      <td>103</td>\n",
              "      <td>47.48905593</td>\n",
              "      <td>19.06418919</td>\n",
              "      <td>Macro</td>\n",
              "      <td>Standard</td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Vodafone</td>\n",
              "      <td>Vodafone</td>\n",
              "      <td></td>\n",
              "      <td>Macro</td>\n",
              "      <td>RTT</td>\n",
              "      <td>Urban</td>\n",
              "      <td>Rooftop structure</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td>Roof</td>\n",
              "      <td>Lapostetö/Magastetö</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td>lapostetö</td>\n",
              "      <td>Flat roof</td>\n",
              "      <td>lapostetö</td>\n",
              "      <td>2G3G4G</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>exclude</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>exclude</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Non Strategic</td>\n",
              "      <td>Non Critical</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Metered Model</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 222 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  celltracker skylon scope  ... date of equipment removal\n",
              "0                 In scope  ...                          \n",
              "1                 In scope  ...                          \n",
              "2                 In scope  ...                          \n",
              "\n",
              "[3 rows x 222 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hEuMIJ5ITPI"
      },
      "source": [
        "towerdb[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "kxtk2vxTvkEP",
        "outputId": "8c12e2e9-6549-430d-8b4b-adc1b86e996b"
      },
      "source": [
        "\"\"\"Check Columns Received\"\"\" \n",
        "def check_columns_received(df, bill_cols):\n",
        "    twdb_col = lower_str(list(df.columns))\n",
        "    col_miss = [i for i in bill_cols if i not in twdb_col]\n",
        "    \"\"\"\n",
        "    for i in bill_cols:\n",
        "        if i not in twdb_col:\n",
        "            col_miss.append(i)\"\"\"\n",
        "    df_col_missing = pd.DataFrame(col_miss, columns=['Column(s) Missing'], index=range(len(col_miss)))\n",
        "    return df_col_missing\n",
        "\n",
        "df_cols = check_columns_received(towerdb, list(msa.columns))\n",
        "df_cols\n",
        "#No columns missing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column(s) Missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Column(s) Missing]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuTDCDSVAP9P"
      },
      "source": [
        "First Check - Dates Formats (dd/mm/YYYY)\n",
        "\n",
        "Columns: Date of equipment removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzPJTGcSANf4"
      },
      "source": [
        "\"\"\"You need to convert all values in cols for string format to check\"\"\"\n",
        "\"\"\"CSV FIles doesn't need convert, only fill na values\"\"\"\n",
        "def check_date_columns(df, df_index,status_col,columns):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_dates = df[columns].fillna('')\n",
        "    df_dates = df_dates.to_dict(orient='list')\n",
        "    #df_dates['sites'] = df_dates[df_index]\n",
        "    #df_dates = df_dates.set_index('sites')\n",
        "    new_dic = defaultdict(list)\n",
        "\n",
        "    date_format = re.compile(r\"[0-9]{1,2}[\\_|\\-|\\/][0-9]{1,2}[\\_|\\-|\\/][0-9]{1,4}\")\n",
        "\n",
        "    for column in set(df_dates.keys()):\n",
        "        for value in df_dates[column]:\n",
        "            if date_format.match(value) == None:\n",
        "                if value in (None, '', 'nan'):\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorret picklist value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok', np.nan)\n",
        "    df_errors[df_index] = [i for i in df[df_index]]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, status_col]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[status_col]+ df_errors.columns[:-1].tolist()]\n",
        "    df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "actives_1 = towerdb[towerdb[tw_status]=='In Service']\n",
        "no_actives_1 = towerdb[~(towerdb[tw_status]=='In Service')]\n",
        "\n",
        "#Checking columns for errors\n",
        "actives_dates_errors = check_date_columns(actives_1, tw_index, tw_status, [tw_bill]) \n",
        "# Actives sites with blank billing trigger date\n",
        "no_actives_dates_errors = check_date_columns(no_actives_1, tw_index, tw_status, [tw_doer]) \n",
        "\n",
        "print(actives_dates_errors)\n",
        "print('\\n')\n",
        "print(no_actives_dates_errors)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4y5qNGSLf6z"
      },
      "source": [
        "Thirth - Check Picklist values All sites\n",
        "\n",
        "Do this check in all sites\n",
        "\n",
        "Check the picklist for each case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbwAq3ClCDqx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "e3550657-d5fe-41c4-8d77-45cdfd440c62"
      },
      "source": [
        "def check_picklist_v1(df,df_index,df_status, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_cols = list(picklist_dict.keys())\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    \"\"\"for id in df_picklist[df_index]:\n",
        "        if id not in new_dic.keys():\n",
        "            new_dic[df_index].append(id)\"\"\" \n",
        "            \n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]): \n",
        "                if pd.isnull(value) or pd.isna(value) or value=='' or value=='nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors[df_index] = [i for i in df[df_index]]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, df_status]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[df_status]+ df_errors.columns[:-1].tolist()]\n",
        "    df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "picklist_tw_general = {\n",
        "    'categorization by transmission sys': ['Macro', 'Macro+DAS', 'Public DAS','Transmission']\n",
        "}\n",
        "\n",
        "df_general_pick = check_picklist_v1(towerdb, tw_index,tw_status, picklist_tw_general)\n",
        "df_general_pick"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>active / not active</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [active / not active]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfestas6f6ES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "abfa7cf9-e0d7-429c-9cec-e1d039ba6cfe"
      },
      "source": [
        "def check_mom_bts(df_tw, tw_index,status_col, bts_col, df_msa):\n",
        "\n",
        "    msa_bts = df_msa[df_msa[bts_col]=='Yes']\n",
        "    msa_bts_sites = [i for i in msa_bts[tw_index]]\n",
        "\n",
        "    tw_bts = df_tw[df_tw[bts_col]=='Yes']\n",
        "    tw_bts_sites = [i for i in tw_bts[tw_index]]\n",
        "\n",
        "    out_tower_bts = [i for i in msa_bts_sites if i not in tw_bts_sites]\n",
        "    filtered = df_msa[df_msa[tw_index].isin([int(i) for i in out_tower_bts])]\n",
        "    filtered = filtered[[tw_index,status_col, bts_col]]\n",
        "    actual = df_tw[df_tw[tw_index].isin(out_tower_bts)][[tw_index, bts_col, status_col]]\n",
        "    merge = pd.merge(filtered, actual, how='inner', on=tw_index, suffixes=['_old', '_in_month'])\n",
        "\n",
        "    return  merge[[tw_index, status_col+'_old',status_col+'_in_month', bts_col+'_old',bts_col+'_in_month']]\n",
        "\n",
        "actives = towerdb[towerdb[tw_status]=='In Service']\n",
        "df_mom_bts = check_mom_bts(actives, tw_index,tw_status, tw_bts, msa, msa_index, msa_bts)\n",
        "# No one error df_mom_bts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>active / not active</th>\n",
              "      <th>bts_site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [code, active / not active, bts_site]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsMno4c2OdqL"
      },
      "source": [
        "Check Picklist and dates formats for In service sites\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CyoPjLhIv88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "06b8efb1-64ba-4243-8179-87fa00cf78bb"
      },
      "source": [
        "def check_picklist_v1(df,df_index,df_status, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "    \n",
        "    df_cols = list(picklist_dict.keys())\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    \"\"\"for id in df_picklist[df_index]:\n",
        "        if id not in new_dic.keys():\n",
        "            new_dic[df_index].append(id)\"\"\" \n",
        "            \n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]): \n",
        "                if pd.isnull(value) or pd.isna(value) or value=='' or value=='nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors[df_index] = [i for i in df[df_index]]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, df_status]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[df_status]+ df_errors.columns[:-1].tolist()]\n",
        "    df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "picklis_dict = {\n",
        "    'confirmed skylon scope': ['In scope','Out of scope'],\n",
        "    'categorization by transmission sys (subcluster)': ['Standard','Core','Dual Use Site','Transmission','Repeater','Long-term Mobile','DAS active',\\\n",
        "                                                        'DAS passive','Macro+DAS active','Macro+DAS passive','Outdoor Small Cells'],\n",
        "    'categorization by transmission sys': ['Macro', 'Macro+DAS', 'Public DAS','Transmission','Repeater','Long-term Mobile', 'Outdoor Small Cells'],\n",
        "    'categorization by site type': ['RTT','GBT','DAS active' ,'DAS passive' ,'RTT+DAS active' ,'GBT+DAS active','RTT+DAS passive' ,'GBT+DAS passive','Outdoor Small Cells'],\n",
        "    'additional information - room configuration (including container information)': ['Indoor','Outdoor','Indoor & Outdoor'],\n",
        "    'type of air cooling' : ['No','Yes; Indoor Air Conditioning','Yes; Indoor Air Conditioning and Free Air cooling / Free cooling units'],\n",
        "    'core site type ': ['Case A','Case B','Non Core'],\n",
        "    'macro site - transmission hub site': ['Yes', 'No'],\n",
        "    'macro site - transmission hub site with/without shelters': ['With shelters','Without shelters','Non Transmission Hub Site'],\n",
        "    'active sharing arrangements involving the operator': ['MORAN (On VF equipment)','MORAN (On non-VF equipment)','MOCN with Spectrum Pooling',\\\n",
        "                                                           'Partial Active-Passive','No Active Sharing'],         \n",
        "    'critical site': ['Yes', 'No'],\n",
        "    'strategic site': ['Yes', 'No'],\n",
        "    'telenor tenant': ['Yes', 'No'],\n",
        "    'telekom tenant': ['Yes', 'No'],\n",
        "    'power supply for tenants': ['AC', 'DC', 'no power'],\n",
        "    'energy category': ['X','Y','Z-1','Z-2','No energy consumption'],\n",
        "    'wip_site': ['Yes', 'No'],\n",
        "    'bts_site': ['Yes', 'No'],\n",
        "    'strategic site': ['Yes', 'No'],\n",
        "    'critical site': ['Yes', 'No'],\n",
        "    'strategic_site_bucket': ['Yes - 0-5%','Yes - 5-10%','Non Strategic'],\n",
        "    'critical_site_beyond_10':['Beyond 10%','Within 10%','Non Critical'],\n",
        "    'sites_as_metered_estimated': ['Estimated Model','Metered Model']\n",
        "}\n",
        "\n",
        "actives_2 = towerdb[towerdb[tw_status]=='In Service']\n",
        "df_in_service_picklist = check_picklist_v1(actives_2,tw_index,tw_status, picklis_dict)\n",
        "df_in_service_picklist\n",
        "#muitos errors\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>active / not active</th>\n",
              "      <th>sites_as_metered_estimated</th>\n",
              "      <th>power supply for tenants</th>\n",
              "      <th>categorization by site type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1826</th>\n",
              "      <td>RGU0352</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Incorrect value: DAS Passive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827</th>\n",
              "      <td>RGU0453</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Incorrect value: DAS Passive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1828</th>\n",
              "      <td>RU0094</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Incorrect value: DAS Passive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1829</th>\n",
              "      <td>RU0138</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Incorrect value: DAS Passive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1830</th>\n",
              "      <td>S0113</td>\n",
              "      <td>In Service</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Incorrect value: DAS Passive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1831 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         code  ...   categorization by site type\n",
              "0        1001  ...                           NaN\n",
              "1        1002  ...                           NaN\n",
              "2        1004  ...                           NaN\n",
              "3        1005  ...                           NaN\n",
              "4        1007  ...                           NaN\n",
              "...       ...  ...                           ...\n",
              "1826  RGU0352  ...  Incorrect value: DAS Passive\n",
              "1827  RGU0453  ...  Incorrect value: DAS Passive\n",
              "1828   RU0094  ...  Incorrect value: DAS Passive\n",
              "1829   RU0138  ...  Incorrect value: DAS Passive\n",
              "1830    S0113  ...  Incorrect value: DAS Passive\n",
              "\n",
              "[1831 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAwey2bGcDER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "496cfea1-4471-46a4-dfe7-a3d1e37c0cb6"
      },
      "source": [
        "def check_date_columns(df, df_index,status_col,columns):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_dates = df[columns].fillna('')\n",
        "    df_dates = df_dates.to_dict(orient='list')\n",
        "    #df_dates['sites'] = df_dates[df_index]\n",
        "    #df_dates = df_dates.set_index('sites')\n",
        "    new_dic = defaultdict(list)\n",
        "\n",
        "    date_format = re.compile(r\"[0-9]{1,2}[\\_|\\-|\\/][0-9]{1,2}[\\_|\\-|\\/][0-9]{1,4}\")\n",
        "\n",
        "    for column in set(df_dates.keys()):\n",
        "        for value in df_dates[column]:\n",
        "            if date_format.match(value) == None:\n",
        "                if value in (None, '', 'nan'):\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorret picklist value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok', np.nan)\n",
        "    df_errors[df_index] = [i for i in df[df_index]]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, status_col]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[status_col]+ df_errors.columns[:-1].tolist()]\n",
        "    df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "actives_1 = towerdb[towerdb[tw_status]=='In Service']\n",
        "date_cols = ['infrastructure ready (existing)/ to be ready (new)', 'ready for active installation (\"rfai\") date', 'first_active_sharing_start_date','first_active_sharing_end_date']\n",
        "#start_dates = ['infrastructure ready (existing)/ to be ready (new)', 'ready for active installation (\"rfai\") date', 'first_active_sharing_start_date','first_active_sharing_end_date']\n",
        "\n",
        "#date_parser(actives, start_dates, \"%d/%m/%Y\", 'no')\n",
        "df_in_service_dates = check_date_columns(actives_1, tw_index,tw_status, date_cols)\n",
        "df_in_service_dates\n",
        "#Muitos Campos em branco"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>active / not active</th>\n",
              "      <th>first_active_sharing_start_date</th>\n",
              "      <th>ready for active installation (\"rfai\") date</th>\n",
              "      <th>first_active_sharing_end_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2048</th>\n",
              "      <td>RGU0352</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2049</th>\n",
              "      <td>RGU0453</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2050</th>\n",
              "      <td>RU0094</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2051</th>\n",
              "      <td>RU0138</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2052</th>\n",
              "      <td>S0113</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2053 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         code  ... first_active_sharing_end_date\n",
              "0        1001  ...                   Blank Value\n",
              "1        1002  ...                   Blank Value\n",
              "2        1004  ...                   Blank Value\n",
              "3        1005  ...                   Blank Value\n",
              "4        1007  ...                   Blank Value\n",
              "...       ...  ...                           ...\n",
              "2048  RGU0352  ...                   Blank Value\n",
              "2049  RGU0453  ...                   Blank Value\n",
              "2050   RU0094  ...                   Blank Value\n",
              "2051   RU0138  ...                   Blank Value\n",
              "2052    S0113  ...                   Blank Value\n",
              "\n",
              "[2053 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TNxDZU4fp0J"
      },
      "source": [
        "Fifth Check BTS Flagged(Billing Trigger and Commercial)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pd0kaUofmxX"
      },
      "source": [
        "def check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col):\n",
        "    \n",
        "    t = type_col.lower()\n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "        \n",
        "    if t == 'doer':\n",
        "        df_tw[date_col]= pd.to_datetime(df_tw[date_col], format='%d/%m/%Y', errors='coerce')\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&((df_tw[date_col] < current_date)|(df_tw[date_col]==''))]\n",
        "        filtered[date_col] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[date_col]))\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "    else:\n",
        "        #df_tw[date_col]= pd.to_datetime(df_tw[date_col], format='%d/%m/%Y', errors='coerce')\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&(df_tw[date_col]=='')]\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "\n",
        "status = 'Yes'\n",
        "actives = towerdb[towerdb[tw_index]=='In Service']\n",
        "df_bts_empty = check_tw_bill_doer(actives, tw_index,tw_bill, tw_bts, status, 'bill')\n",
        "\n",
        "#No errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AEXpWOvfzLo"
      },
      "source": [
        "Check MoM Sites (BTS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-gggsUqgB6-"
      },
      "source": [
        "\"\"\" BTS sites\"\"\"\n",
        "path_uip = '/content/UserInput_Hungary_20210831.xlsx'\n",
        "uip_names = ['Site_ID','BTS site applicable charge (Annual)',\\\n",
        "             'Commercials for sites beyond 10% cap of critical sites (Annual)']\n",
        "uip = pd.read_excel(path_uip ,sheet_name='SiteLevel',usecols=[0,1,2],skiprows=2)\n",
        "uip.columns = uip_names\n",
        "\n",
        "msa_sites = [i for i in msa[msa_index]]\n",
        "tw_sites = [i for i in towerdb[tw_index]]\n",
        "uip_sites = [str(i) for i in uip['Site_ID']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Esp0eztHLT"
      },
      "source": [
        "\"\"\" BTS sites\"\"\"\n",
        "def check_new_sites(df_towerdb, tw_index, bts_col, bill_col, status_col, msa_list, towerdb_list, uip_list):\n",
        "    \n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "    \n",
        "    filtered = df_towerdb[[tw_index, status_col, bts_col]]\n",
        "\n",
        "    #Finding for ALL NEW SITES\n",
        "    new_site = [i for i in towerdb_list if i not in msa_list]\n",
        "    new_sites = pd.DataFrame(new_site, columns=['New_Sites'])\n",
        "    new_sites = pd.merge(new_sites, filtered, how='left', left_on=['New_Sites'], right_on=tw_index)\n",
        "    new_sites = new_sites[['New_Sites', status_col, bts_col]]\n",
        "\n",
        "    #create a copy to make index modifications\n",
        "    df = df_towerdb.copy()\n",
        "\n",
        "    #New columns with Site Codes\n",
        "    df['Sites'] = df[tw_index]\n",
        "    #defining site code to index\n",
        "    df.set_index('Sites', inplace=True)\n",
        "\n",
        "    #filtering by new sites\n",
        "    df = df[df[tw_index].isin(new_site)]\n",
        "\n",
        "    # Save information os sites with demerged date more than current date\n",
        "    df[bill_col] = pd.to_datetime(df[bill_col], format='%d/%m/%Y', errors='coerce')\n",
        "    df_site_bts = df[(df[bts_col]=='Yes')&(df[bill_col] > current_date)].fillna('')\n",
        "    df_site_bts[bill_col] = list(map(lambda x: f'{x:%d/%m/%Y}', df_site_bts[bill_col]))\n",
        "    df_site_bts = df_site_bts[[tw_index,status_col, bts_col, bill_col]]\n",
        "    \n",
        "    #if not (new_sites.empty or bts_out_uis.empty or df_site_bts.empty):\n",
        "    return new_sites, df_site_bts[[tw_index,status_col, bts_col, bill_col]]\n",
        "\n",
        "new_sites, df_bts_errors = check_new_sites(towerdb, tw_index, tw_bts, tw_bill,tw_status, msa_sites, tw_sites, uip_sites)\n",
        "\n",
        "print(new_sites)\n",
        "print(df_bts_errors)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U5IfkxQgsXF"
      },
      "source": [
        "Check UIP sites with towerDB\n",
        "Some countries doesn't have decommissioned column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a4GVzcUvLC3",
        "outputId": "c895baec-3986-40dc-f214-fc3997b7b687"
      },
      "source": [
        "\"\"\" Wip Sites Check\"\"\"\n",
        "def check_wip(df_tw,tw_index, wip_tw, tw_bts, tw_status, df_msa, msa_index, wip_msa_col):\n",
        "\n",
        "    wip_msa = [i for i in df_msa[df_msa[msa_wip]=='Yes'][msa_index]]\n",
        "    \n",
        "    tw_wip_sites = [str(i) for i in df_tw[df_tw[wip_tw]=='Yes'][tw_index]]\n",
        "\n",
        "    tw_wip_site_bts_flagged = df_tw[(df_tw[wip_tw]=='Yes')&(df_tw[tw_bts]=='Yes')]\n",
        "    tw_wip_site_bts_flagged = tw_wip_site_bts_flagged[[tw_index, wip_tw, tw_bts]]\n",
        "    \n",
        "    #wip_out_tw_list = [i for i in tw_wip_sites if i not in wip_msa]\n",
        "    return tw_wip_site_bts_flagged\n",
        "\n",
        "df_wip_and_bts_flagged = check_wip(towerdb,tw_index, tw_wip, tw_bts,tw_status, msa, msa_index, msa_wip)\n",
        "\n",
        "print(df_wip_and_bts_flagged)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [code, wip_site, bts_site]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBHGWYYwviY3"
      },
      "source": [
        "#Coluna Doer tem valores fora do formato\n",
        "def check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col):\n",
        "    t = type_col.lower()\n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "        \n",
        "    if t == 'doer':\n",
        "        df_tw[date_col]= pd.to_datetime(df_tw[date_col], format='%d/%m/%Y', errors='coerce')\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&((df_tw[date_col] < current_date)|(df_tw[date_col]==''))]\n",
        "        filtered[date_col] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[date_col]))\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "    else:\n",
        "\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&(df_tw[date_col]=='')]\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "\n",
        "actives = towerdb[towerdb[tw_status]=='In Service']\n",
        "df_doer = check_tw_bill_doer(actives, tw_index, tw_doer, tw_status, 'In Service', 'doer')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "0n_Qsoyiy8gt",
        "outputId": "340d82a1-d0a4-463a-f614-80ae9ab3a414"
      },
      "source": [
        "#Retorna os sites novos\n",
        "def check_bts(df_tw, bts_tw_columns, tw_index, status_col, df_msa, bts_msa_column, msa_index):\n",
        "\n",
        "    bts_msa = [i for i in msa[msa[bts_msa_column]=='Yes'][msa_index]]\n",
        "    tw_bts_sites = [i for i in df_tw[df_tw[bts_tw_columns]=='Yes'][tw_index]]\n",
        "    #return of datas\n",
        "    bts_out_tw = [i for i in bts_msa if i not in tw_bts_sites]\n",
        "    filtered = df_msa.loc[df_msa[tw_index].isin(bts_out_tw), [tw_index, status_col, bts_tw_columns]]\n",
        "    return filtered\n",
        "\n",
        "df_bts_out = check_bts(towerdb, tw_bts, tw_index, tw_status, msa, msa_bts, msa_index)\n",
        "df_bts_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>active / not active</th>\n",
              "      <th>bts_site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [code, active / not active, bts_site]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye6Vdrpyg7tJ"
      },
      "source": [
        "def check_uip_tw(df_tw,tw_index, status_tw_col, tw_bts_col, tw_critical_col, df_uip, uip_sites):\n",
        "\n",
        "    filtered = df_tw[[tw_index, status_tw_col, tw_bts_col]]\n",
        "    #tw_active = df_tw[df_tw['Site Status']=='In Service']\n",
        "    count_tw_sites = [str(i) for i in df_tw[df_tw[status_tw_col] =='In Service'][tw_index]]\n",
        "\n",
        "    # check number of sites that are in uip file and doesn't have in df_tw\n",
        "    #if not set(count_tw_sites).intersection(uip_sites):\n",
        "    uis_sites_not_in_towerdb = [i for i in uip_sites if i not in count_tw_sites]\n",
        "\n",
        "    uis_sites_not_in_towerdb = pd.DataFrame(uis_sites_not_in_towerdb,columns=['UIS In Month not active in TowerDB!'])\n",
        "    uis_sites_not_in_towerdb = pd.merge(uis_sites_not_in_towerdb, filtered, how='left', left_on='UIS In Month not active in TowerDB!',\\\n",
        "                                    right_on=tw_index)\n",
        "    uis_sites_not_in_towerdb = uis_sites_not_in_towerdb[['UIS In Month not active in TowerDB!', status_tw_col]]\n",
        "\n",
        "    in_service_not_in_uis = [i for i in count_tw_sites if i not in uip_sites]\n",
        "    in_service_not_in_uis = pd.DataFrame(in_service_not_in_uis,columns=['TowerDB Sites out of UIS In Month!'])\n",
        "    in_service_not_in_uis = pd.merge(in_service_not_in_uis, filtered, how='left', left_on='TowerDB Sites out of UIS In Month!',\\\n",
        "                                    right_on=tw_index)\n",
        "    in_service_not_in_uis = in_service_not_in_uis[['TowerDB Sites out of UIS In Month!', status_tw_col]]\n",
        "    #check for decomissioned site not in uip files\n",
        "\n",
        "    #Check BTS sites\n",
        "        #Check BTS sites\n",
        "    bts_sites = [str(i) for i in df_tw[df_tw[tw_bts_col]=='Yes'][tw_index]]\n",
        "    uip_bts = [i for i in df_uip[df_uip['BTS site applicable charge (Annual)']!='']['Site_ID']]\n",
        "    bts_sites_out_uip = [i for i in uip_bts if i not in bts_sites]\n",
        "    bts_sites_out_uip = pd.DataFrame(bts_sites_out_uip, columns=['UIS BTS not in TowerDB(BTS)'])\n",
        "    bts_sites_out_uip = pd.merge(bts_sites_out_uip, filtered, how='left', left_on='UIS BTS not in TowerDB(BTS)',\\\n",
        "                                    right_on=tw_index)\n",
        "    bts_sites_out_uip = bts_sites_out_uip[['UIS BTS not in TowerDB(BTS)', status_tw_col, tw_bts_col]]\n",
        "\n",
        "    #  Check for UIP critical sites \n",
        "    uip_critical = [i for i in df_uip[df_uip['Commercials for sites beyond 10% cap of critical sites (Annual)']!=0]['Site_ID']]\n",
        "    bts_tw_critical = df_tw[df_tw[tw_critical_col]=='Yes'][tw_index]\n",
        "\n",
        "    critical = [i for i in uip_critical if i not in bts_tw_critical]\n",
        "    critical = pd.DataFrame(critical, columns=['Critical site(beyond 10%) out of UIS'])\n",
        "    critical = pd.merge(critical, filtered, how='left', left_on='Critical site(beyond 10%) out of UIS',right_on=tw_index)\n",
        "    critical = critical[['Critical site(beyond 10%) out of UIS', status_tw_col]]\n",
        "    #if not (in_service_uip_sites.empty or decomiss_sites_in_uip.empty or bts_sites_out_uip.empty or critical.empty):\n",
        "    return uis_sites_not_in_towerdb, in_service_not_in_uis, bts_sites_out_uip, critical\n",
        "   \n",
        "#(df_tw,tw_index, status_tw_col, decom_col, tw_bts_col, tw_critical_col, df_uip, uip_sites)\n",
        "uis_sites_not_in_towerdb, in_service_not_in_uis, bts_sites_out_uip, critical = check_uip_tw(towerdb,tw_index, tw_status, tw_bts,tw_critical,\\\n",
        "                                                                 uip, uip_sites)\n",
        "print(uis_sites_not_in_towerdb)\n",
        "print('\\n')\n",
        "print(in_service_not_in_uis)\n",
        "print('\\n')\n",
        "print(critical)\n",
        "#no errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFe-T0eRkaLU"
      },
      "source": [
        "Commercial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XNsmrtTkbe8"
      },
      "source": [
        "def check_commercial(path_current, path_before, col_replace, col_names, merge_cols, col_order):\n",
        "    \n",
        "    def replace_values(df, columns, value=\"\"):\n",
        "        \"\"\"\n",
        "        Está voltando para float\n",
        "        \"\"\"\n",
        "        invalid_values = ['N/A', 'n/a',\"0\", '-', '_', np.nan,'nan']\n",
        "        #lista = []\n",
        "\n",
        "        df.fillna(\"\", inplace=True)\n",
        "        #df[column] = df[column].astype('int64')\n",
        "\n",
        "        for column in columns:\n",
        "            lista = []\n",
        "            for index in df[column]:\n",
        "                #print(f\"{column} -> {index}\")\n",
        "                if index in invalid_values:\n",
        "                    lista.append(value)\n",
        "                else:\n",
        "                    lista.append(index)\n",
        "            df[column] = lista\n",
        "\n",
        "        return df    \n",
        "    \n",
        "    def check_uip_commercial_values(df_actual, df_before, merge_cols):\n",
        "        df_atual = uip_comercial_actual\n",
        "        df_ant = uip_comercial_before\n",
        "        df_cross = pd.merge(df_actual, df_before, on=merge_cols, \\\n",
        "                            how='left', suffixes=('_actual', '_before'), indicator='Exist')\n",
        "        df_cross['Exist'] = np.where(df_cross.Exist == 'both', 'Yes', 'No')\n",
        "        df_cross['Equal Values'] = df_cross['Exist']\n",
        "        \n",
        "        return df_cross\n",
        "    \n",
        "    # Check for commercial Values into current UIP File and compare with UIP File before\n",
        "    uip_comercial_actual = pd.read_excel(path_current,sheet_name='Commercial', names=col_names).fillna('')\n",
        "    #uip_comercial_actual = uip_comercial_actual[['Charge_Type', 'Data_Type', 'Input_Value']]\n",
        "    uip_comercial_actual = replace_values(uip_comercial_actual, col_replace, value=0)\n",
        "\n",
        "    uip_comercial_before = pd.read_excel(path_before,sheet_name='Commercial', names=col_names ).fillna('')\n",
        "    #uip_comercial_before = uip_comercial_before[['Charge_Type', 'Data_Type', 'Input_Value']]\n",
        "    uip_comercial_before = replace_values(uip_comercial_before, col_replace, value=0)\n",
        "\n",
        "    df_commercial =  check_uip_commercial_values(uip_comercial_actual, uip_comercial_before, merge_cols).fillna('')\n",
        "\n",
        "    df_commercial = df_commercial.reindex(columns=col_order)\n",
        "    df_commercial_diffs = df_commercial[df_commercial['Equal Values']=='No']\n",
        "    if not df_commercial_diffs.empty:\n",
        "        return df_commercial_diffs\n",
        "    else:\n",
        "        print('\\nNo errors founded!')\n",
        "\n",
        "path_before = '/content/UserInput_Hungary_20210731.xlsx'\n",
        "names = ['Charge_Type','Sub_Charge_Type', 'Param1','Param2', 'Data_Type', 'Input_Value',\\\n",
        "        'Description/Instruction', 'Frequency of Update']\n",
        "merge_cols = ['Charge_Type','Sub_Charge_Type', 'Param1','Param2', 'Data_Type', \\\n",
        "              'Description/Instruction', 'Frequency of Update']\n",
        "cols_ordered = ['Charge_Type','Sub_Charge_Type', 'Param1','Param2','Data_Type','Input_Value_actual',\\\n",
        "                'Input_Value_before','Equal Values','Description/Instruction','Frequency of Update']\n",
        "col_replaced = ['Input_Value']\n",
        "df_commercial_diffs = check_commercial(path_uip, path_before,col_replaced, names, merge_cols, cols_ordered)\n",
        "#df_commercial_diffs = check_commercial(path_uip, path_before, replace_values, names, merge_cols, cols_ordered)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzYvxx5wnuh8"
      },
      "source": [
        "Excel Log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYdE0UzCnq5h"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "df_list = [\n",
        "    ['In Service Date Errors',actives_dates_errors],\n",
        "    ['Dismantled Dates Errors',no_actives_dates_errors],\n",
        "    ['General Picklist Errors',df_general_pick],\n",
        "    ['In Service Picklist Errors',df_in_service_picklist],\n",
        "    ['Actives Blank Dates',df_in_service_dates],\n",
        "    ['Bill Dates Errors',df_bts_empty],\n",
        "    ['New Sites',new_sites],\n",
        "    ['New Sites Bill date errors',df_bts_errors],\n",
        "    ['WIP & BTS Flagged',df_wip_and_bts_flagged],\n",
        "    ['DOER Dates Errors',df_doer],\n",
        "    ['UIS In Month not active',uis_sites_not_in_towerdb],\n",
        "    ['TowerDB Sites out of UIS',in_service_not_in_uis],\n",
        "    ['Critical Sites out UIS',critical],\n",
        "    ['Commercial Differences',df_commercial_diffs]]\n",
        "path = '/content/HU_towerdb_errors.xlsx'\n",
        "general_log_erros(df_list, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymaR9uoioRBC"
      },
      "source": [
        "TA Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rmiiDZxoLr0"
      },
      "source": [
        "def replace_values(df, columns, value=\"\"):\n",
        "    \"\"\"\n",
        "    Está voltando para float\n",
        "    \"\"\"\n",
        "    invalid_values = ['N/A', 'n/a',\"0\", '-', '_', np.nan,'nan', ' ']\n",
        "\n",
        "    for column in columns:\n",
        "        lista = []\n",
        "        df[column] = df[column].fillna(0)\n",
        "        for index in df[column]:\n",
        "            #print(f\"{column} -> {index}\")\n",
        "            if index in invalid_values:\n",
        "                lista.append(value)\n",
        "            else:\n",
        "                lista.append(index)\n",
        "        df[column] = lista\n",
        "    return df\n",
        "\n",
        "def date_parser(df, columns,format='mix', type_date=\"%d/%m/%Y\"):\n",
        "    for column in columns:\n",
        "        if format == 'mix':\n",
        "            df[column] = [date_obj.strftime(type_date) if not pd.isnull(date_obj) \\\n",
        "                        and not isinstance(date_obj, str) else date_obj for date_obj in df[column]]\n",
        "            df[column] = df[column].astype(str)\n",
        "        else:\n",
        "            df[column] = [date_obj.strftime(type_date) if not pd.isnull(date_obj) else '' for date_obj in df[column]]\n",
        "            df[column] = df[column].astype(str)\n",
        "ta_ord = ['SiteID','SiteID.1','In/out of scope','Tenant Agreement ID','Agreement relates to DAS site?','Tenant (name/ID)',\\\n",
        "          'Classification','MNO classification','Base fee (@ signing) in HUF','Additional fee (@ signing) in HUF',\\\n",
        "          'Annual Fee per Tenant (@ signing) in HUF','Annual Energy Fee  (@ signing)','Annual Maintenance Fee  (@ signing)',\\\n",
        "          'Other Services Fee  (@ signing)','Base fee in HUF','Additional fee in HUF','Current Annual Fee per Tenant in HUF',\\\n",
        "          'Current Annual Energy Fee in HUF','Starting date','Expiring date (raw data)','Expiring date (in practice)',\\\n",
        "          'Renewal Option','Expiring date after renewal','Terms of payments','Payment type','Index','Percentage','Indexation driver',\n",
        "          'VAT Suject','Percentage (VAT)','Termination Date','Residual duration']\n",
        "          \n",
        "ta_leases = ['Tenant Agreement ID','MNO classification', 'Base fee (@ signing) in HUF', 'Starting date',\n",
        "       'Expiring date (raw data)', 'Expiring date (in practice)']\n",
        "dates_ta = ['Starting date','Expiring date (raw data)', 'Expiring date (in practice)']\n",
        "pathta = '/content/TA_Input_Hungary_20210831.csv'\n",
        "ta = pd.read_csv(pathta,  encoding='latin').fillna('')\n",
        "#ta = replace_values(ta,ta_leases, '')\n",
        "#i != '0' or i!= \"\" and not \n",
        "lista = []\n",
        "for i in ta['Base fee (@ signing) in HUF']:\n",
        "    cur = re.compile('\\d{1,3}(?:,\\d{3})')\n",
        "    if cur.match(str(i)) == None :\n",
        "        new_i = int(i)\n",
        "        new_i = f'{new_i:,d}'\n",
        "        lista.append(new_i)\n",
        "    else:\n",
        "        lista.append(i)\n",
        "ta['Base fee (@ signing) in HUF'] = lista\n",
        "\n",
        "#No erros\n",
        "for col in ['Starting date','Expiring date (raw data)', 'Expiring date (in practice)']:\n",
        "    ta[col] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) \\\n",
        "                        and not isinstance(date_obj, str) else date_obj for date_obj in ta[col]]\n",
        "ta['Expiring date (raw data)'] = ta['Expiring date (raw data)'].fillna(0)\n",
        "ta['Expiring date (raw data)'] = ta['Expiring date (raw data)'].replace(0, '')\n",
        "ta['Payment type'] = ta['Payment type'].replace('', 0).astype(int)\n",
        "ta = ta[ta_ord]\n",
        "\n",
        "ta = ta.rename(columns={'SiteID.1':'SiteID'})\n",
        "ta.to_csv('/content/TA_Input_Hungary_20210831_celfinet.csv', index=False, encoding='latin')\n",
        "ta.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "pRFhSERZLgtW",
        "outputId": "976bc941-62b5-4e5f-e059-8f4b5e6ae990"
      },
      "source": [
        "import datetime as dt\n",
        "#Create dates in datetime format\n",
        "lista = []\n",
        "for i in ta['Expiring date (raw data)']:\n",
        "    try:\n",
        "        if i != \"\":\n",
        "            lista.append(pd.to_datetime(i, format='%d/%m/%Y'))\n",
        "        else:\n",
        "            lista.append(datetime(1999, 1, 1, 0, 0, 0))\n",
        "    except:\n",
        "        lista.append(datetime(2199, 1, 1, 0, 0, 0))\n",
        "\n",
        "ta['end'] = lista\n",
        "ta['start'] = [pd.to_datetime(i, format='%d/%m/%Y') if i!= '' else datetime(1999, 1, 1, 0, 0, 0) for i in ta['Starting date']]\n",
        "#Create diff columns to get negative values\n",
        "ta['dt_dff'] = (ta['end'] - ta['start']).dt.days\n",
        "\n",
        "start_or_end_blank = (ta['Starting date']=='')|(ta['Expiring date (raw data)']=='')\n",
        "negative_dates = (ta['dt_dff'] <= 0)\n",
        "cols = ['SiteID', 'Starting date', 'Expiring date (raw data)']\n",
        "ta_dates_errors = ta[start_or_end_blank|negative_dates][cols]\n",
        "ta_dates_errors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SiteID</th>\n",
              "      <th>SiteID</th>\n",
              "      <th>Starting date</th>\n",
              "      <th>Expiring date (raw data)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [SiteID, SiteID, Starting date, Expiring date (raw data)]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWwqiisJeU82"
      },
      "source": [
        "def check_amounts(df, df_index, columns, pattern=','):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_am = df[columns].fillna('')\n",
        "    df_am = df_am.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "\n",
        "    for column in set(df_am.keys()):\n",
        "        for value in df_am[column]:\n",
        "            if not str(value).__contains__(pattern):\n",
        "                if value in (None, '', 'nan'):\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                elif value == '0':\n",
        "                    new_dic[column].append('Input 0')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorret picklist value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok', np.nan)\n",
        "    df_errors[df_index] = df[df_index]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "    #df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "#Drop duplicate of SiteID\n",
        "ta = ta.T.drop_duplicates().T\n",
        "ta_amount = check_amounts(ta, 'SiteID',['Base fee (@ signing) in HUF'])\n",
        "ta_amount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF4zyjT9T94P"
      },
      "source": [
        "df_class_error = ta[(ta['MNO classification']=='')|~(ta['MNO classification'].isin(['MNO 1','MNO 2','MNO 3', 'OTMO']))][['SiteID', 'MNO classification']]\n",
        "df_class_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YYgq-GniEOC"
      },
      "source": [
        "Ta Log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppX4tzj6iF7H"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "ta_s = [['Dates Errors',ta_dates_errors],\n",
        "        ['Amount Errors', ta_amount],\n",
        "        ['Picklist Errors', df_class_error]]\n",
        "path_ta_log = '/content/TA_HU_errors.xlsx'\n",
        "general_log_erros(ta_s, path_ta_log)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcStV100sgVb"
      },
      "source": [
        "LC Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uiUvmkQsyar"
      },
      "source": [
        " #separador virgulas\n",
        "pathlc = '/content/LC_Input_Hungary_20210831.csv'\n",
        "\n",
        "lc_ord = ['Code','Code.1','In/out of scope','Lease Contract ID','Counterpart','Annual lease fees (@ signing) in HUF',\n",
        "          'Annual lease fees (@ signing) in Original currency','Contract currency','Energy fee (@ signing)',\n",
        "          'Other fees  (@ signing)','Current annual lease fees in HUF','Current annual lease fees in original curency',\n",
        "          'Contract currency','Current Energy fee','Current other fees','Sub-lease','# of renegotiation','Starting date',\n",
        "          'Expiring date (raw data)','Expiring date (in practice)','Renewal Option','Expiring date after renewal',\n",
        "          'Terms of payments (days)','Payment type (number of payments per year)','Some period already prepaid','Indexation',\n",
        "          'Indexation Percentage','Indexation driver','VAT Suject','Percentage (VAT)','Termination Date','# of years of renewal',\n",
        "          '# of months of renewal','Type of contrac','Lease renewal (years)','Residual duration']\n",
        "\n",
        "lc = pd.read_csv(pathlc,  encoding='latin').fillna('')\n",
        "lc = lc[lc_ord]\n",
        "leases = ['Current annual lease fees in HUF']\n",
        "lc = replace_values(lc,leases, '')\n",
        "\n",
        "lc_cols = ['Code', 'Current annual lease fees in HUF'] \n",
        "\n",
        "lc = lc.rename(columns={'Code.1': 'Code'})\n",
        "lc.to_csv('/content/LC_Input_Hungary_20210831_celfinet.csv', index=False, encoding='latin')\n",
        "lc.head(2)\n",
        "#No erros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku1kPAVYiZnN"
      },
      "source": [
        "def check_amounts(df, df_index, columns, pattern=','):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_am = df[columns].fillna('')\n",
        "    df_am = df_am.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "\n",
        "    for column in set(df_am.keys()):\n",
        "        for value in df_am[column]:\n",
        "            if not str(value).__contains__(pattern):\n",
        "                if value in (None, '', 'nan'):\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                elif value == '0':\n",
        "                    new_dic[column].append('Input 0')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorret picklist value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok', np.nan)\n",
        "    df_errors[df_index] = df[df_index]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "    #df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "#Drop duplicate of SiteID\n",
        "lc = lc.T.drop_duplicates().T\n",
        "df_lc_amount = check_amounts(lc, 'Code', leases)\n",
        "df_lc_amount\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "25JhrbyIrCJd",
        "outputId": "c8740f73-c9dd-4404-fc37-29cc09a9b17c"
      },
      "source": [
        "import datetime as dt\n",
        "#Create dates in datetime format\n",
        "lista = []\n",
        "for i in lc['Expiring date (raw data)']:\n",
        "    try:\n",
        "        if i != \"\":\n",
        "            lista.append(pd.to_datetime(i, format='%d/%m/%Y'))\n",
        "        else:\n",
        "            lista.append(datetime(1999, 1, 1, 0, 0, 0))\n",
        "    except:\n",
        "        lista.append(datetime(2199, 1, 1, 0, 0, 0))\n",
        "\n",
        "lc['end'] = lista\n",
        "lc['start'] = [pd.to_datetime(i, format='%d/%m/%Y') if i!= '' else datetime(1999, 1, 1, 0, 0, 0) for i in lc['Starting date']]\n",
        "#create diff columns to get negative values\n",
        "lc['dt_dff'] = (lc['end'] - lc['start']).dt.days\n",
        "\n",
        "start_or_end_blank = (lc['Starting date']=='')|(lc['Expiring date (raw data)']=='')\n",
        "negative_dates = (lc['dt_dff'] <= 0)\n",
        "cols = ['Code', 'Starting date', 'Expiring date (raw data)']\n",
        "lc_dates_errors = lc[start_or_end_blank|negative_dates][cols]\n",
        "\n",
        "df_lc_amount\n",
        "lc_dates_errors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Starting date</th>\n",
              "      <th>Expiring date (raw data)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Code, Starting date, Expiring date (raw data)]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdWu7oEOke54"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "df_lc = [['Amount Errors', df_lc_amount],\n",
        "         ['Dates Errors', lc_dates_errors]]\n",
        "\n",
        "general_log_erros(df_lc,'/content/LC_HU_errors.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z21mNDGcrv8Q"
      },
      "source": [
        "UIS Comparioson"
      ]
    }
  ]
}