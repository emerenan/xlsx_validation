{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "es_validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBUSe157QlEACHVwcHznin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emerenan/xlsx_validation/blob/main/es_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4FndupnMVhY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "def lower_str(columns):\n",
        "    newlist = list(map(lambda x: x.lower(), columns))\n",
        "    return newlist\n",
        "\n",
        "def change_incorret(df, df_index, col_chg, incorrect_value, new_value):\n",
        "    list_sites = list(df[df[col_chg]==incorrect_value][df_index])\n",
        "    df.loc[df[df_index].isin(list_sites), col_chg] = new_value\n",
        "\n",
        "def check_lc_ta_dates(df,tw_index, start_date,end_date):\n",
        "    df[start_date] = pd.to_datetime(df[start_date])\n",
        "    df[end_date] = pd.to_datetime(df[end_date], errors='coerce')\n",
        "    filtered = df.loc[pd.to_datetime(df[start_date]) > df[end_date], [tw_index, start_date,end_date]]\n",
        "    print(filtered)\n",
        "    if not filtered.empty:\n",
        "        return filtered[[tw_index, start_date,end_date]]\n",
        "    else:\n",
        "        print('\\nNo Errors Founded!\\n')\n",
        "\n",
        "def check_commercial(path_current, path_before, col_replace, col_names, merge_cols, col_order):\n",
        "    \n",
        "    def check_uip_commercial_values(df_actual, df_before, merge_cols):\n",
        "        df_atual = uip_comercial_actual\n",
        "        df_ant = uip_comercial_before\n",
        "        df_cross = pd.merge(df_actual, df_before, on=merge_cols, \\\n",
        "                            how='left', suffixes=('_actual', '_before'), indicator='Exist')\n",
        "        df_cross['Exist'] = np.where(df_cross.Exist == 'both', 'Yes', 'No')\n",
        "        df_cross['Equal Values'] = df_cross['Exist']\n",
        "        \n",
        "        return df_cross\n",
        "    # Check for commercial Values into current UIP File and compare with UIP File before\n",
        "    uip_comercial_actual = pd.read_excel(path_current,sheet_name='Commercial', names=col_names)\n",
        "    #uip_comercial_actual = uip_comercial_actual[['Charge_Type', 'Data_Type', 'Input_Value']]\n",
        "    uip_comercial_actual = replace_values(uip_comercial_actual, col_replace, value=0)\n",
        "\n",
        "    uip_comercial_before = pd.read_excel(path_before,sheet_name='Commercial', names=col_names )\n",
        "    #uip_comercial_before = uip_comercial_before[['Charge_Type', 'Data_Type', 'Input_Value']]\n",
        "    uip_comercial_before = replace_values(uip_comercial_before, col_replace, value=0)\n",
        "\n",
        "    df_commercial =  check_uip_commercial_values(uip_comercial_actual, uip_comercial_before, merge_cols)\n",
        "\n",
        "    df_commercial = df_commercial.reindex(columns=col_order)\n",
        "    df_commercial_diffs = df_commercial[df_commercial['Equal Values']=='No']\n",
        "    return df_commercial_diffs\n",
        "\n",
        "def general_log_erros(df_list, sheet_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')   \n",
        "    for dataframe, sheet in zip(df_list, sheet_list):\n",
        "        dataframe.to_excel(writer, sheet_name=sheet, startrow=0 , startcol=0)   \n",
        "    writer.save() \n",
        "\n",
        "def find_diffs_between_files(path_OLD, path_NEW, index_col, bill_cols, \\\n",
        "                             status_col, path_save, old_file, new_file, type_file='mix',kind='tw', sheetname='', skipr=0, skipc=0):\n",
        "    \n",
        "    def lower_str(columns):\n",
        "        newlist = list(map(lambda x: x.lower(), columns))\n",
        "        return newlist\n",
        "\n",
        "    def fit_df(df, bill_cols):\n",
        "        fit_cols = lower_str(list(df.columns))\n",
        "        df.columns = fit_cols\n",
        "        df = df[bill_cols]\n",
        "        df = df.dropna(subset=[index_col], axis=0)\n",
        "        df = df.drop_duplicates(subset=[index_col], keep='last')\n",
        "        df[index_col] = df[index_col].astype(str)\n",
        "        df['sites'] = df[index_col]\n",
        "        # Aqui ajusta os nan e nat dos DFs, quando não forem arquivos não lidos\n",
        "        df = df.set_index('sites').fillna('')\n",
        "        return df\n",
        "        \n",
        "    def change_format(index, worksheet, format):\n",
        "        for cell in worksheet[f\"{str(index)}:{str(index)}\"]:\n",
        "            cell.font = format\n",
        "\n",
        "    bill_cols = lower_str(bill_cols)\n",
        "    index_col = index_col.lower()\n",
        "    type_file = type_file.lower()\n",
        "    status_col = status_col.lower()\n",
        "    if type_file == 'excel':\n",
        "        df_OLD = pd.read_excel(path_OLD,sheet_name = sheetname, skiprows = skipr).fillna('')\n",
        "        df_OLD = df_OLD.iloc[:,skipc:]\n",
        "        df_OLD = fit_df(df_OLD,bill_cols)\n",
        "\n",
        "        df_NEW = pd.read_excel(path_NEW,sheet_name = sheetname, skiprows = skipr).fillna('')\n",
        "        df_NEW = df_NEW.iloc[:,skipc:]\n",
        "        df_NEW = fit_df(df_NEW,bill_cols)\n",
        "\n",
        "    elif type_file == 'csv':\n",
        "        df_OLD = pd.read_csv(path_OLD, encoding='latin').fillna('')\n",
        "        df_OLD = fit_df(df_OLD,bill_cols)\n",
        "\n",
        "        df_NEW = pd.read_csv(path_NEW, encoding='latin').fillna('')\n",
        "        df_NEW = fit_df(df_NEW,bill_cols)\n",
        "\n",
        "    elif type_file == 'mix':\n",
        "        df_OLD = pd.read_csv(path_OLD, encoding='latin')\n",
        "        df_OLD = fit_df(df_OLD,bill_cols)\n",
        "\n",
        "        df_NEW = pd.read_excel(path_NEW,sheet_name = sheetname, skiprows = skipr)\n",
        "        df_NEW = df_NEW.iloc[:,skipc:]\n",
        "        df_NEW = fit_df(df_NEW,bill_cols)\n",
        "    else: \n",
        "        df_OLD = fit_df(path_OLD,bill_cols)\n",
        "        df_NEW = fit_df(path_NEW,bill_cols)\n",
        "\n",
        "\n",
        "    # Perform Diff\n",
        "    new_copy = df_NEW.copy()\n",
        "    droppedRows = []\n",
        "    newRows = []\n",
        "\n",
        "    cols_OLD = df_OLD.columns\n",
        "    cols_NEW = df_NEW.columns\n",
        "    sharedCols = list(set(cols_OLD).intersection(cols_NEW))\n",
        "\n",
        "    for row in new_copy.index:\n",
        "        if (row in df_OLD.index) and (row in df_NEW.index):\n",
        "            for col in sharedCols:\n",
        "                value_OLD = df_OLD.loc[row,col]\n",
        "                value_NEW = df_NEW.loc[row,col]\n",
        "               #Error de a.empty() são sites duplcados e nã poodem estar no index\n",
        "                if value_OLD == value_NEW:\n",
        "                    new_copy.loc[row,col] = np.nan\n",
        "                else:\n",
        "                    new_copy.loc[row,col] = f'{value_OLD} > {value_NEW}'\n",
        "        else:\n",
        "            newRows.append(row)\n",
        "\n",
        "    new_copy = new_copy.dropna(axis=0, how='all')\n",
        "    new_copy = new_copy.dropna(axis=1, how='all')\n",
        "\n",
        "    for row in df_OLD.index:\n",
        "        if row not in df_NEW.index:\n",
        "            droppedRows.append(row)\n",
        "            new_copy = new_copy.append(df_OLD.loc[row,:])\n",
        "    \n",
        "    new_copy = new_copy.sort_index(key=lambda x: x.str.lower()).fillna('')\n",
        "    \n",
        "    new_copy = new_copy.reset_index()\n",
        "    if kind=='tw':\n",
        "        sites = [i for i in new_copy['sites']] \n",
        "        old = df_OLD[[status_col]].reset_index()\n",
        "        old = old.loc[old['sites'].isin(sites)]\n",
        "        new = df_NEW[[status_col]].reset_index()\n",
        "        new = new.loc[new['sites'].isin(sites)]\n",
        "        df_cross = pd.merge(new, old, on=['sites'], how='inner', suffixes=('_current', '_before'))\n",
        "        new_copy = pd.merge(new_copy, df_cross, on=['sites'], how='left')\n",
        "\n",
        "\n",
        "    print(f'\\nNew Rows:     {newRows}')\n",
        "    print(f'Dropped Rows: {droppedRows}')\n",
        "\n",
        "    # Save output and format\n",
        "    fname = f'{path_save} - ({old_file}) vs ({new_file}).xlsx'\n",
        "    file = pd.ExcelWriter(fname, engine='openpyxl')\n",
        "    \n",
        "    new_copy.to_excel(file, sheet_name='diffs_founded', index=False)\n",
        "    df_NEW.to_excel(file, sheet_name='new_file', index=False)\n",
        "    df_OLD.to_excel(file, sheet_name='old_file', index=False)\n",
        "\n",
        "    # get openpyxl objects\n",
        "    wb  = file.book\n",
        "    ws = file.sheets['diffs_founded']\n",
        "    \n",
        "    red_fill = PatternFill(start_color='95A7B3', \\\n",
        "                                end_color='95A7B3', fill_type='solid')\n",
        "    red_font = Font(color='00FF0000', italic=True)\n",
        "    new_fmt = Font(color='3F976D',bold=True, italic=True)\n",
        "    removed = Font(color='95A7B3',bold=True, italic=True)\n",
        "\n",
        "    dxf = DifferentialStyle(font=red_font, fill=red_fill)\n",
        "    highlight = Rule(type=\"containsText\", operator=\"containsText\", text=\">\", dxf=dxf)\n",
        "    highlight.formula = ['SEARCH(\">\", A1)']\n",
        "    ws.conditional_formatting.add('A1:ZZ1000', highlight)\n",
        "    \n",
        "     \n",
        "    #print(len(newRows))\n",
        "    for site in new_copy['sites']:\n",
        "        if site in newRows:\n",
        "            idx = new_copy.index[new_copy[index_col]==site].to_list()\n",
        "            idx = list(map(lambda x: x+2, idx))\n",
        "            change_format(*idx,ws,new_fmt)\n",
        "        if site in droppedRows:\n",
        "            idx = new_copy.index[new_copy[index_col]==site].to_list()\n",
        "            idx = list(map(lambda x: x+2, idx))\n",
        "            change_format(*idx,ws,removed)\n",
        "    \n",
        "    wb.save(fname)\n",
        "    print('\\nDone.\\n')\n",
        "\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "187ZOjvNX27i"
      },
      "source": [
        "Looking for differences betwwnn older and newest files in towerdb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMNqI3p4S8M1"
      },
      "source": [
        "Adding new columns for UIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lulong55S_QC"
      },
      "source": [
        "# Lendo o Ficheiro de input\n",
        "path_uip=''\n",
        "sheet = 'SiteLevel'\n",
        "site_level = pd.read_excel(path_uip,sheet, header=[0,1,2])\n",
        "\n",
        "head_1 = pd.MultiIndex.from_product([[''],['Numeric (in months)'],['Delay in Site Modification Projects', 'Delay in BTS Projects']])\n",
        "df_1 = pd.DataFrame(columns=head_1)\n",
        "\n",
        "head_2 = pd.MultiIndex.from_product([[''],['Numeric (in €)'],['Excess of Upgrade Capital Expenditure over Threshold']])\n",
        "df_2 = pd.DataFrame(columns=head_2)\n",
        "\n",
        "site_level = pd.concat([site_level, df_1, df_2], axis=1)\n",
        "site_level.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFXAXm2TPPu2"
      },
      "source": [
        "Doing all checks in Towerdb File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV5q5ZwHQAgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ff23ec-86f9-4875-89ef-a07286752732"
      },
      "source": [
        "def read_files(path, sheetname, n_skiprows, n_skip_columns, site_index):\n",
        "\n",
        "    df = pd.read_excel(path, sheet_name = sheetname, skiprows = n_skiprows)\n",
        "\n",
        "    df = df.iloc[:,n_skip_columns:]\n",
        "\n",
        "    df = df.dropna(subset=[site_index], axis=0)\n",
        "\n",
        "    return df\n",
        "\n",
        "pathtw = '/content/TowerDB_Spain_20210809.xlsx'\n",
        "sheet= 'Enhanced TowerDB'\n",
        "skipr = 7\n",
        "skipc = 3\n",
        "towerdb = read_files(pathtw, sheet, skipr, skipc, 'Code')\n",
        "towerdb = towerdb.rename(columns={'Categorization by Transmission Sys.1': 'Categorization by Transmission Sys_1'})\n",
        "#towerdb.columns = lower_str(list(towerdb.columns))\n",
        "\n",
        "\n",
        "pathmsa = '/content/TowerDB_Spain_20210731.csv'\n",
        "msa = pd.read_csv(pathmsa, encoding='latin')\n",
        "#msa.columns = lower_str(list(msa.columns))\n",
        "\n",
        "col_order = list(msa.columns)\n",
        "\n",
        "towerdb = towerdb[col_order]\n",
        "#towerdb = towerdb.fillna('')\n",
        "\n",
        "ints = ['Inhabitants', 'Altitude', '# of Lease Contracts', 'ORANGE', 'Telefonica', 'YOIGO']\n",
        "for i in ints:\n",
        "    towerdb[i] = towerdb[i].fillna(0)\n",
        "    towerdb[i] = list(map(int, towerdb[i]))\n",
        "\n",
        "dates_tw = ['First_Active_Sharing_Start_Date', 'First_Active_Sharing_End_Date', 'Billing Trigger date']\n",
        "for i in dates_tw:\n",
        "    towerdb[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in towerdb[i]]\n",
        "    \n",
        "towerdb['Date of equipment removal (from MAR´21)'] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) and not isinstance(date_obj, str) else '' for date_obj in towerdb['Date of equipment removal (from MAR´21)']]\n",
        "\n",
        "change_incorret(towerdb, 'Code', 'Sites_As_Metered_Estimated', 'Estimated model', 'Estimated Model' )\n",
        "\n",
        "bill_cols = ['Code',\\\n",
        "             'Inhabitants',\\\n",
        "             'Categorization by Transmission Sys',\\\n",
        "             'Categorization by Site Type',\\\n",
        "             'Vodafone equipment giving Active Sharing to Orange',\\\n",
        "             'Bundled_Sites_Yes_No',\\\n",
        "\t\t\t 'Wip_Site',\\\n",
        "\t\t\t 'Region_For_Tax_Calculation',\\\n",
        "\t\t\t 'Indoor_Outdoor_Categorization',\\\n",
        "\t\t\t 'Bts_Site',\\\n",
        "\t\t\t 'Sites_As_Metered_Estimated',\\\n",
        "\t\t\t 'Indoor_Site_Any_Climate_Control',\\\n",
        "\t\t\t 'Outdoor_Site_With__Power',\\\n",
        "\t\t\t 'Bundled_Site_Categorization',\\\n",
        "\t\t\t 'Strategic_Site',\\\n",
        "\t\t\t 'Strategic_Site_Bucket',\\\n",
        "\t\t\t 'Critical_Site',\\\n",
        "\t\t\t 'CriticalSite_Beyond_10',\\\n",
        "\t\t\t 'Active_Sharing_Arrangement',\\\n",
        "\t\t\t 'Orange_Crossed_Site',\\\n",
        "\t\t\t 'Das_Classification',\\\n",
        "\t\t\t 'Macro_Core_Site_Yes_No',\\\n",
        "\t\t\t 'Macro_Transmission_Hub_Yes_No',\\\n",
        "\t\t\t 'Macro_Transmission_Hub_With_Shelters_Without_Shelters',\\\n",
        "\t\t\t 'Transmission_With_Shelters_Without_Shelters',\\\n",
        "\t\t\t 'Subsequent_Sharing_Arrangement',\\\n",
        "\t\t\t 'First_Active_Sharing_Deployment_Type',\\\n",
        "             'First_Active_Sharing_Start_Date',\\\n",
        "             'First_Active_Sharing_End_Date',\\\n",
        "\t\t\t 'Decommissioned_Site only for VF',\\\n",
        "\t\t\t 'Sites_Fall_Under_2400',\\\n",
        "\t\t\t 'Macro_CoreA_CoreB',\\\n",
        "\t\t\t 'Billing Trigger date']\n",
        "for i in bill_cols:\n",
        "    towerdb[i] = towerdb[i].replace(['N/A', 'n/a',\"0\", '-', '_',' ', np.nan,'nan'], '')\n",
        "\n",
        "towerdb = towerdb.fillna('')\n",
        "towerdb.to_csv('/content/TowerDB_Spain_20210831.csv', encoding='windows-1252', index=False)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (112) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BimKw6Izhq6S"
      },
      "source": [
        "\"\"\"Defining variables which is gonna be reusable in checks\"\"\"\n",
        "tw_index = 'Code'\n",
        "tw_doer = 'Date of equipment removal (from MAR´21)'\n",
        "tw_status = 'on air / active'\n",
        "tw_bts = 'Bts_Site'\n",
        "tw_bill = 'Billing Trigger date'\n",
        "tw_wip = 'Wip_Site'\n",
        "tw_decom = 'Decommissioned_Site only for VF'\n",
        "#w_amount = 'Lease Contract - Current annual lease fee'\n",
        "tw_critical = 'CriticalSite_Beyond_10'\n",
        "msa_index = 'Code'\n",
        "msa_bts = 'Bts_Site'\n",
        "msa_doer = 'Date of equipment removal (from MAR´21)'\n",
        "msa_status = 'on air / active'\n",
        "msa_bill = 'Billing Trigger date'\n",
        "msa_wip = 'Wip_Site'\n",
        "msa_decom = 'Decommissioned_Site only for VF'\n",
        "#msa_amount = 'Lease Contract - Current annual lease fee'\n",
        "msa_critical = 'CriticalSite_Beyond_10'\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_CmMZIVVWBB"
      },
      "source": [
        "Check columns received looking for missing columns that is gonna be used in rating engine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wblfWhtLTeQX"
      },
      "source": [
        "\"\"\"Check Columns Received\"\"\"\n",
        "def check_columns_received(df, bill_cols):\n",
        "    twdb_col = lower_str(list(df.columns))\n",
        "    col_miss = [i for i in bill_cols if i not in twdb_col]\n",
        "    \"\"\"\n",
        "    for i in bill_cols:\n",
        "        if i not in twdb_col:\n",
        "            col_miss.append(i)\"\"\"\n",
        "    df_col_missing = pd.DataFrame(col_miss, columns=['Column(s) Missing'], index=range(len(col_miss)))\n",
        "    return df_col_missing\n",
        "\n",
        "df_cols = check_columns_received(towerdb, col_order)\n",
        "df_cols\n",
        "#No columns missing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAGJs483VchY"
      },
      "source": [
        "First Check - Dates Formats (dd/mm/YYYY) \n",
        "\n",
        "Columns: Date of equipment removal (from MAR´21)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEZFbjGvVzZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780ea14a-1f62-4a9b-9862-afe1994aff5f"
      },
      "source": [
        "\"\"\"You need to convert all values in cols for string format to check\"\"\"\n",
        "def check_date_columns(df, df_index,status_col,columns, format):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    df_dates = df[columns]\n",
        "    df_dates['sites'] = df_dates[df_index]\n",
        "    df_dates = df_dates.set_index('sites')\n",
        "\n",
        "    df_de = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    df_duplicates = count_duplicates(df_dates[df_index])\n",
        "    if not df_duplicates.empty:\n",
        "        df_dates.drop_duplicates(subset=[df_index], inplace=True)\n",
        "\n",
        "    filtered = df[[df_index, status_col]]\n",
        "\n",
        "    if format == 1:\n",
        "        date_format = re.compile(r'\\d{2}\\-\\d{2}\\-\\d{4}')\n",
        "        for de_site in df_dates[df_index]:\n",
        "            for de_column in columns[1:]:\n",
        "                #match = re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', df_dates.loc[ta_site,ta_column])\n",
        "                #print(type(df_dates.loc[de_site,de_column]))\n",
        "                value = df_dates.loc[de_site,de_column]\n",
        "                if date_format.match(value) == None:\n",
        "                    if df_dates.loc[de_site,df_index] not in df_de.index:\n",
        "                        df_de.loc[de_site,df_index] = df_dates.loc[de_site,df_index]\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                    else:\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "        df_de = df_de.dropna(how='all', axis=1).fillna('Ok')       \n",
        "        if not df_de.empty:\n",
        "            df_de.reset_index()\n",
        "            df_de = pd.merge(df_de, filtered, how='left', on=df_index)\n",
        "            df_de = df_de[[df_index, status_col, *columns[1:]]]\n",
        "            return df_de\n",
        "        else: \n",
        "            print('\\nNo one columns with incorrect date format!\\n')\n",
        "    else:\n",
        "        date_format = re.compile(r'\\d{2}\\/\\d{2}\\/\\d{4}')\n",
        "        for de_site in df_dates[df_index]:\n",
        "            for de_column in columns[1:]:\n",
        "                #match = re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', df_dates.loc[ta_site,ta_column])\n",
        "                value = df_dates.loc[de_site,de_column]\n",
        "                if date_format.match(value) == None:\n",
        "                    if df_dates.loc[de_site,df_index] not in df_de.index:\n",
        "                        df_de.loc[de_site,df_index] = df_dates.loc[de_site,df_index]\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                    else:\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                            \n",
        "        df_de = df_de.dropna(how='all', axis=1).fillna('Ok')       \n",
        "        if not df_de.empty:\n",
        "            df_de.reset_index()\n",
        "            df_de = pd.merge(df_de, filtered, how='left', on=df_index)\n",
        "            #df_de = df_de[[df_index, status_col, *columns[1:]]]\n",
        "            return df_de\n",
        "        else: \n",
        "            print('\\nNo one columns with incorrect date format!\\n')\n",
        "\n",
        "# Columns to functions\n",
        "dates_bill = [tw_index, tw_bill]\n",
        "dates_doer = [tw_index, tw_doer]\n",
        "#Columns to parser\n",
        "bill=[tw_bill]\n",
        "doer=[tw_doer]\n",
        "\n",
        "actives_1 = towerdb[towerdb['on air / active']=='In Service']\n",
        "no_actives_1 = towerdb[~(towerdb[tw_status]=='In Service')]\n",
        "\n",
        "#Checking columns for errors\n",
        "actives_dates_errors = check_date_columns(actives_1, tw_index, tw_status, dates_bill, 2) \n",
        "# Actives sites with blank billing trigger date\n",
        "no_actives_dates_errors = check_date_columns(no_actives_1, tw_index,tw_status, dates_doer, 2) \n",
        "# No Actives sites with blank Date of Equipament Removal\n",
        "print(actives_dates_errors)\n",
        "print('\\n')\n",
        "print(no_actives_dates_errors)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2LrHKSGjj9t"
      },
      "source": [
        "Thirth - Check Picklist values All sites\n",
        "\n",
        "Do this check in all sites\n",
        "\n",
        "Check the picklist for each case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoS6fLsXjykD"
      },
      "source": [
        "def check_picklist_v1(df,df_index,df_status, df_cols, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    \"\"\"for id in df_picklist[df_index]:\n",
        "        if id not in new_dic.keys():\n",
        "            new_dic[df_index].append(id)\"\"\" \n",
        "            \n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]): \n",
        "                if pd.isnull(value) or pd.isna(value) or value=='' or value=='nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors[df_index] = df_picklist[df_index]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, df_status]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[df_status]+ df_errors.columns[:-1].tolist()]\n",
        "    #df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "picklist_tw_general = {\n",
        "    'Categorization by Transmission Sys' : ['Macro', 'Public DAS']\n",
        "}\n",
        "pick_col_general = ['Code', 'Categorization by Transmission Sys']\n",
        "\n",
        "df_general_pick = check_picklist_v1(towerdb, tw_index, tw_status, pick_col_general, picklist_tw_general)\n",
        "df_general_pick\n",
        "# No errors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uoBfMK4mZt_"
      },
      "source": [
        "Fifth Check MoM Sites (BTS, decomissoned...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J7-o7qSmZUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701bad98-c46c-4383-cd66-987b8c19f472"
      },
      "source": [
        "\"\"\"Falta Coluna de Flag Indicating BTS Site no twerdb recebido\"\"\"\n",
        "def check_mom_bts(df_tw, tw_index, tw_col, df_msa,msa_index, msa_col):\n",
        "   \n",
        "    msa_bts = df_msa[df_msa[msa_col]=='Yes']\n",
        "    msa_bts_sites = [i for i in msa_bts[msa_index]]\n",
        "\n",
        "    tw_bts = df_tw[df_tw[tw_col]=='Yes']\n",
        "    tw_bts_sites = [i for i in tw_bts[tw_index]]\n",
        "\n",
        "    out_tower_bts = [i for i in msa_bts_sites if i not in tw_bts_sites]\n",
        "    filtered = tw_bts[tw_bts[tw_index].isin(out_tower_bts)]\n",
        "    return filtered[[tw_index, tw_col]]         \n",
        "\n",
        "\n",
        "actives = towerdb[towerdb[tw_status]=='In Service']\n",
        "df_mom_bts = check_mom_bts(actives, tw_index, tw_bts, msa, msa_index, msa_bts)\n",
        "# No one error df_mom_bts\n",
        "\n",
        "decomiss = towerdb[towerdb[tw_status]=='Decommissioned']\n",
        "df_mom_decom = check_mom_bts(decomiss, tw_index, tw_decom, msa, msa_index, msa_decom)\n",
        "# No one error df_mom_decom\n",
        "\n",
        "print(df_mom_bts)\n",
        "print('\\n')\n",
        "print(df_mom_decom)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Code, Bts_Site]\n",
            "Index: []\n",
            "\n",
            "\n",
            "Empty DataFrame\n",
            "Columns: [Code, Decommissioned_Site only for VF]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kyAO221L8Uu"
      },
      "source": [
        "Check Picklist and dates formats for In service sites\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOzkwTx1MGa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "eabfcbbd-0c4c-4772-a0c7-0d558351b2b0"
      },
      "source": [
        "\"\"\"Check all picklist Columns\"\"\"\n",
        "def check_picklist_v1(df,df_index,df_status, df_cols, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    \"\"\"for id in df_picklist[df_index]:\n",
        "        if id not in new_dic.keys():\n",
        "            new_dic[df_index].append(id)\"\"\" \n",
        "            \n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]): \n",
        "                if pd.isnull(value) or pd.isna(value) or value=='' or value=='nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors[df_index] = df_picklist[df_index]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, df_status]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[df_status]+ df_errors.columns[:-1].tolist()]\n",
        "    #df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "picklis_dict = {\n",
        "    'Categorization by Transmission Sys': ['Macro', 'Public DAS'],\n",
        "    'Categorization by Site Type': ['DAS passive','GBT','RTT'],\n",
        "    'Sites_As_Metered_Estimated': ['Estimated Model','Metered Model'],\n",
        "    #'Infrastructure ready (existing)/ to be ready (new)': [''],\n",
        "    'Indoor_Site_Any_Climate_Control': ['No','Yes; Indoor Air Conditioning','Yes; Indoor Air Conditioning and Free Air cooling / Free cooling units'],\n",
        "    'Bts_Site': ['Yes', 'No'],\n",
        "    'Strategic_Site': ['Yes', 'No'],\n",
        "    'Strategic_Site_Bucket': ['Yes - first 460', ''],\n",
        "    'Critical_Site': ['Yes', 'No'],\n",
        "    'CriticalSite_Beyond_10': ['Within 10%','Non Critical'],\n",
        "    'Wip_Site': ['Yes', 'No'],\n",
        "    'Decommissioned_Site only for VF': ['Yes', 'No'],\n",
        "    'First_Active_Sharing_Deployment_Type': ['']\n",
        "}\n",
        "\n",
        "pick_cols = ['Code','Categorization by Transmission Sys','Categorization by Site Type','Sites_As_Metered_Estimated',\\\n",
        "             'Indoor_Site_Any_Climate_Control','Bts_Site',\\\n",
        "             'Strategic_Site','Strategic_Site_Bucket','Critical_Site','CriticalSite_Beyond_10','Wip_Site',\\\n",
        "             'Decommissioned_Site only for VF','First_Active_Sharing_Deployment_Type' ]\n",
        "\n",
        "actives = towerdb[towerdb[tw_status]=='In Service']\n",
        "df_in_service_picklist = check_picklist_v1(actives, tw_index, tw_status, pick_cols, picklis_dict)\n",
        "df_in_service_picklist\n",
        "# No errors"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>on air / active</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [on air / active]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQj9BsQKSHfZ"
      },
      "source": [
        "#check dates in columns\n",
        "def check_date_columns(df, df_index,status_col,columns, format=2):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    df_dates = df[columns]\n",
        "    df_dates['sites'] = df_dates[df_index]\n",
        "    df_dates = df_dates.set_index('sites')\n",
        "\n",
        "    df_de = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    df_duplicates = count_duplicates(df_dates[df_index])\n",
        "    if not df_duplicates.empty:\n",
        "        df_dates.drop_duplicates(subset=[df_index], inplace=True)\n",
        "\n",
        "    filtered = df[[df_index, status_col]]\n",
        "\n",
        "    if format == 1:\n",
        "        date_format = re.compile(r'\\d{2}\\-\\d{2}\\-\\d{4}')\n",
        "        for de_site in df_dates[df_index]:\n",
        "            for de_column in columns[1:]:\n",
        "                #match = re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', df_dates.loc[ta_site,ta_column])\n",
        "                #print(type(df_dates.loc[de_site,de_column]))\n",
        "                value = df_dates.loc[de_site,de_column]\n",
        "                if date_format.match(value) == None:\n",
        "                    if df_dates.loc[de_site,df_index] not in df_de.index:\n",
        "                        df_de.loc[de_site,df_index] = df_dates.loc[de_site,df_index]\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                    else:\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "        df_de = df_de.dropna(how='all', axis=1).fillna('Ok')       \n",
        "        if not df_de.empty:\n",
        "            df_de.reset_index()\n",
        "            df_de = pd.merge(df_de, filtered, how='left', on=df_index)\n",
        "            df_de = df_de[[df_index, status_col, *columns[1:]]]\n",
        "            return df_de\n",
        "        else: \n",
        "            print('\\nNo one columns with incorrect date format!\\n')\n",
        "    else:\n",
        "        date_format = re.compile(r'\\d{2}\\/\\d{2}\\/\\d{4}')\n",
        "        for de_site in df_dates[df_index]:\n",
        "            for de_column in columns[1:]:\n",
        "                #match = re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', df_dates.loc[ta_site,ta_column])\n",
        "                value = df_dates.loc[de_site,de_column]\n",
        "                if date_format.match(value) == None:\n",
        "                    if df_dates.loc[de_site,df_index] not in df_de.index:\n",
        "                        df_de.loc[de_site,df_index] = df_dates.loc[de_site,df_index]\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                    else:\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                            \n",
        "        df_de = df_de.dropna(how='all', axis=1).fillna('Ok')       \n",
        "        if not df_de.empty:\n",
        "            df_de.reset_index()\n",
        "            df_de = pd.merge(df_de, filtered, how='left', on=df_index)\n",
        "            df_de = df_de[[df_index, status_col, *columns[1:]]]\n",
        "            return df_de\n",
        "        else: \n",
        "            print('\\nNo one columns with incorrect date format!\\n')\n",
        "\n",
        "actives['First_Active_Sharing_End_Date'] = actives['First_Active_Sharing_End_Date'].fillna('')\n",
        "in_service_cols = ['Code', 'First_Active_Sharing_Start_Date', 'First_Active_Sharing_End_Date']\n",
        "df_in_service_dates = check_date_columns(actives, tw_index, tw_status, in_service_cols)\n",
        "df_in_service_dates\n",
        "# tem errors em df_in_service_dates sites ativos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF9HkIPBZ3va"
      },
      "source": [
        "Fifth Check BTS Flagged(Billing Trigger and Commercial)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsLeIodqVW4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "967813cf-df40-461d-9ab8-f8c8282b552e"
      },
      "source": [
        "def check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col):\n",
        "    \n",
        "    t = type_col.lower()\n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "    if t == 'doer':\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&(df_tw[date_col].astype('datetime64[ns]') < current_date)]\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "    else:\n",
        "        df_tw[date_col] = pd.to_datetime(df_tw[date_col], format='%d/%m/%Y', errors='coerce')\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&((df_tw[date_col].empty)|(df_tw[date_col]>current_date))]\n",
        "        filtered[date_col] = list(map(lambda x: f'{x:%d/%m/%Y}', filtered[date_col]))\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "\n",
        "status = 'Yes'\n",
        "df_bts_bill_errors= check_tw_bill_doer(towerdb, tw_index,tw_bill, tw_bts, status, 'bill')\n",
        "df_bts_bill_errors\n",
        "#No errors"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Bts_Site</th>\n",
              "      <th>Billing Trigger date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9105</th>\n",
              "      <td>95151</td>\n",
              "      <td>Yes</td>\n",
              "      <td>01/09/2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Code Bts_Site Billing Trigger date\n",
              "9105  95151      Yes           01/09/2021"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePYDr-9PcqOg"
      },
      "source": [
        "\"\"\" BTS sites\"\"\"\n",
        "path_uip = '/content/UserInput_Spain_202107 v31.xlsx'\n",
        "uip_names = ['Site_ID', 'BTS site applicable charge (Annual)', 'Commercials for sites beyond 10% cap of critical sites(Annual)']\n",
        "uip = pd.read_excel(path_uip ,sheet_name='SiteLevel',usecols=[0,1,2],skiprows=2).fillna('')\n",
        "uip.columns = uip_names\n",
        "\n",
        "msa_sites = [i for i in msa[msa_index]]\n",
        "tw_sites = [i for i in towerdb[tw_index]]\n",
        "uip_sites = [i for i in uip['Site_ID']]\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eow-oO-Ndhxl"
      },
      "source": [
        "\"\"\" BTS sites\"\"\"\n",
        "def check_new_sites(df_towerdb, tw_index, bts_col, bill_col, status_col, msa_list, towerdb_list, uip_list):\n",
        "    \n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "    \n",
        "    filtered = df_towerdb[[tw_index, status_col]]\n",
        "\n",
        "    #Finding for ALL NEW SITES\n",
        "    new_site = [i for i in towerdb_list if i not in msa_list]\n",
        "    new_sites = pd.DataFrame(new_site, columns=['New_Sites'])\n",
        "    new_sites = pd.merge(new_sites, filtered, how='left', left_on=['New_Sites'], right_on=tw_index)\n",
        "    new_sites = new_sites[['New_Sites', status_col]]\n",
        "\n",
        "    #create a copy to make index modifications\n",
        "    df = df_towerdb.copy()\n",
        "\n",
        "    #New columns with Site Codes\n",
        "    df['Sites'] = df[tw_index]\n",
        "    #defining site code to index\n",
        "    df.set_index('Sites', inplace=True)\n",
        "\n",
        "    #filtering by new sites\n",
        "    df = df[df[tw_index].isin(new_site)]\n",
        "\n",
        "    # Save information os sites with demerged date more than current date\n",
        "    df[bill_col] = pd.to_datetime(df[bill_col], format='%d/%m/%Y', errors='coerce')\n",
        "    df_site_bts = df[(df[bts_col]=='Yes')&(df[bill_col] > current_date)].fillna('')\n",
        "    df_site_bts[bill_col] = list(map(lambda x: f'{x:%d/%m/%Y}', df_site_bts[bill_col]))\n",
        "    df_site_bts = df_site_bts[[tw_index,status_col, bts_col, bill_col]]\n",
        "    #if not (new_sites.empty or bts_out_uis.empty or df_site_bts.empty):\n",
        "    return new_sites, df_site_bts\n",
        "\n",
        "new_sites, df_bts_errors = check_new_sites(towerdb, tw_index, tw_bts, tw_bill,tw_status, msa_sites, tw_sites, uip_sites)\n",
        "\n",
        "# New sites = 132\n",
        "# Error on BTS sites out of UIP File\n",
        "print(new_sites)\n",
        "print('\\n')\n",
        "print(df_bts_errors)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb7vr-l6nO3Z"
      },
      "source": [
        "Check Wip SItes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgxfEk5qnKdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "dbf74b72-2f44-44d5-edda-c8922d49d5f7"
      },
      "source": [
        "\"\"\" Wip Sites Check\"\"\"\n",
        "def check_wip(df_tw,tw_index, wip_tw, tw_bts, df_msa, msa_index, msa_wip):\n",
        "\n",
        "    wip_msa = [i for i in df_msa[df_msa[msa_wip]=='Yes'][msa_index]]\n",
        "    \n",
        "    tw_wip_sites = [str(i) for i in df_tw[df_tw[wip_tw]=='Yes'][tw_index]]\n",
        "\n",
        "    tw_wip_site_bts_flagged = df_tw[(df_tw[wip_tw]=='Yes')&(df_tw[tw_bts]=='Yes')]\n",
        "    tw_wip_site_bts_flagged = tw_wip_site_bts_flagged[[tw_index, wip_tw, tw_bts]]\n",
        "    \n",
        "    #wip_out_tw_list = [i for i in tw_wip_sites if i not in wip_msa]\n",
        "\n",
        "    return tw_wip_site_bts_flagged\n",
        "\n",
        "df_wip_and_bts_flagged = check_wip(towerdb,tw_index, tw_wip, tw_bts, msa, msa_index, msa_wip)\n",
        "df_wip_and_bts_flagged\n",
        "#No errors"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Wip_Site</th>\n",
              "      <th>Bts_Site</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Code, Wip_Site, Bts_Site]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZpkKgsNn5vR"
      },
      "source": [
        "Check Decomissioned sites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it4pR9Srn1zw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "1e4d006f-ae69-4de9-9fa8-aaa9ba1568cd"
      },
      "source": [
        "def check_decommissioned(df,df_index, decom_col, doer_col):\n",
        "    #c = country.lower()\n",
        "    filtered = df[(df[decom_col]=='Yes')&(df[doer_col]==\"\")]\n",
        "    return filtered[[df_index, decom_col, doer_col]]\n",
        "  \n",
        "df_decom_sites = check_decommissioned(towerdb, tw_index, tw_decom, tw_doer)\n",
        "df_decom_sites\n",
        "#No errors"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Decommissioned_Site only for VF</th>\n",
              "      <th>Date of equipment removal (from MAR´21)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Code, Decommissioned_Site only for VF, Date of equipment removal (from MAR´21)]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL92Kkk1osOj"
      },
      "source": [
        "Check Doer columns for in service sites\n",
        "\n",
        "Should not to be in past or different of blank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPbkQQC8oroV"
      },
      "source": [
        "#COluna Doer tem valores fora do formato\n",
        "def check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col):\n",
        "    \n",
        "    t = type_col.lower()\n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "    if t == 'doer':\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&(df_tw[date_col].astype('datetime64[ns]') < current_date)]\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "    else:\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&(df_tw[date_col].astype('datetime64[ns]').empty)]\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "\n",
        "actives[tw_doer] = actives[tw_doer].replace('Not removed', '')\n",
        "df_doer = check_tw_bill_doer(actives, tw_index, tw_doer, tw_bts, 'Yes', 'doer')\n",
        "df_doer\n",
        "#No errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPWyxksEyBQp"
      },
      "source": [
        "*Tenth* - Check UIP Towerdb matches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOub5bqnxKqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce476bed-c70d-4bc6-ce88-4a32721f4dd0"
      },
      "source": [
        "def check_uip_tw(df_tw,tw_index, status_tw_col,decom_col, tw_bts_col, tw_critical_col, df_uip, uip_sites):\n",
        "\n",
        "    filtered = df_tw[[tw_index, status_tw_col]]\n",
        "    #tw_active = df_tw[df_tw['Site Status']=='In Service']\n",
        "    count_tw_sites = [i for i in df_tw[df_tw[status_tw_col] =='In Service'][tw_index]]\n",
        "\n",
        "    # check number of sites that are in uip file and doesn't have in df_tw\n",
        "    uis_sites_not_in_towerdb = [i for i in uip_sites if i not in count_tw_sites]\n",
        "    uis_sites_not_in_towerdb = pd.DataFrame(uis_sites_not_in_towerdb,columns=['UIS In Month not active in TowerDB!'])\n",
        "    uis_sites_not_in_towerdb = pd.merge(uis_sites_not_in_towerdb, filtered, how='left', left_on='UIS In Month not active in TowerDB!',\\\n",
        "                                    right_on=tw_index)\n",
        "    uis_sites_not_in_towerdb = uis_sites_not_in_towerdb[['UIS In Month not active in TowerDB!', status_tw_col]]\n",
        "    \n",
        "    # Check for in service sites(towerdb) that not to be in UIS\n",
        "    in_service_not_in_uis = [i for i in count_tw_sites if i not in uip_sites]\n",
        "    in_service_not_in_uis = pd.DataFrame(in_service_not_in_uis,columns=['TowerDB Sites out of UIS In Month!'])\n",
        "    in_service_not_in_uis = pd.merge(in_service_not_in_uis, filtered, how='left', left_on='TowerDB Sites out of UIS In Month!',\\\n",
        "                                    right_on=tw_index)\n",
        "    in_service_not_in_uis = in_service_not_in_uis[['TowerDB Sites out of UIS In Month!', status_tw_col]]\n",
        "    #check for decomissioned site not in uip files\n",
        "\n",
        "    tw_decomiss = [i for i in df_tw[df_tw[decom_col]=='Yes'][tw_index] if i in uip_sites]\n",
        "    decomiss_sites_in_uip = pd.DataFrame(tw_decomiss, columns=['Decomissioned Site in UIS File'])\n",
        "    decomiss_sites_in_uip = pd.merge(decomiss_sites_in_uip, filtered, how='left', left_on='Decomissioned Site in UIS File',\\\n",
        "                                    right_on=tw_index)\n",
        "    decomiss_sites_in_uip = decomiss_sites_in_uip[decomiss_sites_in_uip[status_tw_col]=='Decommissioned']\n",
        "    decomiss_sites_in_uip = decomiss_sites_in_uip[['Decomissioned Site in UIS File', status_tw_col]]\n",
        "\n",
        "    #Check BTS sites\n",
        "    bts_sites = [i for i in df_tw[df_tw[tw_bts_col]=='Yes'][tw_index]]\n",
        "    uip_bts = [i for i in df_uip[df_uip['BTS site applicable charge (Annual)']!=\"\"]['Site_ID']]                            \n",
        "\n",
        "    bts_sites_out_uip = [i for i in uip_bts if i not in bts_sites]\n",
        "    bts_sites_out_uip = pd.DataFrame(bts_sites_out_uip, columns=['UIS BTS not in TowerDB(BTS)'])\n",
        "    bts_sites_out_uip = pd.merge(bts_sites_out_uip, filtered, how='left', left_on='UIS BTS not in TowerDB(BTS)',\\\n",
        "                                    right_on=tw_index)\n",
        "    bts_sites_out_uip = bts_sites_out_uip[['UIS BTS not in TowerDB(BTS)', status_tw_col]]\n",
        "\n",
        "    #  Check for UIP critical sites \n",
        "    uip_critical = [i for i in df_uip[df_uip['Commercials for sites beyond 10% cap of critical sites(Annual)']!='']['Site_ID']]\n",
        "    bts_tw_critical = [i for i in df_tw[df_tw[tw_critical_col]=='Beyond 10%'][tw_index]]\n",
        "    print(bts_tw_critical)\n",
        "    critical = [i for i in uip_critical if i not in bts_tw_critical]\n",
        "    critical = pd.DataFrame(critical, columns=['Sites with critical level beyond 10% in out UIS File'])\n",
        "    critical = pd.merge(critical, filtered, how='left', left_on='Sites with critical level beyond 10% in out UIS File',\\\n",
        "                                right_on=tw_index)\n",
        "    critical = critical[['Sites with critical level beyond 10% in out UIS File', status_tw_col]]\n",
        "    #if not (in_service_uip_sites.empty or decomiss_sites_in_uip.empty or bts_sites_out_uip.empty or critical.empty):\n",
        "    return uis_sites_not_in_towerdb, in_service_not_in_uis,decomiss_sites_in_uip, bts_sites_out_uip, critical\n",
        "\n",
        "uis_sites_not_in_towerdb, in_service_not_in_uis,decomiss_sites_in_uis, bts_sites_out_uis, critical = check_uip_tw(towerdb,tw_index, tw_status, \\\n",
        "                                                              tw_decom, tw_bts,tw_critical,uip, uip_sites)\n",
        "print(uis_sites_not_in_towerdb)\n",
        "print('\\n')\n",
        "print(in_service_not_in_uis)\n",
        "print('\\n')\n",
        "print(decomiss_sites_in_uis)\n",
        "print('\\n')\n",
        "print(bts_sites_out_uis)\n",
        "print('\\n')\n",
        "print(critical)\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "    UIS In Month not active in TowerDB! on air / active\n",
            "0                                  1184  Decommissioned\n",
            "1                                 27266  Decommissioned\n",
            "2                                 52208  Decommissioned\n",
            "3                                 53060  Decommissioned\n",
            "4                                 74808  Decommissioned\n",
            "5                                173929  Decommissioned\n",
            "6                                181769             WIP\n",
            "7                                 95151             WIP\n",
            "8                                 92098             WIP\n",
            "9                                196617             NaN\n",
            "10                                19445             NaN\n",
            "\n",
            "\n",
            "Empty DataFrame\n",
            "Columns: [TowerDB Sites out of UIS In Month!, on air / active]\n",
            "Index: []\n",
            "\n",
            "\n",
            "    Decomissioned Site in UIS File on air / active\n",
            "1                             1184  Decommissioned\n",
            "24                           27266  Decommissioned\n",
            "36                           52208  Decommissioned\n",
            "\n",
            "\n",
            "   UIS BTS not in TowerDB(BTS) on air / active\n",
            "0                        19445             NaN\n",
            "\n",
            "\n",
            "Empty DataFrame\n",
            "Columns: [Sites with critical level beyond 10% in out UIS File, on air / active]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVELEIlf0EGZ"
      },
      "source": [
        "Commercial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "le6_RE6XRQBm",
        "outputId": "ea4731e2-deaa-4d21-9253-6bc7e2513645"
      },
      "source": [
        "def check_diffs_v2(path_current, path_last, sheet='Commercial'):\n",
        "    def lower_str(columns):\n",
        "        newlist = list(map(lambda x: x.lower(), columns))\n",
        "        return newlist\n",
        "\n",
        "    def highlight_diff(data, color='yellow'):\n",
        "        attr = 'background-color: {}'.format(color)\n",
        "        other = data.xs('Current', axis='columns', level=-1)\n",
        "        return pd.DataFrame(np.where(data.ne(other, level=0), attr, ''),\n",
        "                            index=data.index, columns=data.columns)\n",
        "\n",
        "    _actual = pd.read_excel(path_current,sheet_name=sheet).fillna('')\n",
        "\n",
        "    _before = pd.read_excel(path_last,sheet_name=sheet).fillna('')\n",
        "\n",
        "    df_all = pd.concat([_actual, _before],axis='columns', keys=['Current', 'Last'])\n",
        "    df_final = df_all.swaplevel(axis='columns')[_actual.columns[1:]]\n",
        "\n",
        "    #df_final.style.apply(highlight_diff, axis=None)\n",
        "    if not df_final.empty:\n",
        "        return df_final[(_actual != _before).any(1)].style.apply(highlight_diff, axis=None)\n",
        "    else:\n",
        "        print('\\nNo differences Founded!\\n')\n",
        "        \n",
        "#cols_ordered = ['Charge_Type','Sub_Charge_Type', 'Param1','Param2', 'Data_Type','Input_Value_actual', 'Input_Value_before' ,'Description/Instruction', 'Frequency of Update']\n",
        "df_com = check_diffs_v2( '/content/UserInput_Spain_202107 v31.xlsx', '/content/UserInput_Spain_20210731.xlsx')\n",
        "df_com"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_d15bbede_00fb_11ec_9e41_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" colspan=2>Sub_charge_Type</th>        <th class=\"col_heading level0 col2\" colspan=2>Param1</th>        <th class=\"col_heading level0 col4\" colspan=2>Param2</th>        <th class=\"col_heading level0 col6\" colspan=2>Data_Type</th>        <th class=\"col_heading level0 col8\" colspan=2>Input_Value</th>        <th class=\"col_heading level0 col10\" colspan=2>Description/Instruction</th>        <th class=\"col_heading level0 col12\" colspan=2>Frequency of Update</th>    </tr>    <tr>        <th class=\"blank level1\" ></th>        <th class=\"col_heading level1 col0\" >Current</th>        <th class=\"col_heading level1 col1\" >Last</th>        <th class=\"col_heading level1 col2\" >Current</th>        <th class=\"col_heading level1 col3\" >Last</th>        <th class=\"col_heading level1 col4\" >Current</th>        <th class=\"col_heading level1 col5\" >Last</th>        <th class=\"col_heading level1 col6\" >Current</th>        <th class=\"col_heading level1 col7\" >Last</th>        <th class=\"col_heading level1 col8\" >Current</th>        <th class=\"col_heading level1 col9\" >Last</th>        <th class=\"col_heading level1 col10\" >Current</th>        <th class=\"col_heading level1 col11\" >Last</th>        <th class=\"col_heading level1 col12\" >Current</th>        <th class=\"col_heading level1 col13\" >Last</th>    </tr></thead><tbody>\n",
              "        </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fc97e5c06d0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9AgSwzZ3B6K"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "        \n",
        "logs = [['Dates Errors', actives_dates_errors],\n",
        "        ['No Actives Dates Errors', no_actives_dates_errors],\n",
        "        ['General Picklist Erros',df_general_pick],\n",
        "        ['MSA BTS not in TowerDB',df_mom_bts],\n",
        "        ['MSA Decom not in TowerDB', df_mom_decom],\n",
        "        ['Active Picklist Errors', df_in_service_picklist],\n",
        "        ['Actives Sites Dates Errors',df_in_service_dates],\n",
        "        ['BTS Bill Dates Erros', df_bts_bill_errors],\n",
        "        ['New Sites', new_sites],\n",
        "        ['New Sites Bill Dates Erros',df_bts_errors], \n",
        "        ['Wip & BTS Flagged', df_wip_and_bts_flagged],\n",
        "        ['Decom sites Dates Errors', df_decom_sites],\n",
        "        ['DOER Errors', df_doer],\n",
        "        ['UIS Sites not active in TowerDB', uis_sites_not_in_towerdb],\n",
        "        ['TowerDB Sites out of UIS', in_service_not_in_uis],\n",
        "        ['Decom Sites In UIS', decomiss_sites_in_uis],\n",
        "        ['UIS BTS not in TowerDB(BTS)', bts_sites_out_uis],\n",
        "        ['Sites Beyond 10% out UIS', critical],\n",
        "        ['Comercial Differences', df_com]]\n",
        "\n",
        "path_log = '/content/TowerDB_ES_Errors.xlsx'\n",
        "general_log_erros(logs, path_log)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13M_kfik0zsh"
      },
      "source": [
        "Lc Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqwvl8K60yKr"
      },
      "source": [
        "def date_parser(df, columns, format, type_dates='normal'):\n",
        "    t_col = type_dates.lower()\n",
        "    for column in columns:\n",
        "        if t_col == 'mixed':\n",
        "            df[column] = [date_obj.strftime(format) if not pd.isnull(date_obj) \\\n",
        "                        and not isinstance(date_obj, str) else date_obj for date_obj in df[column]]\n",
        "            df[column] = df[column].astype(str)\n",
        "        else:\n",
        "            df[column] = [date_obj.strftime(format) if not pd.isnull(date_obj) else '' for date_obj in df[column]]\n",
        "            df[column] = df[column].astype(str)\n",
        "\n",
        "pathtw = '/content/TowerDB_Spain_20210809.xlsx'\n",
        "sheet= 'LC_INPUT_SPAIN'\n",
        "skipr = 0\n",
        "skipc = 0\n",
        "lc = pd.read_excel(pathtw, sheet)\n",
        "dates_lc = ['Inicio','Fin vigen/']\n",
        "date_parser(lc,dates_lc,\"%d/%m/%Y\")\n",
        "lc = lc.fillna('')\n",
        "lc.head(3)\n",
        "lc.to_csv('/content/LC_Input_Spain_20210831.csv', encoding='windows-1252', index=False)\n",
        "#print([i for i in list(lc['Código']) if list(lc['Código']).count(i)>1])\n",
        "#NO erros"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtpOiwl6W2fn"
      },
      "source": [
        "def check_amounts(df_check, df_index, columns, pattern=','):\n",
        "    \"\"\"\n",
        "    Paramns:\n",
        "    pattern: general (. to decimal), other (, to decimal)\n",
        "    \"\"\"\n",
        "\n",
        "    df = df_check[columns]\n",
        "    df['sites'] = df[df_index]\n",
        "    df = df.set_index('sites')\n",
        "\n",
        "    df_new = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    df_duplicates = count_duplicates(df[df_index])\n",
        "    if not df_duplicates.empty:\n",
        "        df.drop_duplicates(subset=[df_index], inplace=True)\n",
        "\n",
        "    for site in df[df_index]:\n",
        "        for column in columns[1:]:\n",
        "            value = str(df.loc[site,column])\n",
        "            if not value.__contains__(pattern):\n",
        "                if df.loc[site,df_index] not in df_new.index:\n",
        "                    df_new.loc[site,df_index] = df.loc[site,df_index]\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = 'Incorret Format to separate decimal values'\n",
        "                else:\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = 'Incorret Format to separate decimal values'\n",
        "\n",
        "    df_new = df_new.dropna(how='all', axis=1).fillna('Ok')       \n",
        "\n",
        "    return df_new\n",
        "\n",
        "lc_cols = ['Código', '   Importe anual']\n",
        "#lc['Importe anual'] = lc['   Importe anual'].astype(str)\n",
        "#Python interpretou como float a coluna de Import Anual\n",
        "df_lc_amount = check_amounts(lc, 'Código', lc_cols, '.')\n",
        "df_lc_amount\n",
        "# No errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "LA9oWJyuW5AC",
        "outputId": "07d1cb25-c77a-4000-c121-fc169ab524f9"
      },
      "source": [
        "def check_lc_ta_dates(df,tw_index, start_date,end_date):\n",
        "    #Fit dates to correct format to compare\n",
        "    df[start_date] = pd.to_datetime(df[start_date], format='%d/%m/%Y', errors='coerce')\n",
        "    df[end_date] = pd.to_datetime(df[end_date], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "    #filtering Dateframe for specific dates\n",
        "    filtered = df.loc[(df[start_date] > df[end_date])|(df[start_date]=='')|(df[end_date]==''), [tw_index, start_date,end_date]]\n",
        "\n",
        "    filtered[start_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[start_date]))\n",
        "    filtered[end_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[end_date]))\n",
        "    filtered = filtered[[tw_index, start_date,end_date]] \n",
        "    return filtered\n",
        "\n",
        "df_lc_dates = check_lc_ta_dates(lc,'Código', 'Inicio','Fin vigen/')\n",
        "df_lc_dates"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Código</th>\n",
              "      <th>Inicio</th>\n",
              "      <th>Fin vigen/</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Código, Inicio, Fin vigen/]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwOlPAnZAxEB"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "logs_lc = [['Amount Errors', df_lc_amount],\n",
        "        ['Dates Errors', df_lc_dates]]\n",
        "        \n",
        "path_log_lc = '/content/LC_ES_Errors.xlsx'\n",
        "general_log_erros(logs_lc, path_log_lc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4jp7suZ1BAQ"
      },
      "source": [
        "TA OSP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br86vCWY1Aia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "6de3e36b-9f16-41c0-bd27-bd232baeccce"
      },
      "source": [
        "pathtw = '/content/TowerDB_Spain_20210809.xlsx'\n",
        "sheet= 'TA_Input_Lease_OSP_Spain'\n",
        "skipr = 0\n",
        "skipc = 0\n",
        "ta_bill = ['Código', 'Importe anual','Inicio','F/cie/tec/']\n",
        "ta_osp = pd.read_excel(pathtw, sheet)\n",
        "\n",
        "dates_ta_osp = ['Inicio','F/cie/tec/']\n",
        "for i in dates_ta_osp:\n",
        "    ta_osp[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in ta_osp[i]]\n",
        "\n",
        "ta_osp = ta_osp.fillna('')\n",
        "ta_osp = ta_osp[~(ta_osp['Importe anual']==\"\")]\n",
        "\n",
        "ta_osp.to_csv('/content/TA_Input_Lease_OSP_Spain_20210831.csv', encoding = 'windows-1252',index=False)\n",
        "ta_osp.head(2)\n",
        "#ta_osp = ta_osp[ta_osp['Inicio']!=\"\"]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Zona</th>\n",
              "      <th>Código</th>\n",
              "      <th>Towering</th>\n",
              "      <th>Nombre Loc</th>\n",
              "      <th>Nombre 1</th>\n",
              "      <th>Número de objeto</th>\n",
              "      <th>Por mes</th>\n",
              "      <th>Period.</th>\n",
              "      <th>Importe anual</th>\n",
              "      <th>F/cie/tec/</th>\n",
              "      <th>Siguiente</th>\n",
              "      <th>Fin+tardío</th>\n",
              "      <th>Válido de</th>\n",
              "      <th>Validez a</th>\n",
              "      <th>Status actual</th>\n",
              "      <th>NºAlquiler</th>\n",
              "      <th>Alquiler Anterior</th>\n",
              "      <th>Den.cl.contrato</th>\n",
              "      <th>Denomin.forma pago</th>\n",
              "      <th>Clase de condición</th>\n",
              "      <th>Objetivo cond.</th>\n",
              "      <th>CeBe</th>\n",
              "      <th>Comentario Central</th>\n",
              "      <th>Comentario Zona</th>\n",
              "      <th>Código Municipio</th>\n",
              "      <th>Provincia</th>\n",
              "      <th>Municipio</th>\n",
              "      <th>Crea el</th>\n",
              "      <th>Inicio</th>\n",
              "      <th>Entorno</th>\n",
              "      <th>Gpo.autoriz.</th>\n",
              "      <th>IDObjDist</th>\n",
              "      <th>ID objeto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Zona  Código Towering Nombre Loc  ... Entorno Gpo.autoriz. IDObjDist ID objeto\n",
              "0            1                      ...                                         \n",
              "1            2                      ...                                         \n",
              "\n",
              "[2 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6IJ4iHKagBt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "3b21335f-9bb2-4048-de20-f74fb6fe08cd"
      },
      "source": [
        "def check_amounts(df_check, df_index, columns, pattern=','):\n",
        "    \"\"\"\n",
        "    Paramns:\n",
        "    pattern: general (. to decimal), other (, to decimal)\n",
        "    \"\"\"\n",
        "\n",
        "    df = df_check[columns]\n",
        "    df['sites'] = df[df_index]\n",
        "    df = df.set_index('sites')\n",
        "\n",
        "    df_new = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    df_duplicates = count_duplicates(df[df_index])\n",
        "    if not df_duplicates.empty:\n",
        "        df.drop_duplicates(subset=[df_index], inplace=True)\n",
        "\n",
        "    for site in df[df_index]:\n",
        "        for column in columns[1:]:\n",
        "            value = str(df.loc[site,column])\n",
        "            if not value.__contains__(pattern):\n",
        "                if df.loc[site,df_index] not in df_new.index:\n",
        "                    df_new.loc[site,df_index] = df.loc[site,df_index]\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = f'Incorret Format: {value}'\n",
        "                else:\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = f'Incorret Format: {value}'\n",
        "\n",
        "    df_new = df_new.dropna(how='all', axis=1).fillna('Ok')       \n",
        "    return df_new\n",
        "\n",
        "\n",
        "ta_osp_cols = ['Código', 'Importe anual']  \n",
        "\n",
        "ta_osp['Importe anual'] = ta_osp['Importe anual'].astype(str)\n",
        "\n",
        "df_ta_osp_amount = check_amounts(ta_osp, 'Código', ta_osp_cols, '.')\n",
        "df_ta_osp_amount"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sh04VEBaZMX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "900217f8-5bbd-4e8d-e731-720151af2db5"
      },
      "source": [
        "def check_lc_ta_dates(df,tw_index, start_date,end_date):\n",
        "    #Fit dates to correct format to compare\n",
        "    df[start_date] = pd.to_datetime(df[start_date], format='%d/%m/%Y', errors='coerce')\n",
        "    df[end_date] = pd.to_datetime(df[end_date], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "    #filtering Dateframe for specific dates\n",
        "    filtered = df.loc[(df[start_date] > df[end_date])|(df[start_date]=='')|(df[end_date]==''), [tw_index, start_date,end_date]]\n",
        "\n",
        "    filtered[start_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[start_date]))\n",
        "    filtered[end_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[end_date]))\n",
        "    filtered = filtered[[tw_index, start_date,end_date]] \n",
        "    return filtered\n",
        "    \n",
        "df_ta_osp_dates = check_lc_ta_dates(ta_osp,'Código', 'Inicio','F/cie/tec/')\n",
        "df_ta_osp_dates\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Código</th>\n",
              "      <th>Inicio</th>\n",
              "      <th>F/cie/tec/</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Código, Inicio, F/cie/tec/]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cigSffhh1K8w"
      },
      "source": [
        "pathtw = '/content/TowerDB_Spain_20210809.xlsx'\n",
        "sheet= 'TA_Input_Lease_TME_Spain'\n",
        "skipr = 0\n",
        "skipc = 0\n",
        "\n",
        "ta_tme = pd.read_excel(pathtw, sheet)\n",
        "dates_ta_tme = ['Inicio','F/cie/tec/']\n",
        "for i in dates_ta_tme:\n",
        "    ta_tme[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in ta_tme[i]]\n",
        "\n",
        "ta_tme = ta_tme.fillna('')\n",
        "ta_tme = ta_tme[~(ta_tme['Importe anual']==\"\")]\n",
        "\n",
        "ta_tme.to_csv('/content/TA_Input_Lease_TME_Spain_20210831.csv', encoding = 'windows-1252',index=False)\n",
        "#ta_tme = ta_tme[ta_tme['Inicio']!=\"\"]"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoGuTQEfUamJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "069cbcb5-5c4b-47aa-e710-f5eeaa54385a"
      },
      "source": [
        "def check_lc_ta_dates(df,tw_index, start_date,end_date):\n",
        "    #Fit dates to correct format to compare\n",
        "    df[start_date] = pd.to_datetime(df[start_date], format='%d/%m/%Y', errors='coerce')\n",
        "    df[end_date] = pd.to_datetime(df[end_date], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "    #filtering Dateframe for specific dates\n",
        "    filtered = df.loc[(df[start_date] > df[end_date])|(df[start_date]=='')|(df[end_date]==''), [tw_index, start_date,end_date]]\n",
        "\n",
        "    filtered[start_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[start_date]))\n",
        "    filtered[end_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[end_date]))\n",
        "    filtered = filtered[[tw_index, start_date,end_date]] \n",
        "    return filtered\n",
        "      \n",
        "df_ta_tme_dates = check_lc_ta_dates(ta_tme,'Código', 'Inicio','F/cie/tec/')\n",
        "df_ta_tme_dates"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Código</th>\n",
              "      <th>Inicio</th>\n",
              "      <th>F/cie/tec/</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Código, Inicio, F/cie/tec/]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0KTML1xUfKP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "e379ea3f-a36e-4aa2-d31b-72d4f5015a0a"
      },
      "source": [
        "def check_amounts(df_check, df_index, columns, pattern=','):\n",
        "    \"\"\"\n",
        "    Paramns:\n",
        "    pattern: general (. to decimal), other (, to decimal)\n",
        "    \"\"\"\n",
        "\n",
        "    df = df_check[columns]\n",
        "    df['sites'] = df[df_index]\n",
        "    df = df.set_index('sites')\n",
        "\n",
        "    df_new = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    df_duplicates = count_duplicates(df[df_index])\n",
        "    if not df_duplicates.empty:\n",
        "        df.drop_duplicates(subset=[df_index], inplace=True)\n",
        "\n",
        "    for site in df[df_index]:\n",
        "        for column in columns[1:]:\n",
        "            value = str(df.loc[site,column])\n",
        "            if not value.__contains__(pattern):\n",
        "                if df.loc[site,df_index] not in df_new.index:\n",
        "                    df_new.loc[site,df_index] = df.loc[site,df_index]\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = f'Incorret Format: {value}'\n",
        "                else:\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = f'Incorret Format: {value}'\n",
        "\n",
        "    df_new = df_new.dropna(how='all', axis=1).fillna('Ok')       \n",
        "\n",
        "    return df_new\n",
        "\n",
        "\n",
        "ta_tme_cols = ['Código', 'Importe anual'] \n",
        "am= ['Importe anual']\n",
        "#ta_tme['Importe anual'] = ta_tme['Importe anual'].astype(str)\n",
        "df_ta_tme_amount = check_amounts(ta_tme, 'Código', ta_tme_cols, '.')\n",
        "df_ta_tme_amount\n",
        "# No errors"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXtLlVp91MJL"
      },
      "source": [
        "pathtw = '/content/TowerDB_Spain_20210809.xlsx'\n",
        "sheet= 'TA_Input_Lease_MM_Spain'\n",
        "skipr = 0\n",
        "skipc = 0\n",
        "ta_mm = pd.read_excel(pathtw, sheet)\n",
        "\n",
        "dates_ta_mm = ['Inicio','F/cie/tec/']\n",
        "for i in dates_ta_mm:\n",
        "    ta_mm[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in ta_mm[i]]\n",
        "\n",
        "ta_mm = ta_mm.fillna('')\n",
        "ta_mm = ta_mm[~(ta_mm['Importe anual']==\"\")]\n",
        "\n",
        "ta_mm.to_csv('/content/TA_Input_Lease_MM_Spain_20210831.csv', encoding = 'windows-1252',index=False)\n",
        "ta_mm.head(2)\n",
        "#ta_mm = ta_mm[ta_mm['Inicio']!=\"\"]\n",
        "\n",
        "#NO erros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DpZJWkpToWq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "c4d4cfa5-e9f7-4940-f517-85eb1504694a"
      },
      "source": [
        "def check_lc_ta_dates(df,tw_index, start_date,end_date):\n",
        "    #Fit dates to correct format to compare\n",
        "    df[start_date] = pd.to_datetime(df[start_date], format='%d/%m/%Y', errors='coerce')\n",
        "    df[end_date] = pd.to_datetime(df[end_date], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "    #filtering Dateframe for specific dates\n",
        "    filtered = df.loc[(df[start_date] > df[end_date])|(df[start_date]=='')|(df[end_date]==''), [tw_index, start_date,end_date]]\n",
        "\n",
        "    filtered[start_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[start_date]))\n",
        "    filtered[end_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[end_date]))\n",
        "    filtered = filtered[[tw_index, start_date,end_date]] \n",
        "    return filtered\n",
        "    \n",
        "df_ta_mm_dates = check_lc_ta_dates(ta_mm,'Código', 'Inicio','F/cie/tec/')\n",
        "df_ta_mm_dates \n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Código</th>\n",
              "      <th>Inicio</th>\n",
              "      <th>F/cie/tec/</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Código, Inicio, F/cie/tec/]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "GuPqvhvPDPku",
        "outputId": "30df5ee7-f721-4898-b900-2bf50d64f8db"
      },
      "source": [
        "def check_amounts(df_check, df_index, columns, pattern=','):\n",
        "    \"\"\"\n",
        "    Paramns:\n",
        "    pattern: general (. to decimal), other (, to decimal)\n",
        "    \"\"\"\n",
        "\n",
        "    df = df_check[columns]\n",
        "    df['sites'] = df[df_index]\n",
        "    df = df.set_index('sites')\n",
        "\n",
        "    df_new = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    df_duplicates = count_duplicates(df[df_index])\n",
        "    if not df_duplicates.empty:\n",
        "        df.drop_duplicates(subset=[df_index], inplace=True)\n",
        "\n",
        "    for site in df[df_index]:\n",
        "        for column in columns[1:]:\n",
        "            value = str(df.loc[site,column])\n",
        "            if not value.__contains__(pattern):\n",
        "                if df.loc[site,df_index] not in df_new.index:\n",
        "                    df_new.loc[site,df_index] = df.loc[site,df_index]\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = f'Incorret Format: {value}'\n",
        "                else:\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = f'Incorret Format: {value}'\n",
        "\n",
        "    df_new = df_new.dropna(how='all', axis=1).fillna('Ok')       \n",
        "    return df_new\n",
        "\n",
        "\n",
        "ta_mm_cols = ['Código', 'Importe anual']  \n",
        "\n",
        "ta_mm['Importe anual'] = ta_mm['Importe anual'].astype(str)\n",
        "df_ta_mm_amount = check_amounts(ta_mm, 'Código', ta_mm_cols, '.')\n",
        "df_ta_mm_amount\n",
        "# No errors\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vquhmwrK1MX7"
      },
      "source": [
        "pathtw = '/content/TowerDB_Spain_20210809.xlsx'\n",
        "sheet= 'TA_Input_Lease_Others_Spain'\n",
        "skipr = 0\n",
        "skipc = 0\n",
        "ta_others = pd.read_excel(pathtw, sheet)\n",
        "\n",
        "dates_ta_ot = ['Inicio','F/cie/tec/']\n",
        "for i in dates_ta_ot:\n",
        "    ta_others[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in ta_others[i]]\n",
        "\n",
        "ta_others = ta_others.fillna('')\n",
        "ta_others = ta_others[~(ta_others['Importe anual']==\"\")]\n",
        "\n",
        "ta_others.to_csv('/content/TA_Input_Lease_Other_Spain_20210831.csv', encoding = 'windows-1252',index=False)\n",
        "ta_others.head(3)\n",
        "#ta_others = ta_others.fillna('')\n",
        "#ta_others = ta_others[ta_others['Inicio']!=\"\"]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RUzKbZNUNnQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "a351e512-459f-4f54-98e9-17931c2cd540"
      },
      "source": [
        "def check_lc_ta_dates(df,tw_index, start_date,end_date):\n",
        "    #Fit dates to correct format to compare\n",
        "    df[start_date] = pd.to_datetime(df[start_date], format='%d/%m/%Y', errors='coerce')\n",
        "    df[end_date] = pd.to_datetime(df[end_date], format='%d/%m/%Y', errors='coerce')\n",
        "\n",
        "    #filtering Dateframe for specific dates\n",
        "    filtered = df.loc[(df[start_date] > df[end_date])|(df[start_date]=='')|(df[end_date]==''), [tw_index, start_date,end_date]]\n",
        "\n",
        "    filtered[start_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[start_date]))\n",
        "    filtered[end_date] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[end_date]))\n",
        "    filtered = filtered[[tw_index, start_date,end_date]] \n",
        "    return filtered\n",
        "    \n",
        "df_ta_o_dates = check_lc_ta_dates(ta_others,'Código', 'Inicio','F/cie/tec/')\n",
        "df_ta_o_dates\n",
        "#NO erros"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Código</th>\n",
              "      <th>Inicio</th>\n",
              "      <th>F/cie/tec/</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Código, Inicio, F/cie/tec/]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "dn4f57alDuRl",
        "outputId": "734f852f-6dbc-40b9-d25d-d389a725e561"
      },
      "source": [
        "def check_amounts(df_check, df_index, columns, pattern=','):\n",
        "    \"\"\"\n",
        "    Paramns:\n",
        "    pattern: general (. to decimal), other (, to decimal)\n",
        "    \"\"\"\n",
        "\n",
        "    df = df_check[columns]\n",
        "    df['sites'] = df[df_index]\n",
        "    df = df.set_index('sites')\n",
        "\n",
        "    df_new = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    df_duplicates = count_duplicates(df[df_index])\n",
        "    if not df_duplicates.empty:\n",
        "        df.drop_duplicates(subset=[df_index], inplace=True)\n",
        "\n",
        "    for site in df[df_index]:\n",
        "        for column in columns[1:]:\n",
        "            value = str(df.loc[site,column])\n",
        "            if not value.__contains__(pattern):\n",
        "                if df.loc[site,df_index] not in df_new.index:\n",
        "                    df_new.loc[site,df_index] = df.loc[site,df_index]\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = f'Incorret Format: {value}'\n",
        "                else:\n",
        "                    if value == '':\n",
        "                        df_new.loc[site,column] = 'Blank Value'\n",
        "                    else:\n",
        "                        df_new.loc[site,column] = f'Incorret Format: {value}'\n",
        "\n",
        "    df_new = df_new.dropna(how='all', axis=1).fillna('Ok')       \n",
        "    return df_new\n",
        "\n",
        "ta_o_cols = ['Código', 'Importe anual']\n",
        "\n",
        "df_ta_o_amount = check_amounts(ta_others, 'Código', ta_o_cols, '.')\n",
        "df_ta_o_amount\n",
        "# No errors\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmmoHOjkGnSO",
        "outputId": "99cf0577-012c-4c82-fac3-768e214fcd6c"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "logs_ta =[['OSP Amount Errors', df_ta_osp_amount],\n",
        "        ['OSP Dates Erros',df_ta_osp_dates],\n",
        "        ['TME Amount Errors', df_ta_tme_dates],\n",
        "        ['TME Dates Erros',df_ta_tme_amount],\n",
        "        ['MM Amount Errors', df_ta_mm_dates],\n",
        "        ['MM Dates Erros',df_ta_mm_amount],\n",
        "        ['Others Amount Errors', df_ta_o_dates],\n",
        "        ['Others Dates Erros',df_ta_o_amount]]\n",
        "        \n",
        "path_ta = '/content/TA_ES_Errors.xlsx'\n",
        "general_log_erros(logs_ta, path_ta)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No one log to write!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}