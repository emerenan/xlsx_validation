{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ro_validations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOc3c+9uEpMMpPSuyICj78v"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI87yjm0BP3x"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "def csv_files(path):\n",
        "    \"\"\"Função usada para ler os ficheiros que tem o simbolo do Euro\"\"\"\n",
        "    import csv\n",
        "    f = open(path, encoding='windows-1252', errors='ignore')\n",
        "    data = []\n",
        "    for row in csv.reader(f, delimiter=','):\n",
        "        data.append(row)\n",
        "    col = [*data[0]]\n",
        "    data.pop(0)\n",
        "    df = pd.DataFrame(data, columns=col)\n",
        "    return df, col\n",
        "\n",
        "def lower_str(columns):\n",
        "    newlist = list(map(lambda x: x.lower(), columns))\n",
        "    return newlist\n",
        "\n",
        "def change_incorret(df, df_index, col_chg, incorrect_value, new_value):\n",
        "    list_sites = list(df[df[col_chg]==incorrect_value][df_index])\n",
        "    df.loc[df[df_index].isin(list_sites), col_chg] = new_value\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iupK8WYif50b"
      },
      "source": [
        "\"\"\"Defining variables which is gonna be reusable in checks\"\"\"\n",
        "tw_index = 'code'\n",
        "tw_doer = 'date_of_equipment_removal'\n",
        "tw_status = 'site status'\n",
        "tw_bts = 'bts sites'\n",
        "tw_bill = 'rfai ( ready for active installation )'\n",
        "tw_wip = 'wip_site'\n",
        "tw_decom = 'decommissioned sites'\n",
        "tw_critical = 'critical site'\n",
        "\n",
        "msa_index = 'code'\n",
        "msa_doer = 'date_of_equipment_removal'\n",
        "msa_status = 'site status'\n",
        "msa_bts = 'bts sites'\n",
        "msa_bill = 'rfai ( ready for active installation )'\n",
        "msa_wip = 'wip_site'\n",
        "msa_decom = 'decommissioned sites'\n",
        "msa_critical = 'critical site'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGFC01Si4XVt"
      },
      "source": [
        "def lower_str(columns):\n",
        "        newlist = list(map(lambda x: x.lower(), columns))\n",
        "        #newlist = list(map(lambda x: re.sub(r'^\\s+|\\s+$', '', str(x.lower())), columns))\n",
        "        #newlist = list(map(lambda x: re.sub(r'\\s+$', '', str(x.lower())), columns))        \n",
        "        return newlist\n",
        "\n",
        "towerdb = pd.read_excel('/content/TowerDB_Romania_20210831 (1).xlsx', sheet_name='TowerDB')\n",
        "towerdb = towerdb.iloc[5:,:]\n",
        "towerdb.columns = lower_str(list(towerdb.columns))\n",
        "#df = df.rename(columns={'Billing Trigger Date': 'Billing Trigger Date2'})\n",
        "dic_cols = {'phase msa (phase 1)/pma (phase 2)':'phase _1/_2',\\\n",
        "        'categorization by transmission sys_1' : 'categorization by transmission sys.1',\\\n",
        "        'macro site - transmission hub site with/transmission hub site without shelters': 'macro site - transmission hub site with/without shelters',\\\n",
        "        'transmission sites – with/without shelters.' :'transmission sites - with/without shelters.',\\\n",
        "        'transmission hub sites’': 'transmission hub sites',\\\n",
        "        'easement (servitù di passaggio)': 'easement (servitu di passaggio)',\\\n",
        "        'unnamed: 35':'no_1',\\\n",
        "        'unnamed: 47':'no_2',\\\n",
        "        'rfai ( ready for active installation )' : 'rfai ( ready for active installation ) ',\\\n",
        "        #'diameter\\nvodafone antenna': 'diameter vodafone antenna',\\\n",
        "        ' current annual lease fees  ': 'current annual lease fees  ',\\\n",
        "        'energy cost fytd_mar_21': 'energy cost fytd_dec_20',\\\n",
        "        'energy consumption fytd_mar_20': 'energy consumption fytd_dec_20',\\\n",
        "        #'diameter\\n(orange rural & unilateranl ' : 'diameter (orange rural & unilateranl',\\\n",
        "        'tlk_1' : 'tlk.1',\\\n",
        "        'rcs&rds_1': 'rcs&rds.1',\\\n",
        "        'bts_site': 'bts sites',\\\n",
        "        'unnamed: 132':'no_3',\\\n",
        "        'unnamed: 134':'no_4'}\n",
        "towerdb = towerdb.rename(columns=dic_cols)\n",
        "#towerdb.columns = list(map(lambda x: re.sub(r'^\\s+|\\s+$', '', str(x.lower())), towerdb.columns.to_list()))\n",
        "\n",
        "dates_tw =['infrastructure ready (existing)/ to be ready (new)','billing trigger date','first_active_sharing_start_date',\n",
        "           'first_active_sharing_end_date','radio equipments to be deactivated by', 'rfai ( ready for active installation ) ', 'date_of_equipment_removal']\n",
        "        \n",
        "for i in dates_tw:\n",
        "    towerdb[i] = pd.to_datetime(towerdb[i])\n",
        "    towerdb[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) \\\n",
        "                    and not isinstance(date_obj, str) else '' for date_obj in towerdb[i]]\n",
        "    towerdb[i] = towerdb[i].astype(str)\n",
        "\n",
        "ints = ['orange passive shared sites ', 'tlk.1', 'orange', 'rcs&rds.1', 'otmos']\n",
        "for i in ints:\n",
        "    towerdb[i] = list(map(int, towerdb[i]))\n",
        "\n",
        "towerdb['no_1'] = ['' for i in range(towerdb.shape[0])]\n",
        "towerdb['no_2'] = ['' for i in range(towerdb.shape[0])]\n",
        "towerdb[tw_index] = list(map(str,towerdb[tw_index]))\n",
        "\n",
        "change_incorret(towerdb, tw_index,'air conditioning','YES','Yes')\n",
        "change_incorret(towerdb, tw_index,'air conditioning','no','No')\n",
        "change_incorret(towerdb, tw_index,'air conditioning',0,'No')\n",
        "change_incorret(towerdb, tw_index,'categorization by site type','DAS Passive','DAS passive')\n",
        "change_incorret(towerdb, tw_index,'strategic_site_bucket','No','Non Strategic')\n",
        "change_incorret(towerdb, tw_index,'decommissioned sites','NO','No')\n",
        "\n",
        "towerdb = towerdb.fillna('')\n",
        "\n",
        "#'Orange Passive Shared Sites',\\\n",
        "replace_cols = lower_str(['Code',\\\n",
        "             'Phase _1/_2',\\\n",
        "             'Categorization by Transmission Sys',\\\n",
        "\t\t\t 'Unused sites (TowerCo holds the property rights but does not host any Operator Equipment or Other Customer equipment )',\\\n",
        "\t\t\t 'Non-Vodafone equipment Sites (TowerCo holds the property rights and does not host any Operator Equipment but hosts Other Customer equipment  )',\\\n",
        "\t\t\t 'PowerOff Sites',\\\n",
        "\t\t\t 'Decommissioned sites',\\\n",
        "\t\t\t 'Categorization by Transmission Sys (sub-cluster)',\\\n",
        "\t\t\t 'Core Type',\\\n",
        "             'macro site - transmission hub site with/without shelters',\\\n",
        "\t\t\t 'Transmission sites - with/without shelters.',\\\n",
        "\t\t\t 'Room Configuration',\\\n",
        "             'Power Supply',\\\n",
        "\t\t\t 'Air Conditioning',\\\n",
        "\t\t\t 'Active Sharing Arrangements involving the Operator',\\\n",
        "             'Categorization by Site Type',\\\n",
        "\t\t\t 'Orange Active Shared Sites ',\\\n",
        "\t\t\t '10% Critical',\\\n",
        "\t\t\t 'Bundled sites',\\\n",
        "\t\t\t 'Strategic Sites',\\\n",
        "\t\t\t 'Unilateral Orange Transmission Site',\\\n",
        "\t\t\t 'First 10 Unilateral Orange Transmission Site',\\\n",
        "\t\t\t 'Wip_Site',\\\n",
        "\t\t\t 'Bts Sites',\\\n",
        "\t\t\t 'Sites_As_Metered_Estimated',\\\n",
        "\t\t\t 'Strategic_Site_Bucket',\\\n",
        "\t\t\t 'Subsequent_Sharing_Arrangement',\\\n",
        "\t\t\t 'Sites_Within_500_Macro_Sites',\\\n",
        "\t\t\t 'X',\\\n",
        "\t\t\t 'Site Status',\\\n",
        "             'Critical site'])  \n",
        "          \n",
        "for i in replace_cols:\n",
        "    towerdb[i] = towerdb[i].replace([0, 'N/A', 'n/a', '0', ' '], '')\n",
        "\n",
        "path_msa = '/content/TowerDB_Romania_20210731.csv'\n",
        "msa = pd.read_csv(path_msa, encoding='latin').fillna('')\n",
        "msa.columns = lower_str(list(msa.columns))\n",
        "msa = msa.rename(columns={\n",
        "    'phase msa (phase 1)/pma (phase 2)': 'phase _1/_2',\n",
        "    'transmission sites \\x96 with/without shelters.': 'transmission sites - with/without shelters.',\n",
        "    'transmission hub sites\\x92': 'transmission hub sites',\n",
        "    #'diameter\\nvodafone antenna': 'diameter vodafone antenna',\n",
        "    #'diameter\\n(orange rural & unilateranl ' : 'diameter (orange rural & unilateranl',\n",
        "    'easement (servitù di passaggio)': 'easement (servitu di passaggio)',\n",
        "    'unnamed: 35':'no_1',\n",
        "    'unnamed: 47':'no_2',\n",
        "    'unnamed: 132':'no_3',\n",
        "    'unnamed: 134':'no_4'})\n",
        "#msa.columns = [re.sub(r'^\\s+|\\s+$', '', str(x.lower())) for x in msa.columns.to_list()]\n",
        "msa.head(3)\n",
        "\n",
        "towerdb = towerdb[list(msa.columns)]\n",
        "towerdb = towerdb.rename(columns={\n",
        "    'no_1':'',\n",
        "    'no_2':'',\n",
        "    'no_3':'',\n",
        "    'no_4':''})\n",
        "\n",
        "towerdb.to_csv('/content/TowerDB_Romania_20210831.csv', index=False)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mI-deOvolRP",
        "outputId": "b23d5920-5ea0-4caf-cd8c-41420e9925ab"
      },
      "source": [
        "from collections import defaultdict\n",
        "bill_cols = lower_str(['Code',\\\n",
        "             'Phase _1/_2',\\\n",
        "             'Categorization by Transmission Sys',\\\n",
        "\t\t\t 'Unused sites (TowerCo holds the property rights but does not host any Operator Equipment or Other Customer equipment )',\\\n",
        "\t\t\t 'Non-Vodafone equipment Sites (TowerCo holds the property rights and does not host any Operator Equipment but hosts Other Customer equipment  )',\\\n",
        "\t\t\t 'PowerOff Sites',\\\n",
        "\t\t\t 'Decommissioned sites',\\\n",
        "\t\t\t 'Categorization by Transmission Sys (sub-cluster)',\\\n",
        "\t\t\t 'Core Type',\\\n",
        "             'macro site - transmission hub site with/without shelters',\\\n",
        "\t\t\t 'Transmission sites - with/without shelters.',\\\n",
        "\t\t\t 'Room Configuration',\\\n",
        "             'Power Supply',\\\n",
        "\t\t\t 'Air Conditioning',\\\n",
        "\t\t\t 'Active Sharing Arrangements involving the Operator',\\\n",
        "             'Categorization by Site Type',\\\n",
        "\t\t\t 'Billing Trigger Date',\\\n",
        "\t\t\t 'current annual lease fees  ',\\\n",
        "             'Orange Passive Shared Sites ',\\\n",
        "\t\t\t 'Orange Active Shared Sites ',\\\n",
        "\t\t\t '10% Critical',\\\n",
        "\t\t\t 'Bundled sites',\\\n",
        "\t\t\t 'Strategic Sites',\\\n",
        "\t\t\t 'Unilateral Orange Transmission Site',\\\n",
        "\t\t\t 'First 10 Unilateral Orange Transmission Site',\\\n",
        "\t\t\t 'Transfer_Date_Of_Registration_Required_Sites',\\\n",
        "\t\t\t 'Wip_Site',\\\n",
        "\t\t\t 'Bts Sites',\\\n",
        "\t\t\t 'Sites_As_Metered_Estimated',\\\n",
        "\t\t\t 'Strategic_Site_Bucket',\\\n",
        "\t\t\t 'Subsequent_Sharing_Arrangement',\\\n",
        "             'First_Active_Sharing_Start_Date',\\\n",
        "             'First_Active_Sharing_End_Date',\\\n",
        "\t\t\t 'Sites_Within_500_Macro_Sites',\\\n",
        "\t\t\t 'Date_Of_Equipment_Removal',\\\n",
        "\t\t\t 'RFAI ( Ready For Active Installation ) ',\\\n",
        "\t\t\t 'X',\\\n",
        "\t\t\t 'Site Status',\\\n",
        "             'Critical site'])\n",
        "\n",
        "errors = ['0', '_']\n",
        "\n",
        "err_dic = defaultdict(list)\n",
        "for i in bill_cols:\n",
        "    for value in towerdb[i]:\n",
        "        if value in errors:\n",
        "            err_dic[i].append(value)\n",
        "err_dic"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list, {})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dodwtpu6yAGd"
      },
      "source": [
        "In month Checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRyJlck4cn50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "a4598f4d-d594-4967-b113-3b4e947368af"
      },
      "source": [
        "\"\"\"Check Columns Received\"\"\" \n",
        "def check_columns_received(df, msa_cols):\n",
        "    twdb_col = lower_str(list(df.columns))\n",
        "    col_miss = [i for i in msa_cols if i not in twdb_col]\n",
        "\n",
        "    df_col_missing = pd.DataFrame(col_miss, columns=['Column(s) Missing'], index=range(len(col_miss)))\n",
        "    return df_col_missing\n",
        "\n",
        "df_cols = check_columns_received(towerdb, lower_str(list(msa.columns)))\n",
        "#No columns missing\n",
        "df_cols"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column(s) Missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no_4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Column(s) Missing\n",
              "0              no_1\n",
              "1              no_2\n",
              "2              no_3\n",
              "3              no_4"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM4xIb3-8GlD"
      },
      "source": [
        "First Check - Dates Formats (dd/mm/YYYY)\n",
        "\n",
        "Columns: Date of equipment removal (from MAR´21)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8anMHTJbc8vS"
      },
      "source": [
        "def check_date_columns(df, df_index,status_col,columns, format):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    df_dates = df[columns]\n",
        "    df_dates['sites'] = df_dates[df_index]\n",
        "    df_dates = df_dates.set_index('sites')\n",
        "\n",
        "    df_de = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    df_duplicates = count_duplicates(df_dates[df_index])\n",
        "    if not df_duplicates.empty:\n",
        "        df_dates.drop_duplicates(subset=[df_index], inplace=True)\n",
        "\n",
        "    filtered = df[[df_index, status_col]]\n",
        "\n",
        "    if format == 1:\n",
        "        date_format = re.compile(r'\\d{2}\\-\\d{2}\\-\\d{4}')\n",
        "        for de_site in df_dates[df_index]:\n",
        "            for de_column in columns[1:]:\n",
        "                #match = re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', df_dates.loc[ta_site,ta_column])\n",
        "                #print(type(df_dates.loc[de_site,de_column]))\n",
        "                value = df_dates.loc[de_site,de_column]\n",
        "                if date_format.match(value) == None:\n",
        "                    if df_dates.loc[de_site,df_index] not in df_de.index:\n",
        "                        df_de.loc[de_site,df_index] = df_dates.loc[de_site,df_index]\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                    else:\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "        df_de = df_de.dropna(how='all', axis=1).fillna('Ok')       \n",
        "        if not df_de.empty:\n",
        "            df_de.reset_index()\n",
        "            df_de = pd.merge(df_de, filtered, how='left', on=df_index)\n",
        "            df_de = df_de[[df_index, status_col, *columns[1:]]]\n",
        "            return df_de\n",
        "        else: \n",
        "            print('\\nNo one columns with incorrect date format!\\n')\n",
        "    else:\n",
        "        date_format = re.compile(r'\\d{2}\\/\\d{2}\\/\\d{4}')\n",
        "        for de_site in df_dates[df_index]:\n",
        "            for de_column in columns[1:]:\n",
        "                #match = re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', df_dates.loc[ta_site,ta_column])\n",
        "                value = df_dates.loc[de_site,de_column]\n",
        "                if date_format.match(value) == None:\n",
        "                    if df_dates.loc[de_site,df_index] not in df_de.index:\n",
        "                        df_de.loc[de_site,df_index] = df_dates.loc[de_site,df_index]\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                    else:\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                            \n",
        "        df_de = df_de.dropna(how='all', axis=1).fillna('Ok')       \n",
        "        if not df_de.empty:\n",
        "            df_de.reset_index()\n",
        "            df_de = pd.merge(df_de, filtered, how='left', on=df_index)\n",
        "            #df_de = df_de[[df_index, status_col, *columns[1:]]]\n",
        "            return df_de\n",
        "        else: \n",
        "            print('\\nNo one columns with incorrect date format!\\n')\n",
        "\n",
        "# Columns to functions\n",
        "dates_doer = [tw_index, tw_doer]\n",
        "dates_bill = [tw_index, tw_bill]\n",
        "\n",
        "#date_parser(towerdb, bill, \"%d/%m/%Y\", 'no')\n",
        "#date_parser(towerdb, doer, \"%d/%m/%Y\", 'mixed')\n",
        "\n",
        "actives = towerdb[towerdb[tw_status]=='In Service']\n",
        "\n",
        "no_actives = towerdb[towerdb[tw_status]=='Dismantled']\n",
        "\n",
        "\"\"\"Checking columns for errors\"\"\"\n",
        "actives_dates_errors = check_date_columns(actives, tw_index, tw_status, dates_bill, 2) \n",
        "# Actives sites with blank billing trigger date\n",
        "\n",
        "no_actives_dates_errors = check_date_columns(no_actives, tw_index,tw_status, dates_doer, 2) \n",
        "#No errors\n",
        "print(actives_dates_errors)\n",
        "print(no_actives_dates_errors)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSv0C2ur9NVi"
      },
      "source": [
        "Thirth - Check Picklist values All sites\n",
        "\n",
        "Do this check in all sites\n",
        "\n",
        "Check the picklist for each case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umJ5BWMYbtmC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "dcea26da-76cb-4c8f-d904-955b01d20096"
      },
      "source": [
        "def check_picklist_v1(df,df_index,df_status, df_cols, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    \"\"\"for id in df_picklist[df_index]:\n",
        "        if id not in new_dic.keys():\n",
        "            new_dic[df_index].append(id)\"\"\" \n",
        "            \n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]): \n",
        "                if pd.isnull(value) or pd.isna(value) or value=='' or value=='nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors[df_index] = df_picklist[df_index]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, df_status]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[df_status]+ df_errors.columns[:-1].tolist()]\n",
        "    #df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "picklist_tw_general = {\n",
        "    'categorization by transmission sys': ['0','Long-term Mobile', 'Macro', 'Outdoor Small Cells', 'Public DAS',\\\n",
        "                                           'Repeater', 'Transmission', 'w/o equipment']\n",
        "}\n",
        "pick_col_general = ['code', 'categorization by transmission sys']\n",
        "\n",
        "df_general_pick = check_picklist_v1(towerdb, tw_index, tw_status, pick_col_general, picklist_tw_general)\n",
        "df_general_pick\n",
        "#no errors"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site status</th>\n",
              "      <th>categorization by transmission sys</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>code</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A5321</th>\n",
              "      <td>WIP</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N6548</th>\n",
              "      <td>WIP</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N4622</th>\n",
              "      <td>WIP</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      site status categorization by transmission sys\n",
              "code                                                \n",
              "A5321         WIP                        Blank Value\n",
              "N6548         WIP                        Blank Value\n",
              "N4622         WIP                        Blank Value"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e3gpaf6KufS"
      },
      "source": [
        "Fifth Check MoM Sites (BTS, decomissoned...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbjKDt7UKBs9",
        "outputId": "cc968456-856a-40f1-e5aa-6afb970a5b27"
      },
      "source": [
        "def check_mom_bts(df_tw, tw_index,status_col, tw_col, df_msa, msa_index, msa_col):\n",
        "\n",
        "    msa_bts = df_msa[df_msa[msa_col]=='Yes']\n",
        "    msa_bts_sites = [i for i in msa_bts[msa_index]]\n",
        "\n",
        "    tw_bts = df_tw[df_tw[tw_col]=='Yes']\n",
        "    tw_bts_sites = [i for i in tw_bts[tw_index]]\n",
        "\n",
        "    out_tower_bts = [i for i in msa_bts_sites if i not in tw_bts_sites]\n",
        "    filtered = tw_bts[tw_bts[tw_index].isin(out_tower_bts)]\n",
        "\n",
        "    return filtered[[tw_index,status_col, tw_col]]    \n",
        "\n",
        "df_mom_bts = check_mom_bts(actives, tw_index,tw_status, tw_bts, msa, msa_index, msa_bts)\n",
        "df_mom_bts\n",
        "# No one error df_mom_bts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "No Errors Founded!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKLJPDH0S3Ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bec8c05-4764-4074-f5d6-4599f6beca35"
      },
      "source": [
        "def check_mom_bts(df_tw, tw_index,status_col, tw_col, df_msa, msa_index, msa_col):\n",
        "\n",
        "    msa_bts = df_msa[df_msa[msa_col]=='Yes']\n",
        "    msa_bts_sites = [i for i in msa_bts[msa_index]]\n",
        "\n",
        "    tw_bts = df_tw[df_tw[tw_col]=='Yes']\n",
        "    tw_bts_sites = [i for i in tw_bts[tw_index]]\n",
        "\n",
        "    out_tower_bts = [i for i in msa_bts_sites if i not in tw_bts_sites]\n",
        "    filtered = tw_bts[tw_bts[tw_index].isin(out_tower_bts)]\n",
        "\n",
        "    return filtered[[tw_index,status_col, tw_col]]    \n",
        "\n",
        "decomiss = towerdb[towerdb[tw_decom]=='Yes']\n",
        "df_mom_decom = check_mom_bts(decomiss, tw_index, tw_status, tw_decom, msa, msa_index, msa_decom)\n",
        "#No errors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "No Errors Founded!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqO-e_WvWHr0"
      },
      "source": [
        "Check Picklist and dates formats for In service sites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti-SjgXhU5Sr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "dece2e2e-67ad-4ed5-fc28-da844f49e514"
      },
      "source": [
        "def check_picklist_v1(df,df_index,df_status, df_cols, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    \"\"\"for id in df_picklist[df_index]:\n",
        "        if id not in new_dic.keys():\n",
        "            new_dic[df_index].append(id)\"\"\" \n",
        "            \n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]): \n",
        "                if pd.isnull(value) or pd.isna(value) or value=='' or value=='nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors[df_index] = df_picklist[df_index]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, df_status]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[df_status]+ df_errors.columns[:-1].tolist()]\n",
        "    #df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "picklis_dict = {\n",
        "    'categorization by transmission sys': ['Long-term Mobile', 'Macro', 'Outdoor Small Cells', 'Public DAS',\\\n",
        "                                           'Repeater', 'Transmission', 'w/o equipment'],\n",
        "    'categorization by site type': ['DAS passive','GBT','RTT', 'Outdoor Small Cells'],\n",
        "    'sites_as_metered_estimated': ['Estimated Model','Metered Model'],\n",
        "    'air conditioning': ['No','Yes'],\n",
        "    'bts sites': ['Yes', 'No'],\n",
        "    'strategic sites': ['Yes', 'No'],\n",
        "    'strategic_site_bucket': ['Non Strategic'],\n",
        "    'critical site': ['Yes', 'No'],\n",
        "    '10% critical': ['Beyond 10%', 'Within 10%','Non Critical'],\n",
        "    'wip_site': ['Yes', 'No'],\n",
        "    'bundled sites': ['Yes', 'No'],\n",
        "    'decommissioned sites': ['Yes', 'No']\n",
        "}\n",
        "\n",
        "picklist_cols = ['Code','Categorization by Transmission Sys','Categorization by Site Type','Sites_As_Metered_Estimated',\\\n",
        "                'Air Conditioning','bts sites','Strategic Sites',\\\n",
        "                'Strategic_Site_Bucket','Critical site','10% Critical','Wip_Site','Bundled sites','Decommissioned sites']\n",
        "actives = towerdb[towerdb[tw_status]=='In Service']\n",
        "df_in_service_picklist = check_picklist_v1(actives, tw_index,tw_status, lower_str(picklist_cols), picklis_dict)\n",
        "df_in_service_picklist\n",
        "#Tem error em 4 colunas "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site status</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [site status]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P92ob_0t8ahp"
      },
      "source": [
        "def check_date_columns(df, df_index,status_col,columns, format):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    df_dates = df[columns]\n",
        "    df_dates['sites'] = df_dates[df_index]\n",
        "    df_dates = df_dates.set_index('sites')\n",
        "\n",
        "    df_de = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    df_duplicates = count_duplicates(df_dates[df_index])\n",
        "    if not df_duplicates.empty:\n",
        "        df_dates.drop_duplicates(subset=[df_index], inplace=True)\n",
        "\n",
        "    filtered = df[[df_index, status_col]]\n",
        "\n",
        "    if format == 1:\n",
        "        date_format = re.compile(r'\\d{2}\\-\\d{2}\\-\\d{4}')\n",
        "        for de_site in df_dates[df_index]:\n",
        "            for de_column in columns[1:]:\n",
        "                #match = re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', df_dates.loc[ta_site,ta_column])\n",
        "                #print(type(df_dates.loc[de_site,de_column]))\n",
        "                value = df_dates.loc[de_site,de_column]\n",
        "                if date_format.match(value) == None:\n",
        "                    if df_dates.loc[de_site,df_index] not in df_de.index:\n",
        "                        df_de.loc[de_site,df_index] = df_dates.loc[de_site,df_index]\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                    else:\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "        df_de = df_de.dropna(how='all', axis=1).fillna('Ok')       \n",
        "        if not df_de.empty:\n",
        "            df_de.reset_index()\n",
        "            df_de = pd.merge(df_de, filtered, how='left', on=df_index)\n",
        "            df_de = df_de[[df_index, status_col, *columns[1:]]]\n",
        "            return df_de\n",
        "        else: \n",
        "            print('\\nNo one columns with incorrect date format!\\n')\n",
        "    else:\n",
        "        date_format = re.compile(r'\\d{2}\\/\\d{2}\\/\\d{4}')\n",
        "        for de_site in df_dates[df_index]:\n",
        "            for de_column in columns[1:]:\n",
        "                #match = re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', df_dates.loc[ta_site,ta_column])\n",
        "                value = df_dates.loc[de_site,de_column]\n",
        "                if date_format.match(value) == None:\n",
        "                    if df_dates.loc[de_site,df_index] not in df_de.index:\n",
        "                        df_de.loc[de_site,df_index] = df_dates.loc[de_site,df_index]\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                    else:\n",
        "                        if pd.isnull(value) or pd.isna(value) or value == 'nan' or value=='':\n",
        "                            df_de.loc[de_site,de_column] = 'Blank Value'\n",
        "                        else:\n",
        "                            df_de.loc[de_site,de_column] = f'Incorret picklist value: {value}'\n",
        "                            \n",
        "        df_de = df_de.dropna(how='all', axis=1).fillna('Ok')       \n",
        "        if not df_de.empty:\n",
        "            df_de.reset_index()\n",
        "            df_de = pd.merge(df_de, filtered, how='left', on=df_index)\n",
        "            df_de = df_de[[df_index, status_col, *columns[1:]]]\n",
        "            return df_de\n",
        "        else: \n",
        "            print('\\nNo one columns with incorrect date format!\\n')\n",
        "\n",
        "#check dates in columns\n",
        "start_dates = ['first_active_sharing_start_date', 'first_active_sharing_end_date']\n",
        "\n",
        "#date_parser(actives, start_dates, \"%d/%m/%Y\", 'no')\n",
        "#actives['First_Active_Sharing_End_Date'] = actives['First_Active_Sharing_End_Date'].fillna('')\n",
        "in_service_cols = [tw_index, 'first_active_sharing_start_date', 'first_active_sharing_end_date']\n",
        "df_in_service_dates = check_date_columns(actives, tw_index,tw_status, in_service_cols, 2)\n",
        "df_in_service_dates\n",
        "# Varias linhas em branco\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnjM9tBg_T3u"
      },
      "source": [
        "Fifth Check BTS Flagged(Billing Trigger and Commercial)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMuKKxOQ_GDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f54c61ae-5bd7-4219-d316-6a3ece732779"
      },
      "source": [
        "def check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col):\n",
        "    \n",
        "    t = type_col.lower()\n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "        \n",
        "    if t == 'doer':\n",
        "        df_tw[date_col]= pd.to_datetime(df_tw[date_col], format='%d/%m/%Y', errors='coerce')\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&((df_tw[date_col] < current_date)|(df_tw[date_col]==''))]\n",
        "        filtered[date_col] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[date_col]))\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "    else:\n",
        "        #df_tw[date_col]= pd.to_datetime(df_tw[date_col], format='%d/%m/%Y', errors='coerce')\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&(df_tw[date_col]=='')]\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        " \n",
        "actives_1 = towerdb[towerdb[tw_status]=='In Service']\n",
        "status = 'Yes'\n",
        "df_bts_empty = check_tw_bill_doer(actives_1, tw_index, tw_bill, tw_bts, status, 'bill')\n",
        "df_bts_empty\n",
        "#no errors"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>bts sites</th>\n",
              "      <th>rfai ( ready for active installation )</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [code, bts sites, rfai ( ready for active installation )]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jgeXm_3PADC"
      },
      "source": [
        "\"\"\" BTS sites\"\"\"\n",
        "path_uip = '/content/UserInput_Romania_20210830.xlsx'\n",
        "uip_names = ['Site_ID','Site Categorization', 'BTS site applicable charge (Annual)',\\\n",
        "             'Commercials for sites beyond 10% cap of critical sites (Annual)']\n",
        "uip = pd.read_excel(path_uip ,sheet_name='SiteLevel',usecols=[0,1,2,3],skiprows=2).fillna('')\n",
        "uip.columns = uip_names\n",
        "uip = uip.iloc[1:, :]\n",
        "\n",
        "msa_sites = [i for i in msa[msa_index]]\n",
        "tw_sites = [i for i in towerdb[tw_index]]\n",
        "uip_sites = [str(i) for i in uip['Site_ID']]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIk8H4EHCFgK"
      },
      "source": [
        "Usar as datas no formato Datetime para rodar esse check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMY_QvNfBj_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ee23af-f751-44a9-f359-bd4eaf22d69a"
      },
      "source": [
        "\"\"\" BTS sites\"\"\"\n",
        "def check_new_sites(df_towerdb, tw_index, bts_col, bill_col, status_col, msa_list, towerdb_list, uip_list):\n",
        "    \n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "    \n",
        "    filtered = df_towerdb[[tw_index, status_col]]\n",
        "\n",
        "    #Finding for ALL NEW SITES\n",
        "    new_site = [i for i in towerdb_list if i not in msa_list]\n",
        "    new_sites = pd.DataFrame(new_site, columns=['New_Sites'])\n",
        "    new_sites = pd.merge(new_sites, filtered, how='left', left_on=['New_Sites'], right_on=tw_index)\n",
        "    new_sites = new_sites[['New_Sites', status_col]]\n",
        "\n",
        "    #create a copy to make index modifications\n",
        "    df = df_towerdb.copy()\n",
        "\n",
        "    #New columns with Site Codes\n",
        "    df['Sites'] = df[tw_index]\n",
        "    #defining site code to index\n",
        "    df.set_index('Sites', inplace=True)\n",
        "\n",
        "    #filtering by new sites\n",
        "    df = df[df[tw_index].isin(new_site)]\n",
        "\n",
        "    # Save information os sites with demerged date more than current date\n",
        "    df[bill_col] = pd.to_datetime(df[bill_col], format='%d/%m/%Y', errors='coerce')\n",
        "    df_site_bts = df[(df[bts_col]=='Yes')&(df[bill_col] > current_date)].fillna('')\n",
        "    df_site_bts[bill_col] = list(map(lambda x: f'{x:%d/%m/%Y}', df_site_bts[bill_col]))\n",
        "    df_site_bts = df_site_bts[[tw_index,status_col, bts_col, bill_col]]\n",
        "    \n",
        "    #if not (new_sites.empty or bts_out_uis.empty or df_site_bts.empty):\n",
        "    return new_sites, df_site_bts[[tw_index,status_col, bts_col, bill_col]]\n",
        "\n",
        "new_sites, df_bts_errors = check_new_sites(towerdb, tw_index, tw_bts, tw_bill,tw_status, msa_sites, tw_sites, uip_sites)\n",
        "\n",
        "print(new_sites)\n",
        "print(df_bts_errors)\n",
        "#No errors"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [New_Sites, site status]\n",
            "Index: []\n",
            "Empty DataFrame\n",
            "Columns: [code, site status, bts sites, rfai ( ready for active installation )]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kisNTXB568E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3-ETlMrDIc9"
      },
      "source": [
        "Check WIP Flagged sites\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK_EajFZDe9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bed01f8-d0cf-4c23-e780-779edbc2f562"
      },
      "source": [
        "\"\"\" Wip Sites Check\"\"\"\n",
        "def check_wip(df_tw,tw_index, wip_tw, tw_bts, tw_status, df_msa, msa_index, wip_msa_col):\n",
        "\n",
        "    wip_msa = [i for i in df_msa[df_msa[msa_wip]=='Yes'][msa_index]]\n",
        "    \n",
        "    tw_wip_sites = [str(i) for i in df_tw[df_tw[wip_tw]=='Yes'][tw_index]]\n",
        "\n",
        "    tw_wip_site_bts_flagged = df_tw[(df_tw[wip_tw]=='Yes')&(df_tw[tw_bts]=='Yes')]\n",
        "    tw_wip_site_bts_flagged = tw_wip_site_bts_flagged[[tw_index, wip_tw, tw_bts]]\n",
        "    \n",
        "    #wip_out_tw_list = [i for i in tw_wip_sites if i not in wip_msa]\n",
        "    return tw_wip_site_bts_flagged\n",
        "\n",
        "df_wip_and_bts_flagged = check_wip(towerdb,tw_index, tw_wip, tw_bts,tw_status, msa, msa_index, msa_wip)\n",
        "\n",
        "print(df_wip_and_bts_flagged)\n",
        "# No errors"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [code, wip_site, bts sites]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMXe7u9QGApN"
      },
      "source": [
        "Check Decomissioned sites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaBUKjONFrwo"
      },
      "source": [
        "def check_decommissioned(df,df_index,status_col, decom_col, doer_col):\n",
        "    filtered = df[(df[decom_col]=='Yes')&(df[doer_col]==\"\")]\n",
        "    return filtered[[df_index, decom_col, doer_col]]\n",
        "  \n",
        "df_decom_sites = check_decommissioned(towerdb, tw_index,tw_status, tw_decom, tw_doer)\n",
        "df_decom_sites\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV7zVfu4GIvZ"
      },
      "source": [
        "Check Doer columns for in service sites\n",
        "\n",
        "Should not to be in past or different of blank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RPXbD-FHSNu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "065e50b7-92ff-4944-fc8d-75cc491c0f48"
      },
      "source": [
        "#Coluna Doer tem valores fora do formato\n",
        "def check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col):\n",
        "    t = type_col.lower()\n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "        \n",
        "    if t == 'doer':\n",
        "        df_tw[date_col]= pd.to_datetime(df_tw[date_col], format='%d/%m/%Y', errors='coerce')\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&((df_tw[date_col] < current_date)|(df_tw[date_col]==''))]\n",
        "        filtered[date_col] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[date_col]))\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "    else:\n",
        "\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&(df_tw[date_col]=='')]\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "\n",
        "actives = towerdb[towerdb[tw_status]=='In Service']\n",
        "df_doer = check_tw_bill_doer(actives, tw_index, tw_doer, tw_status, 'In Service', 'doer')\n",
        "df_doer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>site status</th>\n",
              "      <th>date_of_equipment_removal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [code, site status, date_of_equipment_removal]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ2sZAchIsyE"
      },
      "source": [
        "BTS sites are in subsequent Month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAnIM7eEH8Ub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3075232-de65-40fe-bc7e-f828744dd916"
      },
      "source": [
        "#Retorna os sites novos\n",
        "def check_bts(df_tw, bts_tw_columns, tw_index, status_col, df_msa, bts_msa_column, msa_index):\n",
        "\n",
        "    bts_msa = [i for i in msa[msa[bts_msa_column]=='Yes'][msa_index]]\n",
        "    tw_bts_sites = [i for i in df_tw[df_tw[bts_tw_columns]=='Yes'][tw_index]]\n",
        "    #return of datas\n",
        "    bts_out_tw = [i for i in bts_msa if i not in tw_bts_sites]\n",
        "    filtered = df_tw.loc[df_tw[tw_index].isin(bts_out_tw), [tw_index, status_col, bts_tw_columns]]\n",
        "    return filtered\n",
        "\n",
        "df_bts_out = check_bts(towerdb, tw_bts, tw_index, tw_status, msa, msa_bts, msa_index)\n",
        "df_bts_out\n",
        "#No errors\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "No errors founded!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcBDakUFKwun"
      },
      "source": [
        "*Tenth* - Check UIP Towerdb matches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch405uueK0UG"
      },
      "source": [
        "def check_uip_tw(df_tw,tw_index, status_tw_col, decom_col, tw_bts_col, tw_critical_col, df_uip, uip_sites):\n",
        "\n",
        "    filtered = df_tw[[tw_index, status_tw_col, decom_col, tw_bts_col]]\n",
        "    #tw_active = df_tw[df_tw['Site Status']=='In Service']\n",
        "    count_tw_sites = [str(i) for i in df_tw[df_tw[status_tw_col] =='In Service'][tw_index]]\n",
        "\n",
        "    # check number of sites that are in uip file and doesn't have in df_tw\n",
        "    #if not set(count_tw_sites).intersection(uip_sites):\n",
        "    uis_sites_not_in_towerdb = [i for i in uip_sites if i not in count_tw_sites]\n",
        "\n",
        "    uis_sites_not_in_towerdb = pd.DataFrame(uis_sites_not_in_towerdb,columns=['UIS In Month not active in TowerDB!'])\n",
        "    uis_sites_not_in_towerdb = pd.merge(uis_sites_not_in_towerdb, filtered, how='left', left_on='UIS In Month not active in TowerDB!',\\\n",
        "                                    right_on=tw_index)\n",
        "    uis_sites_not_in_towerdb = uis_sites_not_in_towerdb[['UIS In Month not active in TowerDB!', status_tw_col]]\n",
        "\n",
        "    in_service_not_in_uis = [i for i in count_tw_sites if i not in uip_sites]\n",
        "    in_service_not_in_uis = pd.DataFrame(in_service_not_in_uis,columns=['TowerDB Sites out of UIS In Month!'])\n",
        "    in_service_not_in_uis = pd.merge(in_service_not_in_uis, filtered, how='left', left_on='TowerDB Sites out of UIS In Month!',\\\n",
        "                                    right_on=tw_index)\n",
        "    in_service_not_in_uis = in_service_not_in_uis[['TowerDB Sites out of UIS In Month!', status_tw_col]]\n",
        "    #check for decomissioned site not in uip files\n",
        "\n",
        "\n",
        "    tw_decomiss = [str(i) for i in df_tw[df_tw[decom_col]=='Yes'][tw_index] if i in uip_sites]\n",
        "    decomiss_sites_in_uip = pd.DataFrame(tw_decomiss, columns=['Decomissioned Site in UIS File'])\n",
        "    decomiss_sites_in_uip = pd.merge(decomiss_sites_in_uip, filtered, how='left', left_on='Decomissioned Site in UIS File',\\\n",
        "                                    right_on=tw_index)\n",
        "    decomiss_sites_in_uip = decomiss_sites_in_uip[['Decomissioned Site in UIS File', status_tw_col, decom_col]]\n",
        "\n",
        "    #Check BTS sites\n",
        "        #Check BTS sites\n",
        "    bts_sites = [str(i) for i in df_tw[df_tw[tw_bts_col]=='Yes'][tw_index]]\n",
        "    uip_bts = [i for i in df_uip[df_uip['BTS site applicable charge (Annual)']!='']['Site_ID']]\n",
        "    bts_sites_out_uip = [i for i in uip_bts if i not in bts_sites]\n",
        "    bts_sites_out_uip = pd.DataFrame(bts_sites_out_uip, columns=['UIS BTS not in TowerDB(BTS)'])\n",
        "    bts_sites_out_uip = pd.merge(bts_sites_out_uip, filtered, how='left', left_on='UIS BTS not in TowerDB(BTS)',\\\n",
        "                                    right_on=tw_index)\n",
        "    bts_sites_out_uip = bts_sites_out_uip[['UIS BTS not in TowerDB(BTS)', status_tw_col, tw_bts_col]]\n",
        "\n",
        "    #  Check for UIP critical sites \n",
        "    uip_critical = [i for i in df_uip[df_uip['Commercials for sites beyond 10% cap of critical sites (Annual)']!='']['Site_ID']]\n",
        "    bts_tw_critical = df_tw[df_tw[tw_critical_col]=='Beyond 10%'][tw_index]\n",
        "\n",
        "    critical = [i for i in uip_critical if i not in bts_tw_critical]\n",
        "    critical = pd.DataFrame(critical, columns=['Critical site(beyond 10%) out of UIS'])\n",
        "    critical = pd.merge(critical, filtered, how='left', left_on='Critical site(beyond 10%) out of UIS',right_on=tw_index)\n",
        "    critical = critical[['Critical site(beyond 10%) out of UIS', status_tw_col]]\n",
        "    #if not (in_service_uip_sites.empty or decomiss_sites_in_uip.empty or bts_sites_out_uip.empty or critical.empty):\n",
        "    return uis_sites_not_in_towerdb, in_service_not_in_uis, decomiss_sites_in_uip, bts_sites_out_uip, critical\n",
        "    \n",
        "uis_sites_not_in_towerdb, in_service_not_in_uis, decomiss_sites_in_uip, bts_sites_out_uip, critical = check_uip_tw(towerdb,tw_index, tw_status, \\\n",
        "                                                            tw_decom, tw_bts,tw_critical, \\\n",
        "                                                            uip, uip_sites)\n",
        "print(uis_sites_not_in_towerdb)\n",
        "print('\\n')\n",
        "print(in_service_not_in_uis)\n",
        "print('\\n')\n",
        "print(decomiss_sites_in_uip)\n",
        "print('\\n')\n",
        "print(critical)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA0Tlm-gM8-9"
      },
      "source": [
        "Commercial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-IxBhePM8fl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9fcb6f48-b69f-478c-949c-ac0f2898c499"
      },
      "source": [
        "def check_diffs_v2(path_current, path_last, cols_order, type_file='Excel', sheet='Commercial'):\n",
        "    def lower_str(columns):\n",
        "        newlist = list(map(lambda x: x.lower(), columns))\n",
        "        return newlist\n",
        "\n",
        "    def highlight_diff(data, color='yellow'):\n",
        "        attr = 'background-color: {}'.format(color)\n",
        "        other = data.xs('Current', axis='columns', level=-1)\n",
        "        return pd.DataFrame(np.where(data.ne(other, level=0), attr, ''),\n",
        "                            index=data.index, columns=data.columns)\n",
        "\n",
        "    _actual = pd.read_excel(path_current,sheet_name=sheet).fillna('')\n",
        "\n",
        "    _before = pd.read_excel(path_last,sheet_name=sheet).fillna('')\n",
        "\n",
        "    df_all = pd.concat([_actual, _before],axis='columns', keys=['Current', 'Last'])\n",
        "    df_final = df_all.swaplevel(axis='columns')[_actual.columns[1:]]\n",
        "\n",
        "    #df_final.style.apply(highlight_diff, axis=None)\n",
        "    return df_final[(_actual != _before).any(1)].style.apply(highlight_diff, axis=None)\n",
        "\n",
        "path_uis = '/content/UserInput_Romania_20210830.xlsx'\n",
        "path_before = '/content/UserInput_Romania_20210731.xlsx'\n",
        "commercial_diffs = check_diffs_v2(path_uis, path_before, '')\n",
        "commercial_diffs\n",
        "#Erro na Coluna Param2 Vazio no anterior preenchido no atual"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "#T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col5{\n",
              "            background-color:  yellow;\n",
              "        }</style><table id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" colspan=2>Sub_charge_Type</th>        <th class=\"col_heading level0 col2\" colspan=2>Param1</th>        <th class=\"col_heading level0 col4\" colspan=2>Param2</th>        <th class=\"col_heading level0 col6\" colspan=2>Data_Type</th>        <th class=\"col_heading level0 col8\" colspan=2>MSA Sites (Phase 1)\n",
              "Input_Value</th>        <th class=\"col_heading level0 col10\" colspan=2>PMA Sites (Phase 2)\n",
              "Input_Value</th>        <th class=\"col_heading level0 col12\" colspan=2>Description/Instruction</th>        <th class=\"col_heading level0 col14\" colspan=2>Frequency of Update</th>    </tr>    <tr>        <th class=\"blank level1\" ></th>        <th class=\"col_heading level1 col0\" >Current</th>        <th class=\"col_heading level1 col1\" >Last</th>        <th class=\"col_heading level1 col2\" >Current</th>        <th class=\"col_heading level1 col3\" >Last</th>        <th class=\"col_heading level1 col4\" >Current</th>        <th class=\"col_heading level1 col5\" >Last</th>        <th class=\"col_heading level1 col6\" >Current</th>        <th class=\"col_heading level1 col7\" >Last</th>        <th class=\"col_heading level1 col8\" >Current</th>        <th class=\"col_heading level1 col9\" >Last</th>        <th class=\"col_heading level1 col10\" >Current</th>        <th class=\"col_heading level1 col11\" >Last</th>        <th class=\"col_heading level1 col12\" >Current</th>        <th class=\"col_heading level1 col13\" >Last</th>        <th class=\"col_heading level1 col14\" >Current</th>        <th class=\"col_heading level1 col15\" >Last</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >7</th>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col0\" class=\"data row0 col0\" >LEGACY BASE SERVICE CHARGE FOR PHASE 1 SITE (MSA SITES ONLY)</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col1\" class=\"data row0 col1\" >LEGACY BASE SERVICE CHARGE FOR PHASE 1 SITE (MSA SITES ONLY)</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col2\" class=\"data row0 col2\" >LONG-TERM MOBILE SITES</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col3\" class=\"data row0 col3\" >LONG-TERM MOBILE SITES</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col4\" class=\"data row0 col4\" ></td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col5\" class=\"data row0 col5\" >LONG TERM MOBILE</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col6\" class=\"data row0 col6\" >NUMBER</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col7\" class=\"data row0 col7\" >NUMBER</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col8\" class=\"data row0 col8\" >12240</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col9\" class=\"data row0 col9\" >12240</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col10\" class=\"data row0 col10\" >12240</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col11\" class=\"data row0 col11\" >12240</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col12\" class=\"data row0 col12\" >- Annual value as per the MSA/ PMA\n",
              "- To be edited in case of changes in the MSA/ PMA/ Side Letter \n",
              "- Please enter an Annual value</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col13\" class=\"data row0 col13\" >- Annual value as per the MSA/ PMA\n",
              "- To be edited in case of changes in the MSA/ PMA/ Side Letter \n",
              "- Please enter an Annual value</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col14\" class=\"data row0 col14\" >Only in case of change in MSA/PMA/ Side letter</td>\n",
              "                        <td id=\"T_44d18f72_ff46_11eb_b04e_0242ac1c0002row0_col15\" class=\"data row0 col15\" >Only in case of change in MSA/PMA/ Side letter</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f555bb629d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx0hHrtCT-Pg"
      },
      "source": [
        "Verificar errors nas colunas "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUsKTgjPTSef"
      },
      "source": [
        "Creating Excel Log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocY1u4UrtNpQ"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "dfs = [['In Service Date Errors', actives_dates_errors],\n",
        "    ['Dismantled Dates Errors', no_actives_dates_errors]\n",
        "    ['General Picklist Errors', df_general_pick],\n",
        "    ['BTS In Month Errors', df_mom_bts],\n",
        "    ['Decom Dates Errors' df_mom_decom],\n",
        "    ['In Service Picklist Errors', df_in_service_picklist],\n",
        "    ['Actives Blank Dates', df_in_service_dates], \n",
        "    ['Decom dates Errors', df_decom_sites],\n",
        "    ['New Sites', new_sites],\n",
        "    ['New Sites Bill date errors', df_bts_errors],\n",
        "    ['WIP & BTS Fllaged', df_wip_and_bts_flagged],\n",
        "    ['DOER Dates Errors', df_doer],\n",
        "    ['BTS MSA not in TwDB', df_bts_out],\n",
        "    ['UIS In Month not active', uis_sites_not_in_towerdb],\n",
        "    ['TowerDB Sites out of UIS', in_service_not_in_uis],\n",
        "    ['Decom Sites in UIS', decomiss_sites_in_uip],\n",
        "    ['Critical Sites out UIS', critical]\n",
        "    ['Commercial Differences' , commercial_diffs]] \n",
        "\n",
        "path = '/content/TWDB_RO_errors.xlsx'\n",
        "general_log_erros(dfs, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goCqcbeIUO2E"
      },
      "source": [
        "TA Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccRAXkvYUTa0"
      },
      "source": [
        "ta_ord = ['Code',\n",
        " 'Main contract ID',\n",
        " 'Tenant Agreement (sub contract ID)',\n",
        " 'Tenant ID (customer ID)',\n",
        " 'Tenant Name',\n",
        " 'Classification',\n",
        " 'Current Annual Fee per Tenant (Annual Hosting (with Discount))',\n",
        " 'Current Annual Fee per Tenant (Annual Hosting (with Position Discount)',\n",
        " 'Current Annual Fee per Tenant (Annual Hosting (with Discount)).1',\n",
        " 'Current Annual Energy Fee',\n",
        " 'Current Annual Energy Fee.1',\n",
        " 'Current Annual Maintenance Fee',\n",
        " 'Current Annual Maintenance Fee.1',\n",
        " 'Current Other Services Fee',\n",
        " 'Current Other Services Fee.1',\n",
        " 'Starting date',\n",
        " 'Expiring date',\n",
        " 'Renewal Option',\n",
        " 'Expiring date after renewal',\n",
        " 'Terms of payments',\n",
        " 'Payment type',\n",
        " 'Index',\n",
        " 'Percentage',\n",
        " 'Indexation driver',\n",
        " 'VAT Subject',\n",
        " 'Percentage (VAT)',\n",
        " 'Termination Date']\n",
        "\n",
        "pathtw = '/content/TowerDB_Romania_20210831 (1).xlsx'\n",
        "sheet= 'Tenant Template'\n",
        "ta_dates = ['Starting date', 'Expiring date', 'Expiring date after renewal']\n",
        "ta_amount = ['Current Annual Fee per Tenant (Annual Hosting (with Discount))']\n",
        "ta_bill = ['Tenant Name','Classification','Starting date', 'Expiring date']\n",
        "\n",
        "#ta.columns= [re.sub(r'^\\s+|\\s+$', '', str(x.lower())) for x in ta.columns.to_list()]\n",
        "ta = pd.read_excel(pathtw, sheet_name = sheet, skiprows=7)\n",
        "ta = ta.iloc[:,2:]\n",
        "#df.columns= [re.sub(r'^\\s+|\\s+$', '', str(x.lower())) for x in df.columns.to_list()]\n",
        "ta = ta.dropna(subset=['Tenant Name'], axis=0)\n",
        "ta['Current Other Services Fee.1'] = ['' for i in ta['Code']]\n",
        "ta['Current Annual Fee per Tenant (Annual Hosting (with Discount)).1'] = ['' for i in ta['Code']]\n",
        "ta['Current Annual Maintenance Fee.1'] = ['' for i in ta['Code']]\n",
        "ta['Current Annual Energy Fee.1'] = ['' for i in ta['Code']]\n",
        "ta = ta[ta_ord]\n",
        "\n",
        "for i in ta_dates:\n",
        "    ta[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) \\\n",
        "             and not isinstance(date_obj, str) else '' for date_obj in ta[i]]\n",
        "\n",
        "\"\"\"df = replace_values(df, cols_amount, 0)\n",
        "for col in cols_amount:\n",
        "    df[col] = df[col].fillna(0)\n",
        "    df[col] = df[col].astype(int).apply(lambda x: f'{x:,}')\"\"\"\n",
        "\"\"\"df = replace_values(df, cols_int, 0)\n",
        "for col in cols_int:\n",
        "    df[col] = df[col].fillna(0)\n",
        "    df[col] = df[col].astype(int)\"\"\"\n",
        "\n",
        "for i in ta_bill:\n",
        "    ta[i] = ta[i].replace(['N/A', 'n/a',\"0\", np.nan,'nan'], '')\n",
        "#date_parser(df, cols_date, format, type_date)\n",
        "\n",
        "ta = ta.fillna('')\n",
        "\n",
        "ta = ta.rename(columns={'Current Annual Fee per Tenant (Annual Hosting (with Discount)).1': 'Current Annual Fee per Tenant (Annual Hosting (with Discount)).',\\\n",
        "                        'Current Annual Energy Fee.1': 'Current Annual Energy Fee.',\\\n",
        "                        'Current Annual Maintenance Fee.1': 'Current Annual Maintenance Fee.',\\\n",
        "                        'Current Other Services Fee.1': 'Current Other Services Fee.'})\n",
        "\n",
        "ta.to_csv('/content/TA_Input_Romenia_20210831.csv', index=False)\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3buhIjVzZawa"
      },
      "source": [
        "ta[ta_dates]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emhUCVG4WUMJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c50wrzc6DwEJ"
      },
      "source": [
        "# Check for empty fields or negative differences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKV6NE7O4kz-"
      },
      "source": [
        "import datetime as dt\n",
        "\n",
        "#Create dates in datetime format\n",
        "ta['end'] = [pd.to_datetime(i, format='%d/%m/%Y') if i!= '' else datetime(1999, 1, 1, 0, 0, 0) for i in ta['Expiring date']]\n",
        "ta['start'] = [pd.to_datetime(i, format='%d/%m/%Y') if i!= '' else datetime(1999, 1, 1, 0, 0, 0) for i in ta['Starting date']]\n",
        "#Create diff columns to get negative values\n",
        "ta['dt_dff'] = (ta['end'] - ta['start']).dt.days\n",
        "\n",
        "start_or_end_blank = (ta['Starting date']=='')|(ta['Expiring date']=='')|(ta['Expiring date after renewal']=='')\n",
        "negative_dates = (ta['dt_dff'] <= 0)\n",
        "cols = ['Code','Tenant Name', 'Starting date', 'Expiring date', 'Expiring date after renewal']\n",
        "ta_dates_errors = ta[start_or_end_blank|negative_dates][cols]\n",
        "\n",
        "ta_dates_errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_iBCm9ObrSY"
      },
      "source": [
        "ta =ta.drop(columns='end')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbkHmemhDo8g"
      },
      "source": [
        "# Check for empty Classification or Incorrect Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjDq1hYcmcux"
      },
      "source": [
        "df_class_error = ta[(ta['Classification']=='')|~(ta['Classification'].isin(['MNO', 'OTMO']))][['Code', 'Tenant Name', 'Classification']]\n",
        "df_class_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoxdsWPaD8Uu"
      },
      "source": [
        "# Log creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRizJmmh_9Ie"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "tas = [['Picklist Errors', df_class_error],\n",
        "       ['Dates Errors',df_class_error]]\n",
        "\n",
        "path = '/content/TA_RO_errors.xlsx'\n",
        "general_log_erros(tas, path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}