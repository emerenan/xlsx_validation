{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "de_validations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1beLa5nrAKyE8co1MoPnyTYu_aNS955Hi",
      "authorship_tag": "ABX9TyNAO+GpdMBm9hbcFOxbAlCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emerenan/xlsx_validation/blob/main/de_validations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fJokH_7lGGq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "def csv_files(path):\n",
        "    \"\"\"Função usada para ler os ficheiros que tem o simbolo do Euro\"\"\"\n",
        "    import csv\n",
        "    f = open(path, encoding='windows-1252', errors='ignore')\n",
        "    data = []\n",
        "    for row in csv.reader(f, delimiter=','):\n",
        "        data.append(row)\n",
        "    col = [*data[0]]\n",
        "    data.pop(0)\n",
        "    df = pd.DataFrame(data, columns=col)\n",
        "    return df, col\n",
        "\n",
        "def lower_str(columns):\n",
        "    newlist = list(map(lambda x: x.lower(), columns))\n",
        "    return newlist\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxdOa6NFIYru"
      },
      "source": [
        "Check TowerDB Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_hqckMPb96D"
      },
      "source": [
        "tw_index = 'code'\n",
        "tw_doer = 'date_of_equipment_removal'\n",
        "tw_status = 'site status (tims)'\n",
        "tw_bts = 'bts_sites'\n",
        "tw_bill = 'rfai ( ready for active installation ) '\n",
        "tw_wip = 'wip_sites'\n",
        "tw_decom = 'decommissioned site'\n",
        "tw_critical = 'criticalsite_beyond_10'\n",
        "\n",
        "msa_index = 'code'\n",
        "msa_doer = 'date_of_equipment_removal'\n",
        "msa_status = 'site status (tims)'\n",
        "msa_bts = 'bts_sites'\n",
        "msa_bill = 'rfai ( ready for active installation ) '\n",
        "msa_wip = 'wip_sites'\n",
        "msa_decom = 'decommissioned site'\n",
        "msa_critical = 'criticalsite_beyond_10'\n",
        "bill_col = lower_str([\"Code\",\"Categorization by Transmission Sys\",\"Categorization by Transmission Sys (sub-cluster)\",\\\n",
        "             \"Categorization by Site Type\",\\\n",
        "             \"Categorization by Strategic Site\",\"Categorization by Critical Site\",\"Site Cluster\",\\\n",
        "             \"Strategic Site Bucket\",\"Bts_sites\",\"CriticalSite_Beyond_10\",\"Sites As Metered Estimated\",\"Active Sharing Arrangement\",\\\n",
        "             \"Indoor_Site_Any_Climate_Control\",\"Outdoor_Site_With_Dc_Power\",\"Rfai_Date\",\"decommissioned site\",\\\n",
        "             \"Subsequent_Active_Sharing_Arrangement\",\"First_Active_Sharing_Deployment_Type\",\"First_Active_Sharing_Arrangement_Start_Date\",\\\n",
        "             \"First_Active_Sharing_Arrangement_End_Date\"])\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjkF85ID4ZZR"
      },
      "source": [
        "path_excel = '/content/Output - Skylon - TowerDB - Germany - Release6.3 20210726_Billing_ReducedScope_sharedwithCelfinet_v03 (1).xlsx'\n",
        "#towerdb = pd.read_csv(path_towerdb,encoding='latin')\n",
        "guideline = lower_str(['Code','Site Name','Macro Region','Region','Province','Municipality','Inhabitants','Address','Latitude','Longitude',\\\n",
        "             'Categorization by Transmission Sys','Categorization by Transmission Sys (sub-cluster)','Categorization by Site Type',\\\n",
        "             'Categorization by Indoor / Outdoor Site (Antennas)','Additional Site Type information','Categorization by Inhabitants',\\\n",
        "             'Rural/ Suburban/ Urban','Categorization by CONNECTIVITY','Technology VOD','POD ID','Energy Consumption current FY',\\\n",
        "             'Actual Energy Cost current FY','Infrastructure ready (existing)/ to be ready (new)','Infrastructure to be shared by',\\\n",
        "             'Counterpart','# of Lease Contracts','Current annual lease fees','Current energy lease fees','Current annual other fees',\\\n",
        "             'Total Annual Lease','(Average) residual duration','Maturity Cluster','ExCo rep. Avg Annual Lease costs',\\\n",
        "             'Total Energy Cost currrent FY (Energy provider + LL)','VOD (y/n)','Deutsche Telekom','Annual Fee per Tenant MNO1',\\\n",
        "             'Annual Energy Fee MNO1','Annual Maintenance Fee MNO1','Other Services Fee MNO1','Total Hosting Fee & Services MNO1',\\\n",
        "             'Residual duration MNO1','Maturity Clusters MNO1','Telefonica','Annual Fee per Tenant MNO2','Annual Energy Fee MNO2',\\\n",
        "             'Annual Maintenance Fee MNO2','Other Services Fee MNO2','Total Hosting Fee & Services MNO2','Residual duration MNO2',\\\n",
        "             'Maturity Clusters MNO2','E-Plus','Annual Fee per Tenant MNO3','Annual Energy Fee MNO3','Annual Maintenance Fee MNO3',\\\n",
        "             'Other Services Fee MNO3','Total Hosting Fee & Services','Residual duration MNO3','Maturity Clusters','# of OTMOs',\\\n",
        "             'Annual Fee from OTMOs','Annual Energy Fee from OTMOs','Annual Maintenance Fee OTMOs','Other Services Fee OTMOs',\\\n",
        "             'Total Hosting Fee & Services OTMOs','Average residual duration OTMOs','Maturity Clusters OTMOs','Total # of 3rd Party Tenants',\\\n",
        "             'Annual Fee from 3rd Party Tenants','Annual Energy Fee from 3rd Party Tenants','Annual Maintenance Fee from 3rd Party Tenants',\\\n",
        "             'Other Services Fee from 3rd Party Tenants','Total Hosting Fee & Services from 3rd Party Tenants',\\\n",
        "             'Weighted Average residual duration','Macro Cluster Tenancy','Macro Cluster Lease / Freeholds & Surface Right','Macro Cluster 1',\\\n",
        "             'Sites w/ at least a DDS (Lease Contract Type)','# of Tenants','Categorization by Tenant combination',\\\n",
        "             'Categorization by Type of Passive contracts','Categorization by Land/Surface ownership','In/Out',\\\n",
        "             'No of 3rd Party Tenants (PoP count)','Top cities classification','Type of Structure','Categorization by shared usage (contractual)',\\\n",
        "             'Categorization by Shared Usage (PoP count)','Security Class','Categorization by Sites with Single/Multiple Tower(s)',\\\n",
        "             'Categorization by Special Site/PLC','Categorization by Chimney-location','Categorization by Antenna Constraint',\\\n",
        "             'Categorization by 5G Roll-out Site','Categorization by Authority Site','Categorization by Transport-Sammler',\\\n",
        "             'Categorization by Strategic Site','Categorization by Dual Use Site','Categorization by Sublease Right','GBT Reserve Space','State',\\\n",
        "             'Postal code','Tower Height','Floor Space','Ground Register .1','Ground Register .2','Ground Register .3',\\\n",
        "             'Categorization by Critical Site','Site Cluster','infrastructure to be dismantled by','decommissioned site',\\\n",
        "             'Strategic Site Bucket','Bts_sites','CriticalSite_Beyond_10','Sites As Metered Estimated','Active Sharing Arrangement',\\\n",
        "             'Subsequent_Active_Sharing_Arrangement','First_Active_Sharing_Deployment_Type','First_Active_Sharing_Arrangement_Start_Date',\\\n",
        "             'First_Active_Sharing_Arrangement_End_Date','Indoor_Site_Any_Climate_Control','Outdoor_Site_With_Dc_Power','Rfai_Date',\\\n",
        "             'Cluster for non-enterprise DAS Sites','Site Status (TIMS)','Date_Of_Equipment_Removal'])\n",
        "\n",
        "towerdb = pd.read_excel(path_excel, sheet_name='TowerDB', skiprows=12)\n",
        "towerdb = towerdb.iloc[:, 2:]\n",
        "towerdb.columns = lower_str(list(towerdb.columns))\n",
        "\n",
        "path_msa = '/content/TowerDB_Germany_20210731.csv'\n",
        "msa = pd.read_csv(path_msa,encoding='latin')\n",
        "msa.columns = lower_str(list(msa.columns))\n",
        "\n",
        "columns_to_merge = ['code', 'annual maintenance fee mno3', 'categorization by critical site', 'e-plus', 'categorization by antenna constraint', 'ground register .3', 'criticalsite_beyond_10', 'energy consumption current fy', 'first_active_sharing_deployment_type', 'indoor_site_any_climate_control', 'total hosting fee & services', 'subsequent_active_sharing_arrangement', 'categorization by indoor / outdoor site (antennas)', 'outdoor_site_with_dc_power', 'additional site type information', 'annual fee per tenant mno3', 'total energy cost currrent fy (energy provider + ll)', 'rfai_date', 'cluster for non-enterprise das sites', 'residual duration mno3', 'other services fee mno3', 'actual energy cost current fy', 'annual energy fee mno3', 'ground register .2', 'first_active_sharing_arrangement_start_date', 'ground register .1', 'first_active_sharing_arrangement_end_date', 'maturity clusters']\n",
        "df_merge = msa[columns_to_merge]\n",
        "towerdb = pd.merge(towerdb, df_merge, how='left', on='code')\n",
        "\n",
        "towerdb = towerdb[guideline]\n",
        "\n",
        "dates_tw = ['first_active_sharing_arrangement_start_date','first_active_sharing_arrangement_end_date', 'date_of_equipment_removal']\n",
        "for i in dates_tw:\n",
        "    towerdb[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in towerdb[i]]\n",
        "\n",
        "ints = ['actual energy cost current fy', 'counterpart', '# of lease contracts', 'current energy lease fees',\\\n",
        "        'total annual lease', 'deutsche telekom', 'annual energy fee mno1', 'total hosting fee & services mno1', 'telefonica',\\\n",
        "        'annual energy fee mno2', '# of otmos', 'annual energy fee from otmos', 'total hosting fee & services otmos',\\\n",
        "        'total # of 3rd party tenants', 'annual energy fee from 3rd party tenants', 'annual maintenance fee from 3rd party tenants',\\\n",
        "        'other services fee from 3rd party tenants', 'total hosting fee & services from 3rd party tenants',\\\n",
        "        'no of 3rd party tenants (pop count)', 'security class']\n",
        "for i in ints:\n",
        "    towerdb[i] = towerdb[i].fillna(0)\n",
        "    towerdb[i] = list(map(int, towerdb[i]))\n",
        "\n",
        "bill_col = lower_str([\"Code\",\"Categorization by Transmission Sys\",\"Categorization by Transmission Sys (sub-cluster)\",\\\n",
        "             \"Categorization by Site Type\",\\\n",
        "             \"Categorization by Strategic Site\",\"Categorization by Critical Site\",\"Site Cluster\",\\\n",
        "             \"Strategic Site Bucket\",\"Bts_sites\",\"CriticalSite_Beyond_10\",\"Sites As Metered Estimated\",\"Active Sharing Arrangement\",\\\n",
        "             \"Indoor_Site_Any_Climate_Control\",\"Outdoor_Site_With_Dc_Power\",\"Rfai_Date\",\"decommissioned site\",\\\n",
        "             \"Subsequent_Active_Sharing_Arrangement\",\"First_Active_Sharing_Deployment_Type\",\"First_Active_Sharing_Arrangement_Start_Date\",\\\n",
        "             \"First_Active_Sharing_Arrangement_End_Date\"])\n",
        "\n",
        "for i in bill_col:\n",
        "    towerdb[i] = towerdb[i].replace(['N/A', 'n/a',\"0\", 0, '-'], '')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAHzwAxib_iy"
      },
      "source": [
        "# CSV Reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szr7BJa9rbpc"
      },
      "source": [
        "path_towerdb = '/content/TowerDB_Germany_20210731.csv'\n",
        "\n",
        "towerdb = pd.read_csv(path_towerdb,encoding='latin')\n",
        "towerdb.columns = lower_str(list(towerdb.columns))\n",
        "\n",
        "dates_tw = ['first_active_sharing_arrangement_start_date','first_active_sharing_arrangement_end_date', 'date_of_equipment_removal']\n",
        "for i in dates_tw:\n",
        "    towerdb[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in towerdb[i]]\n",
        "\n",
        "ints = ['security class', 'postal code']\n",
        "for i in ints:\n",
        "    towerdb[i] = towerdb[i].fillna(0)\n",
        "    towerdb[i] = list(map(int, towerdb[i]))\n",
        "\n",
        "#towerdb = towerdb.replace(['N/A', 'n/a',\"0\", '-', , np.nan,'nan'], '')\n",
        "towerdb = towerdb.fillna('')\n",
        "\n",
        "bill_col = lower_str(bill_col)\n",
        "for i in bill_col:\n",
        "    towerdb[i] = towerdb[i].replace(['N/A', 'n/a',\"0\", 0, '-'], '')\n",
        "\n",
        "\"\"\"Read MSA File\"\"\"\n",
        "path_old = '/content/TowerDB_Germany_20210630.csv'\n",
        "msa = pd.read_csv(path_old, encoding='latin1')\n",
        "msa_cols = lower_str(list(msa.columns))\n",
        "msa.columns = msa_cols\n",
        "\n",
        "towerdb = towerdb[msa_cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcGLWlcSCxLj"
      },
      "source": [
        "sites = [i for i in towerdb[towerdb['indoor_site_any_climate_control']=='Yes; Indoor Air Conditioning and Free Air cooling / Free cooling units']['site code']]\n",
        "towerdb.loc[towerdb['site code'].isin(sites), 'climate control (yes/no)'] = 'Yes; Indoor Air Conditioning'\n",
        "\n",
        "sites = [i for i in towerdb[towerdb['climate control (yes/no)']=='Yes; Indoor Free Air cooling / Free cooling units']['site code']]\n",
        "towerdb.loc[towerdb['site code'].isin(sites), 'climate control (yes/no)'] = 'Yes; Indoor Air Conditioning'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bCowhuYNcQ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "a206ac63-d2f8-40a1-d5df-61bf0e0cf585"
      },
      "source": [
        "\"\"\"First Step Check All columns received\"\"\"\n",
        "def check_columns_received(df, bill_cols):\n",
        "    twdb_col = lower_str(list(df.columns))\n",
        "    col_miss = [i for i in bill_cols if i not in twdb_col]\n",
        "    \"\"\"\n",
        "    for i in bill_cols:\n",
        "        if i not in twdb_col:\n",
        "            col_miss.append(i)\"\"\"\n",
        "    df_col_missing = pd.DataFrame(col_miss, columns=['Column(s) Missing'], index=range(len(col_miss)))\n",
        "    return df_col_missing\n",
        "\n",
        "#check billing columns\n",
        "df_col_missing = check_columns_received(towerdb, msa_cols)\n",
        "df_col_missing\n",
        "#tem error Falta Columns de Billing trigger"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column(s) Missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Column(s) Missing]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "cDQ9YxEkXM34",
        "outputId": "d8ebc2ff-fc32-455f-db96-d733e8af9d3f"
      },
      "source": [
        "def check_date_columns(df, df_index,status_col,columns):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_dates = df[columns].fillna('')\n",
        "    df_dates = df_dates.to_dict(orient='list')\n",
        "    #df_dates['sites'] = df_dates[df_index]\n",
        "    #df_dates = df_dates.set_index('sites')\n",
        "    new_dic = defaultdict(list)\n",
        "\n",
        "    date_format = re.compile(r\"[0-9]{1,2}[\\_|\\-|\\/][0-9]{1,2}[\\_|\\-|\\/][0-9]{1,4}\")\n",
        "\n",
        "    for column in set(df_dates.keys()):\n",
        "        for value in df_dates[column]:\n",
        "            if date_format.match(value) == None:\n",
        "                if value in (None, '', 'nan'):\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorret picklist value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors[df_index] = df[df_index]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, status_col]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[status_col]+ df_errors.columns[:-1].tolist()]\n",
        "    #df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "dates_cols = ['Date_Of_Equipment_Removal']\n",
        "dates_cols = lower_str(dates_cols)\n",
        "#Check dates of column 'Date_Of_Equipment_Removal' Pg 7\n",
        "#check_date_columns(df, df_index,status_col,columns, format)\n",
        "dftw_dates_errors = check_date_columns(towerdb, tw_index, tw_status, dates_cols) \n",
        "dftw_dates_errors"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site status (tims)</th>\n",
              "      <th>date_of_equipment_removal</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>code</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0001 B</th>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0001 D</th>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0001 M</th>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0001 O</th>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0001 S</th>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y157 M</th>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y158 M</th>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y159 M</th>\n",
              "      <td>In Service</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Z393 B</th>\n",
              "      <td>WIP</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Z816 D</th>\n",
              "      <td>WIP</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21431 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       site status (tims) date_of_equipment_removal\n",
              "code                                               \n",
              "0001 B         In Service               Blank Value\n",
              "0001 D         In Service               Blank Value\n",
              "0001 M         In Service               Blank Value\n",
              "0001 O         In Service               Blank Value\n",
              "0001 S         In Service               Blank Value\n",
              "...                   ...                       ...\n",
              "Y157 M         In Service               Blank Value\n",
              "Y158 M         In Service               Blank Value\n",
              "Y159 M         In Service               Blank Value\n",
              "Z393 B                WIP               Blank Value\n",
              "Z816 D                WIP               Blank Value\n",
              "\n",
              "[21431 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36VQ-uTqcuLR",
        "outputId": "e6c79910-d85c-469a-fecc-79e6e56bb0fb"
      },
      "source": [
        "towerdb[towerdb[tw_index]=='0001 B']['categorization by transmission sys']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Macro\n",
              "Name: categorization by transmission sys, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi5spCPz9iq2"
      },
      "source": [
        "\"\"\"Check all picklist Columns\"\"\"\n",
        "def check_picklist_v1(df,df_index,df_status, df_cols, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    \"\"\"for id in df_picklist[df_index]:\n",
        "        if id not in new_dic.keys():\n",
        "            new_dic[df_index].append(id)\"\"\" \n",
        "            \n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]): \n",
        "                if pd.isnull(value) or pd.isna(value) or value=='' or value=='nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    \n",
        "    if not df_errors.empty:\n",
        "        #df = df[[df_index, df_status]]\n",
        "        #df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "        df_errors[df_index] = df_picklist[df_index]\n",
        "        df_errors[df_status] = df_picklist[df_status]\n",
        "        df_errors = df_errors.set_index(df_index)\n",
        "        df_errors = df_errors.dropna(how='all', axis=0)\n",
        "        df_errors = df_errors[[df_status]+ df_errors.columns[:-1].tolist()]\n",
        "        df_errors = df_errors.reset_index()\n",
        "        return df_errors\n",
        "    else:\n",
        "        print('\\nNo one Picklist Error Founded!\\n')\n",
        "\n",
        "picklist_col = [\"Code\",'site status (tims)','Categorization by Transmission Sys','Categorization by Transmission Sys (sub-cluster)',\\\n",
        "            'Categorization by Site Type', 'Categorization by Indoor / Outdoor Site (Antennas)',\\\n",
        "            'Categorization by Strategic Site','Categorization by Critical Site', 'Strategic Site Bucket', 'Bts_sites',\\\n",
        "            'CriticalSite_Beyond_10','decommissioned site', 'Sites As Metered Estimated',\\\n",
        "            'Active Sharing Arrangement', 'Indoor_Site_Any_Climate_Control', 'Outdoor_Site_With_Dc_Power']\n",
        "picklist_col = lower_str(picklist_col)\n",
        "picklist = {\n",
        "    'categorization by transmission sys': ['Macro','Public DAS Sites','Repeater Sites','Transmission', 'Long-Term Mobile Sites', 'Non-Enterprise DAS'],\n",
        "    'categorization by transmission sys (sub-cluster)': ['Core', 'DAS', 'Long-term Mobile', 'Non-Enterprise DAS', 'Repeater', 'Standard', 'Transmission'],\n",
        "    'categorization by site type':['DAS','GBT','RTT', 'Non-Enterprise DAS'],\n",
        "    'categorization by indoor / outdoor site (antennas)': ['Outdoor', 'Indoor'],\n",
        "    'categorization by strategic site':['Yes','No'],\n",
        "    'categorization by critical site':['Yes','No'],\n",
        "    'strategic site bucket': ['Yes - 0-5%','Non Strategic'],\n",
        "    'bts_sites': ['Yes','No'],\n",
        "    'criticalsite_beyond_10': ['Beyond 10%','Within 10%','Non Critical'],\n",
        "    'decommissioned site': ['Yes', 'No'],\n",
        "    'sites as metered estimated': ['Estimated Model','Metered Model'],\n",
        "    'active sharing arrangement': ['No Active Sharing'],\n",
        "    'indoor_site_any_climate_control': ['No','Yes; Indoor Air Conditioning','Yes; Indoor Free Air cooling / Free cooling units'],\n",
        "    'outdoor_site_with_dc_power':['AC','DC','AC & DC','No Power']}\n",
        "actives = towerdb[towerdb[tw_status]=='In Service']\n",
        "df_picklist_errors = check_picklist_v1(actives,'code','site status (tims)',picklist_col, picklist)\n",
        "df_picklist_general = check_picklist_v1(towerdb,'code','site status (tims)',picklist_col, picklist)\n",
        "print(df_picklist_errors)\n",
        "print('\\n')\n",
        "print(df_picklist_general)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJK55G7ed--I"
      },
      "source": [
        "Falta UIS para gerar todos os Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxmlKKCF9VE-"
      },
      "source": [
        "#Read UIP File\n",
        "uip_names = ['Site_ID', 'BTS site applicable charge (Annual)', 'Commercials for sites beyond 10% cap of critical sites (Annual)']\n",
        "uip = pd.read_excel('/content/UserInput_Germany_20210831_InMonth.xlsx',sheet_name='SiteLevel',usecols=[0,1,2],skiprows=2)\n",
        "uip.columns = uip_names\n",
        "\n",
        "msa_sites = [i for i in msa[msa[msa_status]=='In Service']['code']]\n",
        "tw_sites = [i for i in towerdb[towerdb[tw_status]=='In Service']['code']]\n",
        "uip_sites = [i for i in uip['Site_ID']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rftVRqlT9TDW"
      },
      "source": [
        "\"\"\"Eigth Check for BTS sites\"\"\"\n",
        "def check_bts(df_tw, bts_tw_columns, tw_index, status_col, df_msa, bts_msa_column, msa_index):\n",
        "\n",
        "    bts_msa = msa[msa[bts_msa_column]=='Yes']\n",
        "    bts_msa = [str(i) for i in bts_msa[msa_index]]\n",
        "\n",
        "    tw_bts_sites = df_tw[df_tw[bts_tw_columns]=='Yes']\n",
        "    tw_bts_sites = [str(i) for i in tw_bts_sites[tw_index]]\n",
        "\n",
        "    #return of datas\n",
        "    filtered = df_tw[[tw_index, status_col, bts_tw_columns]]\n",
        "    bts_out_tw = [i for i in tw_bts_sites if i not in bts_msa]\n",
        "    df = pd.DataFrame(bts_out_tw, columns=['BTS MSA Out TowerDB'])\n",
        "    df = pd.merge(df, filtered, how='left', left_on=['BTS MSA Out TowerDB'], right_on=tw_index)\n",
        "    df = df[['BTS MSA Out TowerDB', status_col, bts_tw_columns]]\n",
        "    return df\n",
        "\n",
        "# Check for BTS sites\n",
        "df_bts_out_tw = check_bts(towerdb,tw_bts,tw_index,tw_status,msa,msa_bts,msa_index)\n",
        "df_bts_out_tw\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZDpKiiU9Ryi"
      },
      "source": [
        "\"\"\"Nineth - Check fopr decomissioned sites\"\"\"\n",
        "def check_decommissioned(df,df_index,status_col, decom_col, doer_col):\n",
        "    #c = country.lower()\n",
        "    sites = [i for i in df[df[decom_col]=='Yes'][df_index]]\n",
        "\n",
        "    filtered = df[(df[df_index].isin(sites))&(df[doer_col]==\"\")]\n",
        "    return filtered[[df_index,status_col, decom_col, doer_col]]\n",
        "\n",
        "#Validate Decomissioned Sites\n",
        "df_decom_errors = check_decommissioned(towerdb,tw_index, tw_status, 'decommissioned site', tw_doer)\n",
        "df_decom_errors\n",
        "#None errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Satoh09PTo"
      },
      "source": [
        "\"\"\"Tenth - Check Date Of Equipement Removed date for in service sites\"\"\"\n",
        "def check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col):\n",
        "    \n",
        "    t = type_col.lower()\n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "    df_tw = df_tw[df_tw[status_col]==status][[tw_index, status_col, date_col]] \n",
        "    dates = [i for i in df_tw[date_col] if i!= '']\n",
        "\n",
        "    if t == 'doer':\n",
        "        filtered = df_tw[df_tw[date_col].astype('datetime64[ns]') < current_date]\n",
        "        return filtered\n",
        "    else:\n",
        "        #bill_dates = pd.to_datetime(df_tw[date_col], errors==coerrce)\n",
        "        filtered = df_tw[df_tw[date_col]=='']\n",
        "        return filtered\n",
        "\n",
        "df_doer_errors = check_tw_bill_doer(towerdb, tw_index, tw_doer , tw_status,'In Service', 'doer')\n",
        "df_doer_errors\n",
        "# None Errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbCsf3dk9OOe"
      },
      "source": [
        "\"\"\"Eleventh - Check Month-on-Month towerdb sites\"\"\"\n",
        "def check_mom_bts(df_tw, tw_index,status_col,df_bts, df_msa, msa_index, msa_bts):\n",
        " \n",
        "    msa_bts_sites = [i for i in df_msa[df_msa[msa_bts]=='Yes'][msa_index]]\n",
        "\n",
        "    tw_bts_sites = [i for i in df_tw[df_tw[df_bts]=='Yes'][tw_index]]\n",
        "\n",
        "    out_tower_bts = [i for i in msa_bts_sites if i not in tw_bts_sites]\n",
        "\n",
        "    filtered = df_msa.loc[df_msa[tw_index].isin(out_tower_bts)]\n",
        "\n",
        "    return filtered[[tw_index,status_col, df_bts]]    \n",
        "\n",
        "df_mom_errors = check_mom_bts(towerdb,tw_index, tw_status, tw_bts, msa,msa_index, msa_bts)\n",
        "df_mom_errors\n",
        "# None Errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXqih0e49NDk"
      },
      "source": [
        "\"\"\"Twelveth - Match UIS sites with Towerdb Sites \"\"\"\n",
        "def check_uip_tw(df_tw,tw_index, status_tw_col,decom_col, tw_bts_col,tw_critical_col, df_uip, uip_sites):\n",
        "\n",
        "    filtered = df_tw[[tw_index, status_tw_col, tw_bts_col, decom_col]]\n",
        "    count_tw_sites = [i for i in df_tw[df_tw[status_tw_col] =='In Service'][tw_index]]\n",
        "\n",
        "    # check number of sites that are in uip file and doesn't have in df_tw\n",
        "    #if not set(count_tw_sites).intersection(uip_sites):\n",
        "    uis_sites_not_in_towerdb = [i for i in uip_sites if i not in count_tw_sites]\n",
        "\n",
        "    uis_sites_not_in_towerdb = pd.DataFrame(uis_sites_not_in_towerdb,columns=['UIS In Month not active in TowerDB!'])\n",
        "    uis_sites_not_in_towerdb = pd.merge(uis_sites_not_in_towerdb, filtered, how='left', left_on='UIS In Month not active in TowerDB!',\\\n",
        "                                    right_on=tw_index)\n",
        "    uis_sites_not_in_towerdb = uis_sites_not_in_towerdb[['UIS In Month not active in TowerDB!', status_tw_col]]\n",
        "    \n",
        "    in_service_not_in_uis = [i for i in count_tw_sites if i not in uip_sites]\n",
        "    in_service_not_in_uis = pd.DataFrame(in_service_not_in_uis,columns=['TowerDB Sites out of UIS In Month!'])\n",
        "    in_service_not_in_uis = pd.merge(in_service_not_in_uis, filtered, how='left', left_on='TowerDB Sites out of UIS In Month!',\\\n",
        "                                    right_on=tw_index)\n",
        "    in_service_not_in_uis = in_service_not_in_uis[['TowerDB Sites out of UIS In Month!', status_tw_col]]\n",
        "    \n",
        "    #Check Decomissioned Sites\n",
        "    tw_decomiss = [i for i in df_tw[df_tw[decom_col]=='Yes'][tw_index] if i in uip_sites]\n",
        "    decomiss_sites_in_uip = pd.DataFrame(tw_decomiss, columns=['Decomissioned Site in UIS File'])\n",
        "    decomiss_sites_in_uip = pd.merge(decomiss_sites_in_uip, filtered, how='left', left_on='Decomissioned Site in UIS File',\\\n",
        "                                    right_on=tw_index)\n",
        "    decomiss_sites_in_uip = decomiss_sites_in_uip[['Decomissioned Site in UIS File', status_tw_col, decom_col]]\n",
        "\n",
        "    bts_sites = [i for i in df_tw[df_tw[tw_bts_col]=='Yes'][tw_index]]\n",
        "    uip_bts = [i for i in df_uip[df_uip['BTS site applicable charge (Annual)']!=\"\"]['Site_ID']]   \n",
        "                           \n",
        "    #if not set(bts_sites).intersection(uip_sites):\n",
        "    bts_sites_out_uip = [i for i in uip_bts if i not in bts_sites]\n",
        "    bts_sites_out_uip = pd.DataFrame(bts_sites_out_uip, columns=['UIS BTS not in TowerDB(BTS)'])\n",
        "    bts_sites_out_uip = pd.merge(bts_sites_out_uip, filtered, how='left', left_on='UIS BTS not in TowerDB(BTS)',\\\n",
        "                                    right_on=tw_index)\n",
        "    bts_sites_out_uip = bts_sites_out_uip[['UIS BTS not in TowerDB(BTS)', status_tw_col, tw_bts_col]]\n",
        "\n",
        "    bts_tw_critical = [i for i in df_tw[df_tw[tw_critical_col]=='Beyond 10%'][tw_index]]\n",
        "    critical = [i for i in bts_tw_critical if i not in uip_critical]\n",
        "    critical = pd.DataFrame(critical, columns=['Sites Beyond 10% out UIS'])\n",
        "    critical = pd.merge(critical, filtered, how='left', left_on='Sites Beyond 10% out UIS',\\\n",
        "                                    right_on=tw_index)\n",
        "    critical = critical[['Sites Beyond 10% out UIS', status_tw_col]]\n",
        "\n",
        "    #if not (in_service_uip_sites.empty or decomiss_sites_in_uip.empty or bts_sites_out_uip.empty or critical.empty):\n",
        "    return uis_sites_not_in_towerdb, in_service_not_in_uis,decomiss_sites_in_uip, bts_sites_out_uip, critical\n",
        "\n",
        "uis_sites_not_in_towerdb, in_service_not_in_uis,decomiss_sites_in_uip,  bts_sites_out_uip, critical = check_uip_tw(towerdb, tw_index, tw_status,tw_decom, tw_bts, \\\n",
        "                                                                                            tw_critical, uip, uip_sites)\n",
        "print(uis_sites_not_in_towerdb)\n",
        "print('\\n')\n",
        "print(in_service_not_in_uis)\n",
        "print('\\n')\n",
        "print(decomiss_sites_in_uip)\n",
        "print('\\n')\n",
        "print(bts_sites_out_uip)\n",
        "print('\\n')\n",
        "print(critical)\n",
        "#None Errors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcvYu4xZ9JAI"
      },
      "source": [
        "Commercial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpAIShm69IWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65174412-3ed0-4bca-d67e-2fa0ab780e5f"
      },
      "source": [
        "act = '/content/UserInput_Germany_20210831_InMonth.xlsx'\n",
        "old = '/content/UserInput_Germany_20210731_InMonth.xlsx'\n",
        "cols_ordered = ['Charge_Type','Sub_charge_Type', 'Param1','Param2', 'Data_Type','Input_Value_actual', 'Input_Value_before',\\\n",
        "                'Equal Values','Description/Instruction', 'Frequency of Update']\n",
        "merge_cols = ['Charge_Type','Sub_charge_Type', 'Param1','Param2', 'Data_Type', 'Description/Instruction', 'Frequency of Update']\n",
        "name = ['Charge_Type','Sub_charge_Type', 'Param1','Param2', 'Data_Type', 'Input_Value', 'Description/Instruction', 'Frequency of Update'] \n",
        "col = ['Input_Value']               \n",
        "def check_commercial(path_current, path_before, col_replace, col_names, merge_cols, col_order):\n",
        "    \n",
        "    def replace_values(df, columns, value=\"\"):\n",
        "        \"\"\"\n",
        "        Está voltando para float\n",
        "        \"\"\"\n",
        "        invalid_values = ['N/A', 'n/a',\"0\", '-', '_', np.nan,'nan']\n",
        "        #lista = []\n",
        "\n",
        "        df.fillna(0, inplace=True)\n",
        "        #df[column] = df[column].astype('int64')\n",
        "\n",
        "        for column in columns:\n",
        "            lista = []\n",
        "            for index in df[column]:\n",
        "                #print(f\"{column} -> {index}\")\n",
        "                if index in invalid_values:\n",
        "                    lista.append(value)\n",
        "                else:\n",
        "                    lista.append(index)\n",
        "            df[column] = lista\n",
        "\n",
        "        return df    \n",
        "    def check_uip_commercial_values(df_actual, df_before, merge_cols):\n",
        "        df_atual = uip_comercial_actual\n",
        "        df_ant = uip_comercial_before\n",
        "        df_cross = pd.merge(df_actual, df_before, on=merge_cols, \\\n",
        "                            how='left', suffixes=('_actual', '_before'), indicator='Exist')\n",
        "        df_cross['Exist'] = np.where(df_cross.Exist == 'both', 'Yes', 'No')\n",
        "        df_cross['Equal Values'] = df_cross['Exist']\n",
        "        \n",
        "        return df_cross\n",
        "    \n",
        "    # Check for commercial Values into current UIP File and compare with UIP File before\n",
        "    uip_comercial_actual = pd.read_excel(path_current,sheet_name='Commercial', names=col_names).fillna('')\n",
        "    #uip_comercial_actual = uip_comercial_actual[['Charge_Type', 'Data_Type', 'Input_Value']]\n",
        "    uip_comercial_actual = replace_values(uip_comercial_actual, col_replace, value=0)\n",
        "\n",
        "    uip_comercial_before = pd.read_excel(path_before,sheet_name='Commercial', names=col_names ).fillna('')\n",
        "    #uip_comercial_before = uip_comercial_before[['Charge_Type', 'Data_Type', 'Input_Value']]\n",
        "    uip_comercial_before = replace_values(uip_comercial_before, col_replace, value=0)\n",
        "\n",
        "    df_commercial =  check_uip_commercial_values(uip_comercial_actual, uip_comercial_before, merge_cols).fillna('')\n",
        "\n",
        "    df_commercial = df_commercial.reindex(columns=col_order)\n",
        "    df_commercial_diffs = df_commercial[df_commercial['Equal Values']=='No']\n",
        "    if not df_commercial_diffs.empty:\n",
        "        return df_commercial_diffs\n",
        "    else:\n",
        "        print('\\nNo errors founded!')\n",
        "\n",
        "df_comm = check_commercial(act, old, col, name, merge_cols, cols_ordered)\n",
        "df_comm\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "No errors founded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 60
        },
        "id": "DV_IL-PfgBE2",
        "outputId": "ea38b5a1-6f41-4f1f-db7d-e6900d7056b7"
      },
      "source": [
        "def check_diffs_v2(path_current, path_last):\n",
        "    def lower_str(columns):\n",
        "        newlist = list(map(lambda x: x.lower(), columns))\n",
        "        return newlist\n",
        "\n",
        "    def highlight_diff(data, color='yellow'):\n",
        "        attr = 'background-color: {}'.format(color)\n",
        "        other = data.xs('Current', axis='columns', level=-1)\n",
        "        return pd.DataFrame(np.where(data.ne(other, level=0), attr, ''),\n",
        "                            index=data.index, columns=data.columns)\n",
        "\n",
        "    _actual = pd.read_excel(path_current,sheet_name='Commercial').fillna('')\n",
        "\n",
        "    _before = pd.read_excel(path_last,sheet_name='Commercial').fillna('')\n",
        "\n",
        "    df_all = pd.concat([_actual, _before],axis='columns', keys=['Current', 'Last'])\n",
        "    df_final = df_all.swaplevel(axis='columns')[_actual.columns[1:]]\n",
        "\n",
        "    #df_final.style.apply(highlight_diff, axis=None)\n",
        "    if not df_final.empty:\n",
        "        return df_final[(_actual != _before).any(1)].style.apply(highlight_diff, axis=None)\n",
        "    else:\n",
        "        print('\\nNo differences Founded!\\n')\n",
        "\n",
        "df_com_vf = check_diffs_v2(act, old)\n",
        "df_com_vf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_4e2983a6_002a_11ec_be57_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" colspan=2>Sub_charge_Type</th>        <th class=\"col_heading level0 col2\" colspan=2>Param1</th>        <th class=\"col_heading level0 col4\" colspan=2>Param2</th>        <th class=\"col_heading level0 col6\" colspan=2>Data_Type</th>        <th class=\"col_heading level0 col8\" colspan=2>Input_Value</th>        <th class=\"col_heading level0 col10\" colspan=2>Description/Instruction</th>        <th class=\"col_heading level0 col12\" colspan=2>Frequency of Update</th>    </tr>    <tr>        <th class=\"blank level1\" ></th>        <th class=\"col_heading level1 col0\" >Current</th>        <th class=\"col_heading level1 col1\" >Last</th>        <th class=\"col_heading level1 col2\" >Current</th>        <th class=\"col_heading level1 col3\" >Last</th>        <th class=\"col_heading level1 col4\" >Current</th>        <th class=\"col_heading level1 col5\" >Last</th>        <th class=\"col_heading level1 col6\" >Current</th>        <th class=\"col_heading level1 col7\" >Last</th>        <th class=\"col_heading level1 col8\" >Current</th>        <th class=\"col_heading level1 col9\" >Last</th>        <th class=\"col_heading level1 col10\" >Current</th>        <th class=\"col_heading level1 col11\" >Last</th>        <th class=\"col_heading level1 col12\" >Current</th>        <th class=\"col_heading level1 col13\" >Last</th>    </tr></thead><tbody>\n",
              "        </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f86c8e2e150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-j1sf25x31H"
      },
      "source": [
        "Generate xlsx Log with invalid or incorrect values founded in TowerDB File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI2QvNPKPguX"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0])\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0])\n",
        "\n",
        "    writer.save() \n",
        "\n",
        "log_dfs = [['DOER Dates Errors', dftw_dates_errors],\n",
        "           ['General Picklist Errors', df_picklist_general],\n",
        "           ['Actives Picklist Errors', df_picklist_errors],\n",
        "           ['Decom Sites Date Error', df_decom_errors],\n",
        "           ['DOER Dates Errors', df_doer_errors],\n",
        "           ['MSA BTS not in TowerDB', df_mom_errors],\n",
        "           ['UIS Sites not active in TowerDB', uis_sites_not_in_towerdb],\n",
        "           ['TowerDB Sites out of UIS', in_service_not_in_uis],\n",
        "           ['Decom Sites In UIS', decomiss_sites_in_uip],\n",
        "           ['UIS BTS not in TowerDB(BTS)', bts_sites_out_uip],\n",
        "           ['Sites Beyond 10% out UIS', critical],\n",
        "           ['Commercial Differences',df_comm]]\n",
        "\n",
        "path_errors = '/content/DE_TowerDB_Errors.xlsx'\n",
        "general_log_erros(log_dfs, path_errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8a5zTVJZdHb"
      },
      "source": [
        "TA Input File Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnfFQcl7xAeC"
      },
      "source": [
        "Special Case(Excel File)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB9VVfOCiUgD"
      },
      "source": [
        "path_in_month = '/content/Output - Skylon - TowerDB - Germany - Release6.3 20210726_Billing_ReducedScope_sharedwithCelfinet_v03 (1).xlsx'\n",
        "\n",
        "#towerdb[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in towerdb[i]]\n",
        "ta = pd.read_excel(path_in_month, sheet_name='TA_Input', skiprows=1)\n",
        "\n",
        "dates_ta = ['Starting date','Expiring date', 'Expiring date after renewal']\n",
        "for i in dates_ta:\n",
        "    ta[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in ta[i]]\n",
        "\n",
        "ta = ta.rename(columns={'Contract Migration Scope': 'Contract Migration Scope 14.05.2020'})\n",
        "ta.columns = lower_str(list(ta.columns))\n",
        "#ta.columns = list(map(lambda x: re.sub(r'^\\s+|\\s+$', '', str(x.lower())), ta.columns.to_list()))\n",
        "ta['tenant (id)'] = ta['tenant (id)'].fillna(0)\n",
        "ta['tenant (id)'] = ta['tenant (id)'].astype(int)\n",
        "\n",
        "guideline_ta = lower_str(['Code',\\\n",
        "          'Tenant Agreement',\n",
        "          'Tenant',\\\n",
        "          'Tenant Cluster',\\\n",
        "          'MNO Cluster',\\\n",
        "          'Tenant (ID)',\n",
        "          'Starting date','Expiring date',\\\n",
        "          'Annual Fee per Tenant',\n",
        "          'Overlapping days in FY20',\n",
        "          'Current Annual Fee per Tenant',\\\n",
        "          'Annual Energy Fee from 3rd Party Tenants',\n",
        "          'OTP Amount',\n",
        "          'Renewal option',\n",
        "          'Residual duration',\\\n",
        "          'Maturity Cluster',\n",
        "          'Contract Scope',\n",
        "          'Site Scope',\n",
        "          'Contract Migration Scope 14.05.2020',\n",
        "          'Comment'])\n",
        "\n",
        "ta = ta[guideline_ta]\n",
        "\n",
        "ta.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQgaEwLAnhO3"
      },
      "source": [
        "import pandas as pd\n",
        "#Read TA Input File\n",
        "path_ta_last = '/content/TA_Input_Germany_20210731.csv'\n",
        "\n",
        "ta_col = ['Code',\\\n",
        "          'Tenant Agreement',\n",
        "          'Tenant',\\\n",
        "          'Tenant Cluster',\\\n",
        "          'MNO Cluster',\\\n",
        "          'Tenant (ID)',\n",
        "          'Starting date','Expiring date',\\\n",
        "          ' Annual Fee per Tenant ',\n",
        "          'Overlapping days in FY20',\n",
        "          ' Current Annual Fee per Tenant ',\\\n",
        "          'Annual Energy Fee from 3rd Party Tenants',\n",
        "          ' OTP Amount ',\n",
        "          ' Renewal option ',\n",
        "          ' Residual duration ',\\\n",
        "          'Maturity Cluster',\n",
        "          'Contract Scope',\n",
        "          'Site Scope',\n",
        "          'Contract Migration Scope 14.05.2020',\n",
        "          'Comment']\n",
        "\n",
        "ta = pd.read_csv(path_ta_input, encoding='latin')\n",
        "\n",
        "dates_ta = ['Starting date','Expiring date', 'Expiring date after renewal']\n",
        "for i in dates_ta:\n",
        "    ta[i] = [date_obj.strftime(\"%d/%m/%Y\") if not pd.isnull(date_obj) else '' for date_obj in ta[i]]\n",
        "\n",
        "ta = ta[ta_col]\n",
        "\n",
        "ta_bill = ['Tenant Agreement','Tenant', 'Starting date','Expiring date']\n",
        "\n",
        "for i in ta_bill:\n",
        "    ta[i] = ta[i].replace(['N/A', 'n/a',\"0\", 0, '_',' ', np.nan,'nan'], '')\n",
        "\n",
        "ta.to_csv('/content/TA_Input_Germany_20210831.csv', index=False)\n",
        "\n",
        "ta.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiWCoNFiC-dW"
      },
      "source": [
        "def check_lc_ta_dates(df,tw_index, start_date,end_date):\n",
        "    df[start_date] = pd.to_datetime(df[start_date], format='%d/%m/%Y')\n",
        "    df[end_date] = pd.to_datetime(df[end_date] , format='%d/%m/%Y')\n",
        "    filtered = df[df[start_date] > df[end_date]]\n",
        "    return filtered[[tw_index, start_date,end_date]]\n",
        "\n",
        "#Check date format(dd/mm/YYYY)\n",
        "df_dates_erros = check_lc_ta_dates(ta, 'Code','Starting date', 'Expiring date')\n",
        "df_dates_erros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hLYxtCGr0pX"
      },
      "source": [
        "#Check Amount values\n",
        "def check_amounts(df_check, df_index, columns, pattern=','):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df = df_check[columns].fillna('')\n",
        "    df = df.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    for id in df_check[df_index]:\n",
        "        new_dic[df_index].append(id)\n",
        "\n",
        "    for column in columns:\n",
        "        for value in df[column]:\n",
        "            value = str(value)\n",
        "            if value == '':\n",
        "                new_dic[column].append('Blank')\n",
        "            elif not value.__contains__(pattern):\n",
        "                new_dic[column].append(f'Incorrect format: {value}')\n",
        "            else:\n",
        "                new_dic[column].append(\"Ok\")\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.replace('Ok', np.nan)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    return df_errors\n",
        "\n",
        "cols = lower_str(['Annual Fee per Tenant', 'Current Annual Fee per Tenant'])  \n",
        "            \n",
        "df = check_amounts(ta, 'code', cols,'.')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX3W3VkdyK_u"
      },
      "source": [
        "LC Input File Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEVcpBOrqHj9"
      },
      "source": [
        "path_lc = '/content/Output - Skylon - TowerDB - Germany - Release6.3 20210726_Billing_ReducedScope_sharedwithCelfinet_v03 (1).xlsx'\n",
        "\n",
        "lc = pd.read_excel(path_lc, sheet_name='LC_Input', skiprows=1)\n",
        "\n",
        "lc.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ4pbk9US_yM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "593dcca0-d2d5-44cf-d920-39e7cee237ef"
      },
      "source": [
        "#Read TA Input File\n",
        "lc_cols = ['Lease Contract ID','Code','Counterpart','Counterpart Cluster','Counterpart (ID)','Starting date','Expiring date',\\\n",
        "           ' Annual lease fees ','Overlapping days in FY20',' Current annual lease fees ',' OTP Amount ',\\\n",
        "           'Renewal option','(Average) residual duration','Maturity Cluster','Site Scope','Contract scope','MNO Cluster','reason for scope',\\\n",
        "           'Adjustment','+/-','Contract Migration Scope 14.05.2020']\n",
        "\n",
        "path_lc_input = '/content/LC_Input_Germany_20210731.csv'\n",
        "lc = pd.read_csv(path_lc_input, encoding='latin')\n",
        "\n",
        "lc_bill = ['Lease Contract ID', 'Starting date','Expiring date', ' Annual lease fees ']\n",
        "for i in lc_bill:\n",
        "    lc[i] = lc[i].replace(['N/A', 'n/a',\"0\", 0, '_',' ', np.nan,'nan'], '')\n",
        "lc = lc[lc_cols]\n",
        "\n",
        "lc.to_csv('/content/LC_Input_Germany_20210831.csv', index=False)\n",
        "lc.head(1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lease Contract ID</th>\n",
              "      <th>Code</th>\n",
              "      <th>Counterpart</th>\n",
              "      <th>Counterpart Cluster</th>\n",
              "      <th>Counterpart (ID)</th>\n",
              "      <th>Starting date</th>\n",
              "      <th>Expiring date</th>\n",
              "      <th>Annual lease fees</th>\n",
              "      <th>Overlapping days in FY20</th>\n",
              "      <th>Current annual lease fees</th>\n",
              "      <th>OTP Amount</th>\n",
              "      <th>Renewal option</th>\n",
              "      <th>(Average) residual duration</th>\n",
              "      <th>Maturity Cluster</th>\n",
              "      <th>Site Scope</th>\n",
              "      <th>Contract scope</th>\n",
              "      <th>MNO Cluster</th>\n",
              "      <th>reason for scope</th>\n",
              "      <th>Adjustment</th>\n",
              "      <th>+/-</th>\n",
              "      <th>Contract Migration Scope 14.05.2020</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1100002245/1100000642</td>\n",
              "      <td>0001 B</td>\n",
              "      <td>Gemeinn.Wohnungsbau AG Berlin</td>\n",
              "      <td>OTMO</td>\n",
              "      <td>800001944</td>\n",
              "      <td>05/12/1990</td>\n",
              "      <td>31/12/2030</td>\n",
              "      <td>8980.78</td>\n",
              "      <td>365</td>\n",
              "      <td>8980.7825</td>\n",
              "      <td>NaN</td>\n",
              "      <td>On-going</td>\n",
              "      <td>9.583333</td>\n",
              "      <td>&lt;= 10 years</td>\n",
              "      <td>in scope</td>\n",
              "      <td>In Scope</td>\n",
              "      <td>OTMO</td>\n",
              "      <td>condition, or indicator for one-time payment o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>In scope</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Lease Contract ID    Code  ...  +/- Contract Migration Scope 14.05.2020\n",
              "0  1100002245/1100000642  0001 B  ...  NaN                            In scope\n",
              "\n",
              "[1 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKAl12onDOyt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "fef557c1-1ef9-4b3b-d2f2-92db87046529"
      },
      "source": [
        "def check_lc_ta_dates(df,tw_index, start_date,end_date):\n",
        "    df[start_date] = pd.to_datetime(df[start_date], format='%d/%m/%Y')\n",
        "    df[end_date] = pd.to_datetime(df[end_date] , format='%d/%m/%Y')\n",
        "    filtered = df[df[start_date] > df[end_date]]\n",
        "    return filtered[[tw_index, start_date,end_date]]\n",
        "\n",
        "\n",
        "df_dates_erros = check_lc_ta_dates(lc, 'Code', 'Starting date', 'Expiring date')\n",
        "df_dates_erros\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>Starting date</th>\n",
              "      <th>Expiring date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Code, Starting date, Expiring date]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wipQ692frbT"
      },
      "source": [
        "def check_picklist_v1(df,df_index,df_status, df_cols, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    \"\"\"for id in df_picklist[df_index]:\n",
        "        if id not in new_dic.keys():\n",
        "            new_dic[df_index].append(id)\"\"\" \n",
        "            \n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]): \n",
        "                if pd.isnull(value) or pd.isna(value) or value=='' or value=='nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNxgSApsromn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "72395cf0-75c1-457d-e886-03842214d65e"
      },
      "source": [
        "def check_amounts(df_check, df_index, columns, pattern=','):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df = df_check[columns].fillna('')\n",
        "    df = df.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "    for id in df_check[df_index]:\n",
        "        new_dic[df_index].append(id)\n",
        "\n",
        "    for column in columns:\n",
        "        for value in df[column]:\n",
        "            value = str(value)\n",
        "            if value == '':\n",
        "                new_dic[column].append('Blank')\n",
        "            elif not value.__contains__(pattern):\n",
        "                new_dic[column].append(f'Incorrect format: {value}')\n",
        "            else:\n",
        "                new_dic[column].append(\"Ok\")\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.replace('Ok', np.nan)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    return df_errors\n",
        "\n",
        "lc_cols = ['Annual lease fees']\n",
        "lc_am = check_amounts(lc, 'Code',lc_cols, '.')\n",
        "lc_am"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    }
  ]
}