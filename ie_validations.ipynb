{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ie_validations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyF5MwoMhFi+4gYZlVmjx+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emerenan/xlsx_validation/blob/main/ie_validations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8It8h3GcBwr_"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "import re\n",
        "\n",
        "def lower_str(columns):\n",
        "    newlist = list(map(lambda x: x.lower(), columns))\n",
        "    return newlist\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyBxhhVnhluV"
      },
      "source": [
        "Towerdb File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "TSe_wC_GzTI6",
        "outputId": "d5740cef-1023-4957-9049-c0b6c77a675d"
      },
      "source": [
        "\"\"\" Need Unlock spreadsheet before\"\"\"\n",
        "path='/content/TowerDB_Ireland_20210630 v1.xlsx'\n",
        "sheet='TowerDB_Input_Ireland_20210630'\n",
        "skiprows=0\n",
        "skipcols=0\n",
        "\"\"\"A coluna Infrastructure Ready Date contem 0 e deve ser feito replace\"\"\"\n",
        "towerdb = pd.read_excel(path, sheet_name = sheet).fillna('')\n",
        "towerdb = towerdb.dropna(subset=['Site ID '], axis=0)\n",
        "\n",
        "dates_tw = ['Infrastructure Ready Date','Billing Trigger Date', 'BTS Site Acceptance Date', 'First_Active_Sharing_Start_Date', 'First_Active_Sharing_End_Date']\n",
        "for col in dates_tw:\n",
        "    lista = []\n",
        "    towerdb[col] = towerdb[col].replace([0, '#N/D', 'N/A', np.nan, 'nan', '-'], '')\n",
        "    for dt in towerdb[col]:\n",
        "        if dt != '' or len(dt) > 0:\n",
        "            new_dt = f\"{dt:%d/%m/%Y}\"\n",
        "            lista.append(new_dt)\n",
        "        else:\n",
        "            lista.append(dt)\n",
        "    towerdb[col] = lista\n",
        "\n",
        "#Read CZ towerdb files\n",
        "\"\"\"Merge to get DOER column\"\"\"\n",
        "msa = pd.read_csv('/content/TowerDB_Ireland_20210731.csv', engine='python')\n",
        "doer_col = msa[['Site ID ', 'Date of Equipment Removal']]\n",
        "towerdb = towerdb.merge(doer_col, on='Site ID ')\n",
        "\n",
        "lista = []\n",
        "towerdb['Date of Equipment Removal'] = towerdb['Date of Equipment Removal'].replace([0, '#N/D', 'N/A', np.nan, 'nan'],'')\n",
        "for dt in towerdb['Date of Equipment Removal']:\n",
        "    if dt != '' and re.match(r\"[0-9]{1,2}[\\_|\\-|\\/][0-9]{1,2}[\\_|\\-|\\/][0-9]{1,4}\", dt) is None:\n",
        "        new_dt = f\"{dt:%d/%m/%Y}\"\n",
        "        lista.append(new_dt)\n",
        "    else:\n",
        "        lista.append(dt)\n",
        "towerdb['Date of Equipment Removal'] = lista\n",
        "\n",
        "towerdb.rename(columns={'Billing Trigger Date': 'Billing Trigger Date.1'}, inplace=True)\n",
        "towerdb['Billing Trigger Date'] = towerdb['Infrastructure Ready Date'].values\n",
        "\n",
        "towerdb[\"Energy Cost FY1819\"] = towerdb[\"Energy Cost FY1819\"].apply(lambda x: '€ {:0,.2f}'.format(x))\n",
        "#towerdb['First_Active_Sharing_Start_Date'] = towerdb['First_Active_Sharing_Start_Date'].replace('-', '')\n",
        "#towerdb['First_Active_Sharing_End_Date'] = towerdb['First_Active_Sharing_End_Date'].replace('-', '')\n",
        "\n",
        "cols = list(msa.columns)\n",
        "towerdb = towerdb[cols]\n",
        "\n",
        "replace_cols = ['Site ID ','Strategic','Critical', 'Site Type (See structure Type)','Core Site Type','Transmission System',\\\n",
        "             'Macro Site - Transmission Hub Site','Macro Site - Transmission Hub Site with/without Shelters','Transmission Sites', 'Room Configuration',\\\n",
        "             'Power Supply','Air Conditioning','Strategic_Site_Bucket','CriticalSite_Beyond_10','Sites_As_Metered_Estimated','Meter_Sharing_Site','Bts_Sites',\\\n",
        "             'Phase1_Site_Or_Consent_Site','WIP_Sites','Active_Sharing_Arrangement','Subsequent_Sharing_Arrangement','First_Active_Sharing_Deployment_Type',\\\n",
        "             'Billing Trigger Date','Date of Equipment Removal']\n",
        "\n",
        "invalid_values = ['N/A', 'n/a',\"0\" ,0, '_', np.nan,'nan', ' ']\n",
        "for col in replace_cols:\n",
        "    towerdb[col] = towerdb[col].replace(invalid_values, '')\n",
        "\n",
        "towerdb.rename(columns={'Billing Trigger Date.1': 'Billing Trigger Date'}, inplace=True)\n",
        "\n",
        "towerdb.head(3)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Population</th>\n",
              "      <th>County</th>\n",
              "      <th>Site Name</th>\n",
              "      <th>Address</th>\n",
              "      <th>Site Provider</th>\n",
              "      <th>Strategic</th>\n",
              "      <th>Critical</th>\n",
              "      <th>Altitude (ASL)</th>\n",
              "      <th>Lat (WGS 84)</th>\n",
              "      <th>Long (WGS 84)</th>\n",
              "      <th>Site Class</th>\n",
              "      <th>Site Owner</th>\n",
              "      <th>Hub List</th>\n",
              "      <th>Site Type (See structure Type)</th>\n",
              "      <th>Active Dishes</th>\n",
              "      <th>INTP</th>\n",
              "      <th>Core Site Type</th>\n",
              "      <th>Transmission System</th>\n",
              "      <th>Macro Site - Transmission Hub Site</th>\n",
              "      <th>Macro Site - Transmission Hub Site with/without Shelters</th>\n",
              "      <th>Transmission Sites</th>\n",
              "      <th>Public DAS Sites (Active/ Passive)</th>\n",
              "      <th>Fibre/Microwave</th>\n",
              "      <th>Technology VOD</th>\n",
              "      <th>Structure Type</th>\n",
              "      <th>Structure Type (Standardised)</th>\n",
              "      <th>Room Configuration</th>\n",
              "      <th>Power Supply</th>\n",
              "      <th>Air Conditioning</th>\n",
              "      <th>Tower Height</th>\n",
              "      <th>Site Area (sqm)</th>\n",
              "      <th>Site Area (Available)</th>\n",
              "      <th>Macro Region</th>\n",
              "      <th>MPRN</th>\n",
              "      <th>Site Decom</th>\n",
              "      <th>SAP Site Code</th>\n",
              "      <th>Energy Cost FY1819</th>\n",
              "      <th>Active / Not Active</th>\n",
              "      <th>New Build planned</th>\n",
              "      <th>Site Status</th>\n",
              "      <th>Planned Sublets</th>\n",
              "      <th>Infrastructure Ready Date</th>\n",
              "      <th>Strategic_Site_Bucket</th>\n",
              "      <th>CriticalSite_Beyond_10</th>\n",
              "      <th>Sites_As_Metered_Estimated</th>\n",
              "      <th>Meter_Sharing_Site</th>\n",
              "      <th>Bts_Sites</th>\n",
              "      <th>Phase1_Site_Or_Consent_Site</th>\n",
              "      <th>Transfer_Date_Of_Consent_Site</th>\n",
              "      <th>Billing Trigger Date</th>\n",
              "      <th>WIP_Sites</th>\n",
              "      <th>Decommisioned_Site</th>\n",
              "      <th>Active_Sharing_Arrangement</th>\n",
              "      <th>Subsequent_Sharing_Arrangement</th>\n",
              "      <th>First_Active_Sharing_Deployment_Type</th>\n",
              "      <th>First_Active_Sharing_Start_Date</th>\n",
              "      <th>First_Active_Sharing_End_Date</th>\n",
              "      <th>BTS Site Acceptance Date</th>\n",
              "      <th>Billing Trigger Date</th>\n",
              "      <th>Date of Equipment Removal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CE009</td>\n",
              "      <td>183</td>\n",
              "      <td>Clare</td>\n",
              "      <td>Dangan</td>\n",
              "      <td>Dangan, Ballyvaughan, Co Care</td>\n",
              "      <td>Private Individual</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>47</td>\n",
              "      <td>53.1011</td>\n",
              "      <td>-9.12983</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Vodafone</td>\n",
              "      <td>P4</td>\n",
              "      <td>GBT</td>\n",
              "      <td>2</td>\n",
              "      <td>Standard</td>\n",
              "      <td>Non Core</td>\n",
              "      <td>Macro</td>\n",
              "      <td>No</td>\n",
              "      <td>Non Transmission Hub Site</td>\n",
              "      <td>Non Transmission Site</td>\n",
              "      <td>0</td>\n",
              "      <td>Microwave</td>\n",
              "      <td>2G; 3G</td>\n",
              "      <td>Lattice</td>\n",
              "      <td>Lattice</td>\n",
              "      <td>Indoor</td>\n",
              "      <td>AC</td>\n",
              "      <td>No</td>\n",
              "      <td>18</td>\n",
              "      <td>400</td>\n",
              "      <td>80</td>\n",
              "      <td>Mid West</td>\n",
              "      <td>1.00097e+10</td>\n",
              "      <td>In Service</td>\n",
              "      <td>IECE009</td>\n",
              "      <td>€ 1,229.31</td>\n",
              "      <td>Active</td>\n",
              "      <td></td>\n",
              "      <td>In Service</td>\n",
              "      <td></td>\n",
              "      <td>01/08/1998</td>\n",
              "      <td>Non Strategic</td>\n",
              "      <td>Non Critical</td>\n",
              "      <td>Estimated Model</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>MSA (Phase 1)</td>\n",
              "      <td></td>\n",
              "      <td>01/08/1998</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No Active Sharing</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CE015</td>\n",
              "      <td>1229</td>\n",
              "      <td>Clare</td>\n",
              "      <td>Bunratty Castle Hotel</td>\n",
              "      <td>Bunratty Castle Hotel Bunratty Clare</td>\n",
              "      <td>Hotel Company</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>12</td>\n",
              "      <td>52.6962</td>\n",
              "      <td>-8.81526</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Private Company</td>\n",
              "      <td>P4</td>\n",
              "      <td>RTT</td>\n",
              "      <td>1</td>\n",
              "      <td>Standard</td>\n",
              "      <td>Non Core</td>\n",
              "      <td>Macro</td>\n",
              "      <td>No</td>\n",
              "      <td>Non Transmission Hub Site</td>\n",
              "      <td>Non Transmission Site</td>\n",
              "      <td>0</td>\n",
              "      <td>Microwave</td>\n",
              "      <td>2G; 3G; 4G</td>\n",
              "      <td>Rooftop structure</td>\n",
              "      <td>Rooftop structure</td>\n",
              "      <td>KN type Outdoor</td>\n",
              "      <td>AC</td>\n",
              "      <td>No</td>\n",
              "      <td>13.4</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Mid West</td>\n",
              "      <td>0</td>\n",
              "      <td>In Service</td>\n",
              "      <td>IECE015</td>\n",
              "      <td>€ 1,853.73</td>\n",
              "      <td>Active</td>\n",
              "      <td></td>\n",
              "      <td>In Service</td>\n",
              "      <td></td>\n",
              "      <td>07/05/2007</td>\n",
              "      <td>Non Strategic</td>\n",
              "      <td>Non Critical</td>\n",
              "      <td>Estimated Model</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>MSA (Phase 1)</td>\n",
              "      <td></td>\n",
              "      <td>07/05/2007</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No Active Sharing</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CE020</td>\n",
              "      <td>1143</td>\n",
              "      <td>Clare</td>\n",
              "      <td>Liscannor Bay Hotel</td>\n",
              "      <td>Liscannor Bay View Hotel Liscannor Clare</td>\n",
              "      <td>Hotel Company</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>11</td>\n",
              "      <td>52.9382</td>\n",
              "      <td>-9.38929</td>\n",
              "      <td>Rural</td>\n",
              "      <td>Private Company</td>\n",
              "      <td>P4</td>\n",
              "      <td>RTT</td>\n",
              "      <td>1</td>\n",
              "      <td>Standard</td>\n",
              "      <td>Non Core</td>\n",
              "      <td>Macro</td>\n",
              "      <td>No</td>\n",
              "      <td>Non Transmission Hub Site</td>\n",
              "      <td>Non Transmission Site</td>\n",
              "      <td>0</td>\n",
              "      <td>Microwave</td>\n",
              "      <td>2G; 3G</td>\n",
              "      <td>Rooftop structure</td>\n",
              "      <td>Rooftop structure</td>\n",
              "      <td>KN type Outdoor</td>\n",
              "      <td>AC</td>\n",
              "      <td>No</td>\n",
              "      <td>19.2</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Mid West</td>\n",
              "      <td>1.0019e+10</td>\n",
              "      <td>In Service</td>\n",
              "      <td>IECE020</td>\n",
              "      <td>€ 995.32</td>\n",
              "      <td>Active</td>\n",
              "      <td></td>\n",
              "      <td>In Service</td>\n",
              "      <td></td>\n",
              "      <td>21/05/2002</td>\n",
              "      <td>Non Strategic</td>\n",
              "      <td>Non Critical</td>\n",
              "      <td>Estimated Model</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>MSA (Phase 1)</td>\n",
              "      <td></td>\n",
              "      <td>21/05/2002</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No Active Sharing</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Site ID  Population  ... Billing Trigger Date Date of Equipment Removal\n",
              "0    CE009        183  ...                                               \n",
              "1    CE015       1229  ...                                               \n",
              "2    CE020       1143  ...                                               \n",
              "\n",
              "[3 rows x 61 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPEfoI7BkV9"
      },
      "source": [
        "def change_incorret_values(df, df_index, col_chg, incorrect_value, new_value):\n",
        "    list_sites = list(df[df[col_chg]==incorrect_value][df_index])\n",
        "    df.loc[df[df_index].isin(list_sites), col_chg] = new_value\n",
        "    print(df.loc[df[df_index].isin(list_sites)][[df_index, col_chg]])\n",
        "\n",
        "def change_incorret_list(df,list_sites, df_index, col_chg, new_value):\n",
        "    #list_sites = list(df[df[col_chg]==incorrect_value][df_index])\n",
        "    df.loc[df[df_index].isin(list_sites), col_chg] = new_value\n",
        "    print(df.loc[df[df_index].isin(list_sites)][[df_index, col_chg]])\n",
        "\n",
        "lista = ['CK166', 'CK173', 'CKMTG','DN370','DNTS1','DNVIC','GY135','KK074','RN053','RN058','SO071','WD067']\n",
        "change_incorret_list(towerdb, lista, 'Site ID ', \"Site Status\", 'To be dismantled')\n",
        "\n",
        "b_sites = ['CK094','DX264','GY025','DN947']\n",
        "change_incorret_list(towerdb, b_sites,'Site ID ',\"Bts_Sites\", 'Yes')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPNDTPe_pq0X"
      },
      "source": [
        "\"\"\"Precisa dos Critical sites da UIS\"\"\"\n",
        "c_sites = critical['UIS Sites(critical beyond 10%) different in TowerDB'].to_list()\n",
        "change_incorret_list(towerdb, c_sites,'Site ID ','CriticalSite_Beyond_10', 'Beyond 10%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRy770oTk7BJ"
      },
      "source": [
        "towerdb.to_csv('/content/TowerDB_Ireland_20210831.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "4vNkIMdNRO2i",
        "outputId": "f290f165-fc4e-4454-e505-6ae902e75cea"
      },
      "source": [
        "\"\"\"Check columns received\"\"\"\n",
        "def check_columns_received(df, bill_cols):\n",
        "    twdb_col = list(df.columns)\n",
        "    col_miss = [i for i in bill_cols if i not in twdb_col]\n",
        "\n",
        "    if col_miss:\n",
        "        df_col_missing = pd.DataFrame(col_miss, columns=['Column(s) Missing'])\n",
        "        return df_col_missing\n",
        "    else:\n",
        "        print('\\nNo missing columns.')\n",
        "\n",
        "df_col_missing = check_columns_received(towerdb, cols)\n",
        "df_col_missing\n",
        "#Tem error 3 columns faltando"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column(s) Missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Billing Trigger Date.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Column(s) Missing\n",
              "0  Billing Trigger Date.1"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAwYpoALt0Rg"
      },
      "source": [
        "def check_date_columns(df, df_index,status_col,columns):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_dates = df[columns].fillna('')\n",
        "    df_dates = df_dates.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "\n",
        "    date_format = re.compile(r\"[0-9]{1,2}[\\_|\\-|\\/][0-9]{1,2}[\\_|\\-|\\/][0-9]{1,4}\")\n",
        "\n",
        "    for column in set(df_dates.keys()):\n",
        "        for value in df_dates[column]:\n",
        "            if date_format.match(value) is None:\n",
        "                if value in (None, '', 'nan'):\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorret picklist value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors[df_index] = [i for i in df[df_index]]\n",
        "    df_errors = df_errors.replace('Ok', np.nan)   \n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "    \n",
        "    df = df[[df_index, status_col]]\n",
        "    df_errors = pd.merge(df_errors,df, how='left', on=[df_index])\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors[[status_col]+ df_errors.columns[:-1].tolist()]\n",
        "    df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "towerdb = towerdb.T.drop_duplicates().T\n",
        "\n",
        "actives_1 = towerdb[towerdb['Site Status']=='In Service']\n",
        "no_actives_1 = towerdb[~(towerdb['Site Status']=='In Service')]\n",
        "\n",
        "#Checking columns for errors\n",
        "actives_dates_errors = check_date_columns(actives_1, 'Site ID ', 'Site Status', ['Billing Trigger Date']) \n",
        "# Actives sites with blank billing trigger date\n",
        "no_actives_dates_errors = check_date_columns(no_actives_1, 'Site ID ', 'Site Status', ['Date of Equipment Removal']) \n",
        "\n",
        "print(actives_dates_errors)\n",
        "print('\\n')\n",
        "print(no_actives_dates_errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3v-aomjhR2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f8e765-c47f-4baf-e0cf-917c4813bd8d"
      },
      "source": [
        "def check_picklist(df, df_index, df_status, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_cols = list(picklist_dict.keys())\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "\n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]):\n",
        "                if pd.isnull(value) or pd.isna(value) or value == '' or value == 'nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors[df_index] = [i for i in df[df_index]]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, df_status]]\n",
        "    df_errors = pd.merge(df_errors, df, how='left', on=[df_index], suffixes=('_checked', '_actual'))\n",
        "    cols = list(df_errors.columns)\n",
        "    if df_status + '_actual' in cols:\n",
        "        df_errors = df_errors.set_index([df_index, df_status + '_actual'])\n",
        "    else:\n",
        "        df_errors = df_errors.set_index([df_index])\n",
        "        df_errors = df_errors[[df_status] + df_errors.columns[:-1].tolist()]\n",
        "    df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "general_picklist = {\n",
        "    'Transmission System': [\"Macro\",\"Public DAS\",\"Long-term Mobile\",\"Transmission\",'Repeater','Macro+DAS','Outdoor Small Cells'],\n",
        "}\n",
        "\n",
        "df_general_picklist = check_picklist(towerdb, 'Site ID ','Site Status', general_picklist)\n",
        "\n",
        "print(df_general_picklist)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Site ID  Site Status Transmission System\n",
            "0    DN133  Dismantled         Blank Value\n",
            "1    DN214  Dismantled         Blank Value\n",
            "2    DN359  Dismantled         Blank Value\n",
            "3    DNSE1  Dismantled         Blank Value\n",
            "4    WX035  Dismantled         Blank Value\n",
            "5    LK568    Pipeline         Blank Value\n",
            "6    MH079    Pipeline         Blank Value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "uWKG3hZRQ6SA",
        "outputId": "361904ad-eeba-4285-eb58-f9ec678c4c11"
      },
      "source": [
        "\"\"\"MoM BTS check sites\"\"\"\n",
        "def check_mom_bts(df_tw,df_msa, df_index, status_col, check_col):\n",
        "\n",
        "    msa_bts = df_msa[df_msa[check_col]=='Yes']\n",
        "    msa_bts_sites = [i for i in msa_bts[df_index]]\n",
        "\n",
        "    tw_bts = df_tw[df_tw[check_col]=='Yes']\n",
        "    tw_bts_sites = [i for i in tw_bts[df_index]]\n",
        "\n",
        "    out_tower_bts = [i for i in msa_bts_sites if i not in tw_bts_sites]\n",
        "    filtered = df_msa[df_msa[df_index].isin(out_tower_bts)]\n",
        "    filtered = filtered[[df_index, status_col, check_col]]\n",
        "    actual = df_tw[df_tw[df_index].isin(out_tower_bts)][[df_index, check_col, status_col]]\n",
        "    merge = pd.merge(filtered, actual, how='inner', on=df_index, suffixes=['_old', '_in_month'])\n",
        "\n",
        "    return  merge[[df_index, status_col+'_old', status_col+'_in_month', check_col+'_old', check_col+'_in_month']]\n",
        "\n",
        "df_mom = check_mom_bts(towerdb, msa , 'Site ID ','Site Status', \"Bts_Sites\")\n",
        "df_mom"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Site Status_old</th>\n",
              "      <th>Site Status_in_month</th>\n",
              "      <th>Bts_Sites_old</th>\n",
              "      <th>Bts_Sites_in_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CK094</td>\n",
              "      <td>In Service</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DN947</td>\n",
              "      <td>In Service</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DX264</td>\n",
              "      <td>In Service</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GY025</td>\n",
              "      <td>In Service</td>\n",
              "      <td>In Service</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Site ID  Site Status_old  ... Bts_Sites_old Bts_Sites_in_month\n",
              "0    CK094      In Service  ...           Yes                 No\n",
              "1    DN947      In Service  ...           Yes                 No\n",
              "2    DX264      In Service  ...           Yes                 No\n",
              "3    GY025      In Service  ...           Yes                 No\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Q7yx-cfDiLJ6",
        "outputId": "109aaeed-4bdf-493a-a49b-1bab6f4a6c88"
      },
      "source": [
        "\"\"\"MoM DEcomissioned check sites\"\"\"\n",
        "def check_mom_bts(df_tw,df_msa, df_index, status_col, check_col):\n",
        "\n",
        "    msa_bts = df_msa[df_msa[check_col]=='Yes']\n",
        "    msa_bts_sites = [i for i in msa_bts[df_index]]\n",
        "\n",
        "    tw_bts = df_tw[df_tw[check_col]=='Yes']\n",
        "    tw_bts_sites = [i for i in tw_bts[df_index]]\n",
        "\n",
        "    out_tower_bts = [i for i in msa_bts_sites if i not in tw_bts_sites]\n",
        "    filtered = df_msa[df_msa[df_index].isin(out_tower_bts)]\n",
        "    filtered = filtered[[df_index, status_col, check_col]]\n",
        "    actual = df_tw[df_tw[df_index].isin(out_tower_bts)][[df_index, check_col, status_col]]\n",
        "    merge = pd.merge(filtered, actual, how='inner', on=df_index, suffixes=['_old', '_in_month'])\n",
        "\n",
        "    return  merge[[df_index, status_col+'_old', status_col+'_in_month', check_col+'_old', check_col+'_in_month']]\n",
        "\n",
        "df_decom = check_mom_bts(towerdb, msa, 'Site ID ', 'Site Status', 'Decommisioned_Site')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Site Status_old</th>\n",
              "      <th>Site Status_in_month</th>\n",
              "      <th>Decommisioned_Site_old</th>\n",
              "      <th>Decommisioned_Site_in_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Site ID , Site Status_old, Site Status_in_month, Decommisioned_Site_old, Decommisioned_Site_in_month]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPoEM_j5QtEb",
        "outputId": "5774453d-0604-4a24-b273-d73ece4c5171"
      },
      "source": [
        "def check_picklist(df, df_index, df_status, picklist_dict):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_cols = list(picklist_dict.keys())\n",
        "    df_picklist = df[df_cols].fillna('')\n",
        "    df_picklist = df_picklist.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "\n",
        "    for column in set(picklist_dict.keys()):\n",
        "        for value in df_picklist[column]:\n",
        "            if value not in set(picklist_dict[column]):\n",
        "                if pd.isnull(value) or pd.isna(value) or value == '' or value == 'nan':\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorrect value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok!')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok!', np.nan)\n",
        "    df_errors[df_index] = [i for i in df[df_index]]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "\n",
        "    df = df[[df_index, df_status]]\n",
        "    df_errors = pd.merge(df_errors, df, how='left', on=[df_index], suffixes=('_checked', '_actual'))\n",
        "    cols = list(df_errors.columns)\n",
        "    if df_status + '_actual' in cols:\n",
        "        df_errors = df_errors.set_index([df_index, df_status + '_actual'])\n",
        "    else:\n",
        "        df_errors = df_errors.set_index([df_index])\n",
        "        df_errors = df_errors[[df_status] + df_errors.columns[:-1].tolist()]\n",
        "    df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\n",
        "\n",
        "picklist = {\n",
        "    \"Strategic\": ['Yes', 'No'],\n",
        "    'Critical': ['Yes', 'No'],\n",
        "    'Site Type (See structure Type)': ['RTT','GBT','DAS active','DAS passive','RTT+DAS active','GBT+DAS active','RTT+DAS passive','GBT+DAS passive','Outdoor Small Cells'],\n",
        "    'INTP ': ['Standard','Core','Dual Use Site','Transmission','Repeater','Long-term Mobile','DAS active','DAS passive','Macro+DAS active','Macro+DAS passive','Outdoor Small Cells'],\n",
        "    'Core Site Type': ['Non Core', 'Case A', 'Case B'],\n",
        "    'Transmission System': [\"Macro\",\"Public DAS\",\"Long-term Mobile\",\"Transmission\",'Repeater','Macro+DAS','Outdoor Small Cells'],\n",
        "    'Macro Site - Transmission Hub Site': ['Yes', 'No'],\n",
        "    'Macro Site - Transmission Hub Site with/without Shelters': [\"With shelters\",\"Without shelters\",\"Non Transmission Hub Site\"],\n",
        "    'Transmission Sites': [\"With shelters\",\"Without shelters\",\"Non Transmission Site\"],\n",
        "    'Room Configuration': ['Indoor','Outdoor','Indoor & Outdoor', \"KN type Outdoor\",\"RBS type Outdoor\"],\n",
        "    'Power Supply': ['AC','DC', 'AC & DC','No Power'],\n",
        "    'Air Conditioning': ['No','Yes; Indoor Air Conditioning','Yes; Indoor Free Air cooling / Free cooling units'],\n",
        "    'Site Status': ['Pipeline','Ordered','WIP','In Service','To be dismantled','Dismantled','Cancelled'],\n",
        "    'Strategic_Site_Bucket': ['Yes - 0-5%','Yes - 5-10%','Non Strategic'],\n",
        "    'CriticalSite_Beyond_10': ['Beyond 10%','Within 10%','Non Critical'],\n",
        "    'Sites_As_Metered_Estimated': ['Estimated Model','Metered Model'],\n",
        "    'Meter_Sharing_Site': ['Yes', 'No'],\n",
        "    \"Bts_Sites\": ['Yes', 'No'],\n",
        "    'Phase1_Site_Or_Consent_Site': ['MSA (Phase 1)','PMA (Phase 2)'],\n",
        "    'WIP_Sites': ['Yes', 'No'],\n",
        "    'Active_Sharing_Arrangement': ['MORAN (On VF equipment)','MORAN (On non-VF equipment)','MOCN with Spectrum Pooling','Partial Active-Passive','No Active Sharing'],\n",
        "    'Subsequent_Sharing_Arrangement': ['Yes', 'No']\n",
        "\n",
        "}\n",
        "\"\"\"Picklist check\"\"\"\n",
        "actives = towerdb[towerdb['Site Status']=='In Service']\n",
        "\n",
        "\"\"\"Picklist check\"\"\"\n",
        "actives = towerdb[towerdb['Site Status']=='In Service']\n",
        "df_active_picklist = check_picklist(actives, 'Site ID ','Site Status',  picklist)\n",
        "\n",
        "print(df_active_picklist)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Site ID  Site Status Subsequent_Sharing_Arrangement\n",
            "0    WH032  In Service                    Blank Value\n",
            "1    DN304  In Service                    Blank Value\n",
            "2    DN947  In Service                    Blank Value\n",
            "3    DX252  In Service                    Blank Value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR9tLCZ5RoyT"
      },
      "source": [
        "path_uip = '/content/UserInput_Ireland_July 21_06.07.2021.xlsx'\n",
        "uip_names = ['Site_ID', 'BTS site applicable charge (Annual)', \\\n",
        "             'Commercials for sites beyond 10% cap of critical sites (Annual)']\n",
        "uip = pd.read_excel(path_uip ,sheet_name='SiteLevel',usecols=[0,1,2],skiprows=2).fillna('')\n",
        "uip.columns = uip_names\n",
        "\n",
        "msa_sites = [i for i in msa['Site ID ']]\n",
        "tw_sites = [i for i in towerdb ['Site ID ']]\n",
        "uip_sites = [i for i in uip['Site_ID']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATAfbi5SnMNn"
      },
      "source": [
        "\"\"\"Check Bill in service sites\"\"\"\n",
        "def check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col):\n",
        "    t = type_col.lower()\n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "        \n",
        "    if t == 'doer':\n",
        "        df_tw[date_col]= pd.to_datetime(df_tw[date_col], format='%d/%m/%Y', errors='coerce')\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&((df_tw[date_col] < current_date)|(df_tw[date_col]==''))]\n",
        "        filtered[date_col] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[date_col]))\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "    else:\n",
        "\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&(df_tw[date_col]=='')]\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "\n",
        "#check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col)       \n",
        "df_bill = check_tw_bill_doer(actives, 'Site ID ', 'Billing Trigger Date',\"Bts_Sites\",'Yes', 'bill')\n",
        "df_bill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlREMj57Tcgh"
      },
      "source": [
        "\"\"\"BTS Wip\"\"\"\n",
        "def check_wip(df_tw,  df_msa, tw_index, wip_tw, tw_bts, tw_status):\n",
        "\n",
        "    wip_msa = [i for i in df_msa[df_msa[wip_tw]=='Yes'][tw_index]]\n",
        "    \n",
        "    tw_wip_sites = [str(i) for i in df_tw[df_tw[wip_tw]=='Yes'][tw_index]]\n",
        "\n",
        "    tw_wip_site_bts_flagged = df_tw[(df_tw[wip_tw]=='Yes')&(df_tw[tw_bts]=='Yes')]\n",
        "    tw_wip_site_bts_flagged = tw_wip_site_bts_flagged[[tw_index, wip_tw, tw_bts]]\n",
        "    \n",
        "    #wip_out_tw_list = [i for i in tw_wip_sites if i not in wip_msa]\n",
        "    return tw_wip_site_bts_flagged\n",
        "\n",
        "df_wip_and_bts_flagged = check_wip(towerdb, msa, 'Site ID ','WIP_Sites', \"Bts_Sites\",\"Site Status\")\n",
        "\n",
        "print(df_wip_and_bts_flagged)\n",
        "# No errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFq2dM-BUoBT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "7da391ad-9e83-46f6-9e47-37c7e9713fd4"
      },
      "source": [
        "\"\"\"Decomissioned Sites\"\"\"\n",
        "def check_decommissioned(df,df_index, decom_col, doer_col):\n",
        "    #c = country.lower()\n",
        "    filtered = df[(df[decom_col]=='Yes')&(df[doer_col]==\"\")]\n",
        "    return filtered[[df_index, decom_col, doer_col]]\n",
        "actives = towerdb[towerdb['Site Status']=='in Service']\n",
        "df_decom_errors = check_decommissioned(actives,'Site ID ','Decommisioned_Site', 'Date of Equipment Removal')\n",
        "df_decom_errors\n",
        "# No errors\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Decommisioned_Site</th>\n",
              "      <th>Date of Equipment Removal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Site ID , Decommisioned_Site, Date of Equipment Removal]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN6Jg1eJSUD8"
      },
      "source": [
        "\"\"\" BTS sites\"\"\"\n",
        "def check_new_sites(df_towerdb, tw_index, bts_col, bill_col, status_col, msa_list, towerdb_list, uip_list):\n",
        "    \n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "    \n",
        "    filtered = df_towerdb[[tw_index, status_col]]\n",
        "\n",
        "    #Finding for ALL NEW SITES\n",
        "    new_site = [i for i in towerdb_list if i not in msa_list]\n",
        "    new_sites = pd.DataFrame(new_site, columns=['New_Sites'])\n",
        "    new_sites = pd.merge(new_sites, filtered, how='left', left_on=['New_Sites'], right_on=tw_index)\n",
        "    new_sites = new_sites[['New_Sites', status_col]]\n",
        "\n",
        "    #create a copy to make index modifications\n",
        "    df = df_towerdb.copy()\n",
        "\n",
        "    #New columns with Site Codes\n",
        "    df['Sites'] = df[tw_index]\n",
        "    #defining site code to index\n",
        "    df.set_index('Sites', inplace=True)\n",
        "\n",
        "    #filtering by new sites\n",
        "    df = df[df[tw_index].isin(new_site)]\n",
        "\n",
        "    # Save information os sites with demerged date more than current date\n",
        "    df[bill_col] = pd.to_datetime(df[bill_col], format='%d/%m/%Y', errors='coerce')\n",
        "    df_site_bts = df[(df[bts_col]=='Yes')&(df[bill_col] > current_date)].fillna('')\n",
        "    df_site_bts[bill_col] = list(map(lambda x: f'{x:%d/%m/%Y}', df_site_bts[bill_col]))\n",
        "    df_site_bts = df_site_bts[[tw_index,status_col, bts_col, bill_col]]\n",
        "    \n",
        "    #if not (new_sites.empty or bts_out_uis.empty or df_site_bts.empty):\n",
        "    return new_sites, df_site_bts[[tw_index,status_col, bts_col, bill_col]]\n",
        "\n",
        "#(df_towerdb, tw_index, bts_col, bill_col, status_col, msa_list, towerdb_list, uip_list)\n",
        "new_sites, bts_out_uis = check_new_sites(towerdb, 'Site ID ', \"Bts_Sites\", \\\n",
        "                                                      'Billing Trigger Date','Site Status', msa_sites, tw_sites, uip_sites)\n",
        "\n",
        "print(new_sites)\n",
        "print('\\n')\n",
        "print(bts_out_uis)\n",
        "#no errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "yidvieJtVXOq",
        "outputId": "d3b337cc-03db-4810-c265-9fd75861f711"
      },
      "source": [
        "\"\"\"Check doer in service sites\"\"\"\n",
        "def check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col):\n",
        "    t = type_col.lower()\n",
        "    # capture current date as string\n",
        "    current_date = pd.to_datetime('now').date()\n",
        "    # convert current to timestamp\n",
        "    current_date = pd.to_datetime(current_date)\n",
        "        \n",
        "    if t == 'doer':\n",
        "        df_tw[date_col]= pd.to_datetime(df_tw[date_col], format='%d/%m/%Y', errors='coerce')\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&((df_tw[date_col] < current_date)|(df_tw[date_col]==''))]\n",
        "        filtered[date_col] = list(map(lambda x: f'{x:%d/%m/%Y}',filtered[date_col]))\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "    else:\n",
        "\n",
        "        filtered = df_tw[(df_tw[status_col]==status)&(df_tw[date_col]=='')]\n",
        "        return filtered[[tw_index, status_col, date_col]] \n",
        "\n",
        "#check_tw_bill_doer(df_tw, tw_index, date_col, status_col, status, type_col)       \n",
        "df_doer = check_tw_bill_doer(actives, 'Site ID ', 'Date of Equipment Removal','Site Status','In Service', 'doer')\n",
        "df_doer\n",
        "# No errors\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Site Status</th>\n",
              "      <th>Date of Equipment Removal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Site ID , Site Status, Date of Equipment Removal]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IEdLtcFVb8u"
      },
      "source": [
        "def check_uip_tw(df_tw,tw_index, status_tw_col, decom_col, tw_bts_col, tw_critical_col, df_uip, uip_sites):\n",
        "\n",
        "    filtered = df_tw[[tw_index, status_tw_col, tw_critical_col]]\n",
        "    #tw_active = df_tw[df_tw['Site Status']=='In Service']\n",
        "    count_tw_sites = [i for i in df_tw[df_tw[status_tw_col] =='In Service'][tw_index]]\n",
        "\n",
        "    #if not set(count_tw_sites).intersection(uip_sites):\n",
        "    uis_sites_not_in_towerdb = [i for i in uip_sites if i not in count_tw_sites]\n",
        "    uis_sites_not_in_towerdb = pd.DataFrame(uis_sites_not_in_towerdb,columns=['UIS In Month not active in TowerDB!'])\n",
        "    uis_sites_not_in_towerdb = pd.merge(uis_sites_not_in_towerdb, filtered, how='left', left_on='UIS In Month not active in TowerDB!',\\\n",
        "                                    right_on=tw_index)\n",
        "    uis_sites_not_in_towerdb = uis_sites_not_in_towerdb[['UIS In Month not active in TowerDB!', status_tw_col]]\n",
        "    \n",
        "    in_service_not_in_uis = [i for i in count_tw_sites if i not in uip_sites]\n",
        "    in_service_not_in_uis = pd.DataFrame(in_service_not_in_uis,columns=['TowerDB Sites out of UIS In Month!'])\n",
        "    in_service_not_in_uis = pd.merge(in_service_not_in_uis, filtered, how='left', left_on='TowerDB Sites out of UIS In Month!',\\\n",
        "                                    right_on=tw_index)\n",
        "    in_service_not_in_uis = in_service_not_in_uis[['TowerDB Sites out of UIS In Month!', status_tw_col]]\n",
        "    #check for decomissioned site not in uip files\n",
        "\n",
        "    tw_decomiss = [i for i in df_tw[df_tw[decom_col]=='Yes'][tw_index] if i in uip_sites]\n",
        "    decomiss_sites_in_uip = pd.DataFrame(tw_decomiss, columns=['Decomissioned Site in UIS File'])\n",
        "    decomiss_sites_in_uip = pd.merge(decomiss_sites_in_uip, filtered, how='left', left_on='Decomissioned Site in UIS File',\\\n",
        "                                    right_on=tw_index)\n",
        "    decomiss_sites_in_uip = decomiss_sites_in_uip[['Decomissioned Site in UIS File', status_tw_col]]\n",
        "\n",
        "    #Check BTS sites\n",
        "    bts_sites = [i for i in df_tw[df_tw[tw_bts_col]=='Yes'][tw_index]]\n",
        "    uip_bts = [i for i in df_uip[df_uip['BTS site applicable charge (Annual)']!='']['Site_ID']]\n",
        "\n",
        "    #if not set(bts_sites).intersection(uip_sites):\n",
        "    bts_sites_out_uip = [i for i in uip_bts if i not in bts_sites]\n",
        "    bts_sites_out_uip = pd.DataFrame(bts_sites_out_uip, columns=['UIS BTS not in TowerDB(BTS)'])\n",
        "    bts_sites_out_uip = pd.merge(bts_sites_out_uip, filtered, how='left', left_on='UIS BTS not in TowerDB(BTS)',\\\n",
        "                                    right_on=tw_index)\n",
        "    bts_sites_out_uip = bts_sites_out_uip[['UIS BTS not in TowerDB(BTS)', status_tw_col]]\n",
        "\n",
        "    #  Check for UIP critical sites \n",
        "    uip_critical = [i for i in df_uip[df_uip['Commercials for sites beyond 10% cap of critical sites (Annual)']!='']['Site_ID']]\n",
        "    bts_tw_critical = df_tw[df_tw[tw_critical_col]=='Beyond 10%'][tw_index]\n",
        "    \n",
        "    #if set(uip_critical).intersection(bts_tw_critical):\n",
        "    critical = [i for i in uip_critical if i not in bts_tw_critical]\n",
        "    critical = pd.DataFrame(critical, columns=['UIS Sites(critical beyond 10%) different in TowerDB'])\n",
        "    critical = pd.merge(critical, filtered, how='left', left_on='UIS Sites(critical beyond 10%) different in TowerDB',\\\n",
        "                                right_on=tw_index)\n",
        "    critical = critical[['UIS Sites(critical beyond 10%) different in TowerDB', status_tw_col, tw_critical_col]]\n",
        "    #if not (in_service_uip_sites.empty or decomiss_sites_in_uip.empty or bts_sites_out_uip.empty or critical.empty):\n",
        "    return uis_sites_not_in_towerdb, in_service_not_in_uis, decomiss_sites_in_uip, bts_sites_out_uip, critical\n",
        "\n",
        "\"\"\"Check UIP sites matches with Towerdb sites\"\"\"\n",
        "uis_sites_not_in_towerdb, in_service_not_in_uis, decomiss_sites_in_uip, bts_sites_out_uip, critical = check_uip_tw(towerdb,'Site ID ', 'Site Status', \\\n",
        "                                                              'Decommisioned_Site', \"Bts_Sites\",'CriticalSite_Beyond_10', uip, uip_sites)\n",
        "print(uis_sites_not_in_towerdb)\n",
        "print('\\n')\n",
        "print(in_service_not_in_uis)\n",
        "print('\\n')\n",
        "print(decomiss_sites_in_uip)\n",
        "print('\\n')\n",
        "print(bts_sites_out_uip)\n",
        "print('\\n')\n",
        "print(critical)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9xlPXOYdmdB"
      },
      "source": [
        "True up check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LckjPL1rWfob"
      },
      "source": [
        "def check_uip_tw(df_tw,tw_index, status_tw_col, decom_col, tw_bts_col, tw_critical_col, df_uip, uip_sites):\n",
        "\n",
        "    filtered = df_tw[[tw_index, status_tw_col, tw_critical_col]]\n",
        "    #tw_active = df_tw[df_tw['Site Status']=='In Service']\n",
        "    count_tw_sites = [i for i in df_tw[df_tw[status_tw_col] =='In Service'][tw_index]]\n",
        "\n",
        "    #if not set(count_tw_sites).intersection(uip_sites):\n",
        "    uis_sites_not_in_towerdb = [i for i in uip_sites if i not in count_tw_sites]\n",
        "    uis_sites_not_in_towerdb = pd.DataFrame(uis_sites_not_in_towerdb,columns=['UIS In Month not active in TowerDB!'])\n",
        "    uis_sites_not_in_towerdb = pd.merge(uis_sites_not_in_towerdb, filtered, how='left', left_on='UIS In Month not active in TowerDB!',\\\n",
        "                                    right_on=tw_index)\n",
        "    uis_sites_not_in_towerdb = uis_sites_not_in_towerdb[['UIS In Month not active in TowerDB!', status_tw_col]]\n",
        "    \n",
        "    in_service_not_in_uis = [i for i in count_tw_sites if i not in uip_sites]\n",
        "    in_service_not_in_uis = pd.DataFrame(in_service_not_in_uis,columns=['TowerDB Sites out of UIS In Month!'])\n",
        "    in_service_not_in_uis = pd.merge(in_service_not_in_uis, filtered, how='left', left_on='TowerDB Sites out of UIS In Month!',\\\n",
        "                                    right_on=tw_index)\n",
        "    in_service_not_in_uis = in_service_not_in_uis[['TowerDB Sites out of UIS In Month!', status_tw_col]]\n",
        "    #check for decomissioned site not in uip files\n",
        "\n",
        "    tw_decomiss = [i for i in df_tw[df_tw[decom_col]=='Yes'][tw_index] if i in uip_sites]\n",
        "    decomiss_sites_in_uip = pd.DataFrame(tw_decomiss, columns=['Decomissioned Site in UIS File'])\n",
        "    decomiss_sites_in_uip = pd.merge(decomiss_sites_in_uip, filtered, how='left', left_on='Decomissioned Site in UIS File',\\\n",
        "                                    right_on=tw_index)\n",
        "    decomiss_sites_in_uip = decomiss_sites_in_uip[['Decomissioned Site in UIS File', status_tw_col]]\n",
        "\n",
        "    #Check BTS sites\n",
        "    bts_sites = [i for i in df_tw[df_tw[tw_bts_col]=='Yes'][tw_index]]\n",
        "    uip_bts = [i for i in df_uip[df_uip['BTS site applicable charge (Annual)']!='']['Site_ID']]\n",
        "\n",
        "    #if not set(bts_sites).intersection(uip_sites):\n",
        "    bts_sites_out_uip = [i for i in uip_bts if i not in bts_sites]\n",
        "    bts_sites_out_uip = pd.DataFrame(bts_sites_out_uip, columns=['UIS BTS not in TowerDB(BTS)'])\n",
        "    bts_sites_out_uip = pd.merge(bts_sites_out_uip, filtered, how='left', left_on='UIS BTS not in TowerDB(BTS)',\\\n",
        "                                    right_on=tw_index)\n",
        "    bts_sites_out_uip = bts_sites_out_uip[['UIS BTS not in TowerDB(BTS)', status_tw_col]]\n",
        "\n",
        "    #  Check for UIP critical sites \n",
        "    uip_critical = [i for i in df_uip[df_uip['Commercials for sites beyond 10% cap of critical sites (Annual)']!='']['Site_ID']]\n",
        "    bts_tw_critical = df_tw[df_tw[tw_critical_col]=='Beyond 10%'][tw_index]\n",
        "    \n",
        "    #if set(uip_critical).intersection(bts_tw_critical):\n",
        "    critical = [i for i in uip_critical if i not in bts_tw_critical]\n",
        "    critical = pd.DataFrame(critical, columns=['UIS Sites(critical beyond 10%) different in TowerDB'])\n",
        "    critical = pd.merge(critical, filtered, how='left', left_on='UIS Sites(critical beyond 10%) different in TowerDB',\\\n",
        "                                right_on=tw_index)\n",
        "    critical = critical[['UIS Sites(critical beyond 10%) different in TowerDB', status_tw_col, tw_critical_col]]\n",
        "    #if not (in_service_uip_sites.empty or decomiss_sites_in_uip.empty or bts_sites_out_uip.empty or critical.empty):\n",
        "    return uis_sites_not_in_towerdb, in_service_not_in_uis, decomiss_sites_in_uip, bts_sites_out_uip, critical\n",
        "\n",
        "path_uiptrue = '/content/UserInput_Ireland_20210630 June delta.xlsx'\n",
        "uip_names = ['Site_ID', 'BTS site applicable charge (Annual)', 'Commercials for sites beyond 10% cap of critical sites (Annual)']\n",
        "uip_true = pd.read_excel(path_uip ,sheet_name='SiteLevel',usecols=[0,1,2],skiprows=2)\n",
        "uip_true.columns = uip_names\n",
        "uip_sites_true = [i for i in uip_true['Site_ID']]\n",
        "\n",
        "uis_true_not_in_towerdb,in_service_uis_true, decomiss_in_uis, bts_sites_out_uis_true, critical_true = check_uip_tw(towerdb,'Site ID ', 'Site Status', \\\n",
        "                                                                'Decommisioned_Site', \"Bts_Sites\",'CriticalSite_Beyond_10', uip, uip_sites)\n",
        "#No errors\n",
        "print(uis_sites_not_in_towerdb)\n",
        "print('\\n')\n",
        "print(in_service_not_in_uis)\n",
        "print('\\n')\n",
        "print(decomiss_sites_in_uip)\n",
        "print('\\n')\n",
        "print(bts_sites_out_uip)\n",
        "print('\\n')\n",
        "print(critical)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaw6H__1aihQ"
      },
      "source": [
        "def check_commercial(path_current, path_before, col_replace, col_names, merge_cols, col_order):\n",
        "    \n",
        "    def replace_values(df, columns, value=\"\"):\n",
        "        \"\"\"\n",
        "        Está voltando para float\n",
        "        \"\"\"\n",
        "        invalid_values = ['N/A', 'n/a',\"0\", '-', '_', np.nan,'nan']\n",
        "        #lista = []\n",
        "\n",
        "        df.fillna(\"\", inplace=True)\n",
        "        #df[column] = df[column].astype('int64')\n",
        "\n",
        "        for column in columns:\n",
        "            lista = []\n",
        "            for index in df[column]:\n",
        "                #print(f\"{column} -> {index}\")\n",
        "                if index in invalid_values:\n",
        "                    lista.append(value)\n",
        "                else:\n",
        "                    lista.append(index)\n",
        "            df[column] = lista\n",
        "\n",
        "        return df\n",
        "\n",
        "    def check_uip_commercial_values(df_actual, df_before, merge_cols):\n",
        "        df_atual = uip_comercial_actual\n",
        "        df_ant = uip_comercial_before\n",
        "        df_cross = pd.merge(df_actual, df_before, on=merge_cols, \\\n",
        "                            how='left', suffixes=('_actual', '_before'), indicator='Exist')\n",
        "        df_cross['Exist'] = np.where(df_cross.Exist == 'both', 'Yes', 'No')\n",
        "        df_cross['Equal Values'] = df_cross['Exist']\n",
        "        \n",
        "        return df_cross\n",
        "    # Check for commercial Values into current UIP File and compare with UIP File before\n",
        "    uip_comercial_actual = pd.read_excel(path_current,sheet_name='Commercial', names=col_names)\n",
        "    #uip_comercial_actual = uip_comercial_actual[['Charge_Type', 'Data_Type', 'Input_Value']]\n",
        "    uip_comercial_actual = replace_values(uip_comercial_actual, col_replace, value=0)\n",
        "\n",
        "    uip_comercial_before = pd.read_excel(path_before,sheet_name='Commercial', names=col_names )\n",
        "    #uip_comercial_before = uip_comercial_before[['Charge_Type', 'Data_Type', 'Input_Value']]\n",
        "    uip_comercial_before = replace_values(uip_comercial_before, col_replace, value=0)\n",
        "\n",
        "    df_commercial =  check_uip_commercial_values(uip_comercial_actual, uip_comercial_before, merge_cols)\n",
        "\n",
        "    #df_commercial = df_commercial.reindex(columns=col_order)\n",
        "    df_commercial_diffs = df_commercial[df_commercial['Equal Values']=='No']\n",
        "    if not df_commercial_diffs.empty:\n",
        "        return df_commercial_diffs\n",
        "    else:\n",
        "        print('\\nNo Errors founded!')\n",
        "\n",
        "names = ['Charge_Type','Sub_Charge_Type', 'Param1','Param2', 'Data_Type', 'Input_Value',\\\n",
        "         'Description/Instruction', 'Frequency of Update']\n",
        "merge_cols = ['Charge_Type','Sub_Charge_Type', 'Param1','Param2', 'Data_Type', \\\n",
        "              'Description/Instruction', 'Frequency of Update']\n",
        "cols_ordered = ['Charge_Type','Sub_Charge_Type', 'Param1','Param2','Data_Type','Input_Value_actual',\\\n",
        "                'Input_Value_before','Equal Values','Description/Instruction', 'Frequency of Update']\n",
        "# Check for commercial Values into current UIP File and compare with UIP File before\n",
        "path_before = '/content/UserInput_Ireland_20210731.xlsx'\n",
        "path_curr = '/content/UserInput_Ireland_July 21_06.07.2021.xlsx'\n",
        "df_com = check_commercial(path_curr, path_before,['Input_Value'], names, merge_cols, cols_ordered)\n",
        "df_com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUNmmb-3wsMu"
      },
      "source": [
        "Excel log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tCh5lYFv3Cm"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "df_tw = [['In Service Date Errors',actives_dates_errors],\n",
        "        ['Dismantled Dates Errors',no_actives_dates_errors],\n",
        "        ['General Picklist Errors',df_general_picklist],\n",
        "        ['Decom Status Error',df_decom],\n",
        "        ['In Service Picklist Errors',df_active_picklist],\n",
        "        ['Billing Dates Errors',df_bill],\n",
        "        ['WIP & BTS Flagged',df_wip_and_bts_flagged],\n",
        "        ['Decom dates Errors',df_decom_errors],\n",
        "        ['New Sites',new_sites],\n",
        "        ['New Sites Bill date errors',bts_out_uis],\n",
        "        ['DOER Dates Errors',df_doer],\n",
        "        ['UIS In Month not active', uis_sites_not_in_towerdb],\n",
        "        ['TowerDB Sites out of UIS', in_service_not_in_uis],\n",
        "        ['Decom Sites in UIS', decomiss_sites_in_uip],\n",
        "        ['Critical Sites out UIS', critical],\n",
        "        ['Commercial Differences' , df_com]] \n",
        "\n",
        "path_tw = '/content/towerdb_IE_errors.xlsx'\n",
        "general_log_erros(df_tw, path_tw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZusOO39hZh9"
      },
      "source": [
        "TA Input File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0hTjigk4T0P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "4cb10bc7-8985-419d-9925-234f23edfce3"
      },
      "source": [
        "#Read TA Input File\n",
        "def read_files(path, sheetname,col_name, n_skiprows, n_skip_columns, site_index, cols_date, cols_int,\\\n",
        "               cols_amount, bill_cols, format='mix', type_date=\"%d/%m/%Y\"):\n",
        "    \n",
        "    def replace_values(df, columns, value=\"\"):\n",
        "        \"\"\"\n",
        "        Está voltando para float\n",
        "        \"\"\"\n",
        "        invalid_values = ['N/A', 'n/a',\"0\", '-', '_', np.nan,'nan', ' ', 'not available yet']\n",
        "\n",
        "        for column in columns:\n",
        "            lista = []\n",
        "            df[column] = df[column].fillna(0)\n",
        "            for index in df[column]:\n",
        "                #print(f\"{column} -> {index}\")\n",
        "                if index in invalid_values:\n",
        "                    lista.append(value)\n",
        "                else:\n",
        "                    lista.append(index)\n",
        "            df[column] = lista\n",
        "        return df\n",
        "    def date_parser(df, columns,format, type_date):\n",
        "        for column in columns:\n",
        "            if format == 'mix':\n",
        "                df[column] = [date_obj.strftime(type_date) if not pd.isnull(date_obj) \\\n",
        "                            and not isinstance(date_obj, str) else '' for date_obj in df[column]]\n",
        "                df[column] = df[column].astype(str)\n",
        "            else:\n",
        "                df[column] = [date_obj.strftime(type_date) if not pd.isnull(date_obj) else '' for date_obj in df[column]]\n",
        "                df[column] = df[column].astype(str)\n",
        "    #header=0, names = col_name,\n",
        "    df = pd.read_excel(path, sheet_name = sheetname, engine='openpyxl', skiprows = n_skiprows)\n",
        "    df = df.iloc[:,n_skip_columns:]\n",
        "    df = df[col_name] \n",
        "    df = df.dropna(subset=[site_index], axis=0)\n",
        "    df = replace_values(df, cols_amount, 0)\n",
        "    for col in cols_amount:\n",
        "        df[col] = df[col].fillna(0)\n",
        "        df[col] = df[col].astype(int).apply(lambda x: f'{x:,}')\n",
        "    df = replace_values(df, cols_int, 0)\n",
        "    for col in cols_int:\n",
        "        df[col] = df[col].fillna(0)\n",
        "        df[col] = df[col].astype(int)\n",
        "    df = df.fillna('')\n",
        "    df = replace_values(df, bill_cols)\n",
        "    date_parser(df, cols_date, format, type_date)\n",
        "    # define the entiry columns which doesn't have NaN \n",
        "    return df\n",
        "ta_col_ord = [\"Site ID \",\"Site Name \",\"Address \",\"Site Provider\",\"Site type\",\\\n",
        "              \"Tenant/Customer \",\"Customer Type \",\" Initial Rent  \",\" Current Rent  \",\" REC Uplift Charge \",\\\n",
        "              \"Current Power Charge\",\"Renegotiations \",\"Lease Start Date \",\"Lease End date \",\"Right to Renew \",\\\n",
        "              \"End of Renewal Period \",\"Payment Terms \",\"Payment Frequency \",\"Rent Review \",\"Indexation Driver\",\\\n",
        "              \"Fixed Increase \",\"CPI \",\"Percentage\",\"Increase frequency\",\"Increase Date\",\"VAT\",\"Rate \",\"Termination date \"]\n",
        "interger = ['Increase frequency']\n",
        "amount = []\n",
        "ta_bill_cols = [\"Site ID \",\"Tenant/Customer \",\"Customer Type \",\\\n",
        "                \"Lease Start Date \",\"Lease End date \"]\n",
        "ta_dates = [\"Lease Start Date \",\"Lease End date \", \"Increase Date\", 'Termination date ']\n",
        "              \n",
        "path='/content/TowerDB_Ireland_20210630 v1.xlsx'\n",
        "sheet='TA_Input_Ireland_20210630'\n",
        "skiprows=0\n",
        "skipcols=0\n",
        "#(path, sheetname,col_name, n_skiprows, n_skip_columns, site_index, cols_date, cols_int,\\\n",
        "               #cols_amount, bill_cols, format='mix', type_date=\"%d/%m/%Y\")\n",
        "ta = read_files(path, sheet,ta_col_ord, 0, 0, \"Site ID \", ta_dates, interger,amount, ta_bill_cols)\n",
        "\n",
        "#Replacing values\n",
        "ta.loc[ta['Rate ']==0.23, 'Rate '], ta.loc[ta['Rate ']==0.21, 'Rate '], ta.loc[ta['Rate ']=='-', 'Rate '] = '23%','21%', ''\n",
        "ta.loc[ta['Percentage']==1, 'Percentage'], ta.loc[ta['Percentage']=='-', 'Percentage'] = '100%', ''\n",
        "\n",
        "ta.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Site Name</th>\n",
              "      <th>Address</th>\n",
              "      <th>Site Provider</th>\n",
              "      <th>Site type</th>\n",
              "      <th>Tenant/Customer</th>\n",
              "      <th>Customer Type</th>\n",
              "      <th>Initial Rent</th>\n",
              "      <th>Current Rent</th>\n",
              "      <th>REC Uplift Charge</th>\n",
              "      <th>Current Power Charge</th>\n",
              "      <th>Renegotiations</th>\n",
              "      <th>Lease Start Date</th>\n",
              "      <th>Lease End date</th>\n",
              "      <th>Right to Renew</th>\n",
              "      <th>End of Renewal Period</th>\n",
              "      <th>Payment Terms</th>\n",
              "      <th>Payment Frequency</th>\n",
              "      <th>Rent Review</th>\n",
              "      <th>Indexation Driver</th>\n",
              "      <th>Fixed Increase</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Percentage</th>\n",
              "      <th>Increase frequency</th>\n",
              "      <th>Increase Date</th>\n",
              "      <th>VAT</th>\n",
              "      <th>Rate</th>\n",
              "      <th>Termination date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CE007</td>\n",
              "      <td>Lack West</td>\n",
              "      <td>Lack West Kilmihil  Clare</td>\n",
              "      <td>Vodafone</td>\n",
              "      <td>GBT</td>\n",
              "      <td>Three Ireland Services (Hutchinston) Ltd</td>\n",
              "      <td>MNO</td>\n",
              "      <td></td>\n",
              "      <td>14417.338624</td>\n",
              "      <td></td>\n",
              "      <td>Vfi supply</td>\n",
              "      <td></td>\n",
              "      <td>06/02/2006</td>\n",
              "      <td>05/02/2011</td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td>Quarterly in Advance</td>\n",
              "      <td>4</td>\n",
              "      <td>CPI Applied from 01 October annually</td>\n",
              "      <td>Annually Tenant Fees</td>\n",
              "      <td>CPI/4% (the greater of)</td>\n",
              "      <td>-</td>\n",
              "      <td>100%</td>\n",
              "      <td>12</td>\n",
              "      <td>01/10/2019</td>\n",
              "      <td>Yes</td>\n",
              "      <td>23%</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CE007</td>\n",
              "      <td>Lack West</td>\n",
              "      <td>Lack West Kilmihil  Clare</td>\n",
              "      <td>Vodafone</td>\n",
              "      <td>GBT</td>\n",
              "      <td>Tetra Ireland Communications Ltd</td>\n",
              "      <td>OTMO</td>\n",
              "      <td>9500</td>\n",
              "      <td>10142.700000</td>\n",
              "      <td></td>\n",
              "      <td>531</td>\n",
              "      <td></td>\n",
              "      <td>01/10/2011</td>\n",
              "      <td>30/09/2021</td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td>Half Yearly</td>\n",
              "      <td>2</td>\n",
              "      <td>Annually</td>\n",
              "      <td>Annually Tenant Fees</td>\n",
              "      <td>CPI</td>\n",
              "      <td>-</td>\n",
              "      <td>100%</td>\n",
              "      <td>12</td>\n",
              "      <td>01/10/2019</td>\n",
              "      <td>Yes</td>\n",
              "      <td>23%</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CE007</td>\n",
              "      <td>Lack West</td>\n",
              "      <td>Lack West Kilmihil  Clare</td>\n",
              "      <td>Vodafone</td>\n",
              "      <td>GBT</td>\n",
              "      <td>Imagine</td>\n",
              "      <td>OTMO</td>\n",
              "      <td>12000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td></td>\n",
              "      <td>Vfi supply</td>\n",
              "      <td></td>\n",
              "      <td>25/07/2019</td>\n",
              "      <td>24/07/2024</td>\n",
              "      <td>No</td>\n",
              "      <td></td>\n",
              "      <td>Quarterly In Advance</td>\n",
              "      <td>4</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>Yes</td>\n",
              "      <td>23%</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Site ID  Site Name                    Address   ...  VAT Rate  Termination date \n",
              "0    CE007  Lack West  Lack West Kilmihil  Clare  ...  Yes   23%                  \n",
              "1    CE007  Lack West  Lack West Kilmihil  Clare  ...  Yes   23%                  \n",
              "2    CE007  Lack West  Lack West Kilmihil  Clare  ...  Yes   23%                  \n",
              "\n",
              "[3 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcjgdlF976fT"
      },
      "source": [
        "ta.to_csv('/content/TA_Input_Ireland_20210831.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-ZH1soy1Dl7"
      },
      "source": [
        "check for blank fields in Lease Start Date and Lease End date, and if Lease Start Dates always be prior to end dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QjbaAY_l2Gv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "06c15008-833f-452a-a5cd-07221285f107"
      },
      "source": [
        "import datetime as dt\n",
        "\n",
        "#Create dates in datetime format\n",
        "ta['end'] = [pd.to_datetime(i, format='%d/%m/%Y') if i!= '' else datetime(1999, 1, 1, 0, 0, 0) for i in ta['Lease End date ']]\n",
        "ta['start'] = [pd.to_datetime(i, format='%d/%m/%Y') if i!= '' else datetime(1999, 1, 1, 0, 0, 0) for i in ta['Lease Start Date ']]\n",
        "#Create diff columns to get negative values\n",
        "ta['dt_dff'] = (ta['end'] - ta['start']).dt.days\n",
        "\n",
        "start_or_end_blank = (ta['Lease Start Date ']=='')|(ta['Lease End date ']=='')\n",
        "negative_dates = (ta['dt_dff'] <= 0)\n",
        "cols = ['Site ID ',\"Tenant/Customer \", 'Lease Start Date ', 'Lease End date ']\n",
        "ta_dates_errors = ta[start_or_end_blank|negative_dates][cols]\n",
        "\n",
        "ta_dates_errors\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Tenant/Customer</th>\n",
              "      <th>Lease Start Date</th>\n",
              "      <th>Lease End date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Site ID , Tenant/Customer , Lease Start Date , Lease End date ]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUrS1kNw09sD"
      },
      "source": [
        "Check customer types (MNO, OTMO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "0ee8-1EK0sjX",
        "outputId": "5ab13395-2bb8-4540-ae65-92ae97ef91e7"
      },
      "source": [
        "df_class_error = ta[(ta['Customer Type ']=='')|~(ta['Customer Type '].isin(['MNO', 'OTMO']))][['Site ID ',\"Tenant/Customer \", 'Customer Type ']]\n",
        "df_class_error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Tenant/Customer</th>\n",
              "      <th>Customer Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Site ID , Tenant/Customer , Customer Type ]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEJOpERa3JAX"
      },
      "source": [
        "Check Tenant/Customer for blank fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "1u8PQ2nu2wsb",
        "outputId": "371d53a1-04ad-493e-efcb-eab782ee7e34"
      },
      "source": [
        "df_customer_error = ta[ta[\"Tenant/Customer \"].isin(['', None, ' '])][['Site ID ',\"Tenant/Customer \"]]\n",
        "df_customer_error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Tenant/Customer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Site ID , Tenant/Customer ]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mre3hvLN4uOp"
      },
      "source": [
        "Ta Log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV7Nbmo74vkp"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "ta_df = [['Dates Errors', ta_dates_errors],\n",
        "    ['Customer Type Erros', df_class_error],\n",
        "    ['Tenant Errors', df_customer_error]]\n",
        "path_log_ta = '/content/TA_IE_Log.xlsx'\n",
        "general_log_erros(ta_df, path_log_ta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjMBeXxb-Lqx"
      },
      "source": [
        "LC Validations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7i1rWzA-KxL"
      },
      "source": [
        "#Read TA Input File\n",
        "def read_files(path, sheetname,col_name, n_skiprows, n_skip_columns, site_index, cols_date, cols_int,\\\n",
        "               cols_amount, bill_cols, format='mix', type_date=\"%d/%m/%Y\"):\n",
        "    \n",
        "    def replace_values(df, columns, value=\"\"):\n",
        "        \"\"\"\n",
        "        Está voltando para float\n",
        "        \"\"\"\n",
        "        invalid_values = ['N/A', 'n/a',\"0\", '-', '_', np.nan,'nan', ' ', 'not available yet']\n",
        "\n",
        "        for column in columns:\n",
        "            lista = []\n",
        "            df[column] = df[column].fillna(0)\n",
        "            for index in df[column]:\n",
        "                #print(f\"{column} -> {index}\")\n",
        "                if index in invalid_values:\n",
        "                    lista.append(value)\n",
        "                else:\n",
        "                    lista.append(index)\n",
        "            df[column] = lista\n",
        "        return df\n",
        "    def date_parser(df, columns,format, type_date):\n",
        "        for column in columns:\n",
        "            if format == 'mix':\n",
        "                df[column] = [date_obj.strftime(type_date) if not pd.isnull(date_obj) \\\n",
        "                            and not isinstance(date_obj, str) else '' for date_obj in df[column]]\n",
        "                df[column] = df[column].astype(str)\n",
        "            else:\n",
        "                df[column] = [date_obj.strftime(type_date) if not pd.isnull(date_obj) else '' for date_obj in df[column]]\n",
        "                df[column] = df[column].astype(str)\n",
        "    #header=0, names = col_name,\n",
        "    df = pd.read_excel(path, sheet_name = sheetname, engine='openpyxl', skiprows = n_skiprows)\n",
        "    df = df.iloc[:,n_skip_columns:]\n",
        "    df = df[col_name] \n",
        "    df = df.dropna(subset=[site_index], axis=0)\n",
        "    df = replace_values(df, cols_amount, 0)\n",
        "    for col in cols_amount:\n",
        "        df[col] = df[col].fillna(0)\n",
        "        df[col] = df[col].astype(int).apply(lambda x: f'{x:,}')\n",
        "    df = replace_values(df, cols_int, 0)\n",
        "    for col in cols_int:\n",
        "        df[col] = df[col].fillna(0)\n",
        "        df[col] = df[col].astype(int)\n",
        "    df = df.fillna('')\n",
        "    df = replace_values(df, bill_cols)\n",
        "    date_parser(df, cols_date, format, type_date)\n",
        "    # define the entiry columns which doesn't have NaN \n",
        "    return df\n",
        "lc_ord = [\"Site ID \",\"Site Name \",\"Address \",\"Site Provider\",\"Contract Type\",\"Vendor\",\" Current Rent  \",\\\n",
        "          \" Sublet/Uplift \",\" Total Rent \",\"Misc Fees \",\"Sublet Clause \",\"Conditions \",\"Uplift for Sublet \",\\\n",
        "          \"Lease Start Date \",\"Lease End date \",\"Right to Renew \",\"End of Renewal Period \",\"Payment Terms \",\\\n",
        "          \"Payment Frequency\",\"Rent Review \",\"Fixed Increase \",\"Indexation Driver\",\"CPI/Increase Type\",\\\n",
        "          \"Percentage\",\"Increase Frequency\",\"Increase date\",\"VAT Subject\",\"VAT\",\"Termination date \",\"Observations\"]\n",
        "interger = []#'Increase frequency'\n",
        "amount = []#\" Current Rent  \",\" Total Rent \"\n",
        "ta_bill_cols = [\"Site ID \",\\\n",
        "                \"Lease Start Date \",\"Lease End date \"]\n",
        "dates = [\"Lease Start Date \",\"Lease End date \", \"Increase date\"]             \n",
        "path='/content/TowerDB_Ireland_20210630 v1.xlsx'\n",
        "sheet_lc='LC_Input_Ireland_20210630'\n",
        "#(path, sheetname,col_name, n_skiprows, n_skip_columns, site_index, cols_date, cols_int,\\\n",
        "               #cols_amount, bill_cols, format='mix', type_date=\"%d/%m/%Y\")\n",
        "lc = read_files(path, sheet_lc,lc_ord, 0, 0, \"Site ID \", dates, interger,amount, ta_bill_cols)\n",
        "#lc[\"Uplift for Sublet \"] = [re.sub('^€', '', str(x)) for x in lc[\"Uplift for Sublet \"]]\n",
        "#lc[\"Uplift for Sublet \"] = lc[\"Uplift for Sublet \"].replace('-', '')\n",
        "lc.loc[lc[\"VAT\"]==0.23, \"VAT\"], lc.loc[lc[\"Percentage\"]==1, \"Percentage\"] = '23%', \"100%\"\n",
        "\n",
        "lc.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXXMSe5I-3Ns"
      },
      "source": [
        "lc.to_csv('/content/LC_Input_Ireland_20210831.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtK_6bIX58W9"
      },
      "source": [
        "Checking Dates Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSoO4rltm8Gm"
      },
      "source": [
        "import datetime as dt\n",
        "\n",
        "#Create dates in datetime format\n",
        "lc['end'] = [pd.to_datetime(i, format='%d/%m/%Y') if i!= '' else datetime(1999, 1, 1, 0, 0, 0) for i in lc['Lease End date ']]\n",
        "lc['start'] = [pd.to_datetime(i, format='%d/%m/%Y') if i!= '' else datetime(1999, 1, 1, 0, 0, 0) for i in lc['Lease Start Date ']]\n",
        "#create diff columns to get negative values\n",
        "lc['dt_dff'] = (lc['end'] - lc['start']).dt.days\n",
        "\n",
        "start_or_end_blank = (lc['Lease Start Date ']=='')|(lc['Lease End date ']=='')\n",
        "negative_dates = (lc['dt_dff'] <= 0)\n",
        "cols = ['Site ID ', 'Lease Start Date ', 'Lease End date ']\n",
        "df_lc_dates = lc[start_or_end_blank|negative_dates][cols]\n",
        "\n",
        "df_lc_dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B91O2ABp5_rG"
      },
      "source": [
        "Checking amount field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bmmCXE1_tQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "278bcb1a-17b5-45d1-b20e-274427317592"
      },
      "source": [
        "def check_amounts(df, df_index, columns, pattern=','):\n",
        "    \"\"\"\n",
        "    Paramns \\n\n",
        "        Dates needs to be in string format not in datetime, otherwise raise an error.\\n\n",
        "        Convert entire column to string before.\n",
        "    \"\"\"\n",
        "    from collections import defaultdict\n",
        "\n",
        "    df_am = df[columns].fillna('')\n",
        "    df_am = df_am.to_dict(orient='list')\n",
        "\n",
        "    new_dic = defaultdict(list)\n",
        "\n",
        "    for column in set(df_am.keys()):\n",
        "        for value in df_am[column]:\n",
        "            if not str(value).__contains__(pattern):\n",
        "                if value in (None, '', 'nan'):\n",
        "                    new_dic[column].append('Blank Value')\n",
        "                elif value == '0':\n",
        "                    new_dic[column].append('Input 0')\n",
        "                else:\n",
        "                    new_dic[column].append(f'Incorret picklist value: {value}')\n",
        "            else:\n",
        "                new_dic[column].append('Ok')\n",
        "\n",
        "    df_errors = pd.DataFrame(new_dic)\n",
        "    df_errors = df_errors.replace('Ok', np.nan)\n",
        "    df_errors[df_index] = df[df_index]\n",
        "    df_errors = df_errors.set_index(df_index)\n",
        "    df_errors = df_errors.dropna(how='all', axis=0)\n",
        "    df_errors = df_errors.dropna(how='all', axis=1)\n",
        "    df_errors = df_errors.reset_index()\n",
        "    #df_errors = df_errors.reset_index()\n",
        "    return df_errors\n",
        "\"\"\"Check Amount\"\"\"\n",
        "lc_col_amounts = [' Total Rent ']\n",
        "df_lc_amounts = check_amounts(lc, \"Site ID \", lc_col_amounts, '.')\n",
        "df_lc_amounts\n",
        "# No errors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Site ID</th>\n",
              "      <th>Total Rent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GY025</td>\n",
              "      <td>Blank Value</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Site ID   Total Rent \n",
              "0    GY025  Blank Value"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L0CS7vd6Dh4"
      },
      "source": [
        "Log creating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5giQV3Wwysa",
        "outputId": "5c84cb35-5819-4efd-e2ac-b2de5bd9f60e"
      },
      "source": [
        "def general_log_erros(df_list, path):\n",
        "    writer = pd.ExcelWriter(path,engine='openpyxl')  \n",
        "    for lista in df_list:\n",
        "        try:\n",
        "            if not lista[1].empty:\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "        except:\n",
        "            if lista[1] is not None and lista[1].is_valid():\n",
        "                lista[1].to_excel(writer, sheet_name=lista[0], index=False)\n",
        "    try: \n",
        "        writer.save() \n",
        "    except IndexError:\n",
        "        print('No one log to write!')\n",
        "\n",
        "df_lc = [['Dates Errors',df_lc_dates_erros],\n",
        "         ['Amount Errors', df_lc_amounts]]\n",
        "\n",
        "path_lc = '/content/LC_IE_log.xlsx'\n",
        "general_log_erros(df_lc, path_lc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/openpyxl/workbook/child.py:102: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
            "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}